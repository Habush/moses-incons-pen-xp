{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\r\n",
      "Requirement already satisfied: jax[cuda11_cudnn82] in /usr/local/lib/python3.9/dist-packages (0.3.14)\r\n",
      "Collecting jax[cuda11_cudnn82]\r\n",
      "  Downloading jax-0.3.17.tar.gz (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m65.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (1.23.1)\r\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (1.8.1)\r\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (4.3.0)\r\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn82]) (0.6.0)\r\n",
      "Collecting jaxlib==0.3.15+cuda11.cudnn82\r\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.15%2Bcuda11.cudnn82-cp39-none-manylinux2014_x86_64.whl (162.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m162.7/162.7 MB\u001B[0m \u001B[31m14.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax[cuda11_cudnn82]) (5.8.0)\r\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax[cuda11_cudnn82]) (3.8.1)\r\n",
      "Building wheels for collected packages: jax\r\n",
      "  Building wheel for jax (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for jax: filename=jax-0.3.17-py3-none-any.whl size=1217849 sha256=cf5d68c72c247ee1496af27707c457ba8b1b342321249ea0380d9fb1986b5dec\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/36/cd/88/2d90379f7549c27d5654e893f74210f30f0c645c23a71e6f56\r\n",
      "Successfully built jax\r\n",
      "Installing collected packages: jaxlib, jax\r\n",
      "  Attempting uninstall: jaxlib\r\n",
      "    Found existing installation: jaxlib 0.3.8+cuda11.cudnn82\r\n",
      "    Uninstalling jaxlib-0.3.8+cuda11.cudnn82:\r\n",
      "      Successfully uninstalled jaxlib-0.3.8+cuda11.cudnn82\r\n",
      "  Attempting uninstall: jax\r\n",
      "    Found existing installation: jax 0.3.14\r\n",
      "    Uninstalling jax-0.3.14:\r\n",
      "      Successfully uninstalled jax-0.3.14\r\n",
      "Successfully installed jax-0.3.17 jaxlib-0.3.15+cuda11.cudnn82\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting tensorflow-probability\r\n",
      "  Downloading tensorflow_probability-0.18.0-py2.py3-none-any.whl (6.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.6/6.6 MB\u001B[0m \u001B[31m94.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability) (1.14.0)\r\n",
      "Collecting dm-tree\r\n",
      "  Downloading dm_tree-0.1.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m142.7/142.7 kB\u001B[0m \u001B[31m40.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (1.1.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (2.1.0)\r\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (0.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (1.23.1)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability) (5.1.1)\r\n",
      "Installing collected packages: dm-tree, tensorflow-probability\r\n",
      "Successfully installed dm-tree-0.1.7 tensorflow-probability-0.18.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting numpyro\r\n",
      "  Downloading numpyro-0.10.1-py3-none-any.whl (292 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m292.7/292.7 kB\u001B[0m \u001B[31m37.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting multipledispatch\r\n",
      "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from numpyro) (4.64.0)\r\n",
      "Requirement already satisfied: jax>=0.2.13 in /usr/local/lib/python3.9/dist-packages (from numpyro) (0.3.17)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from numpyro) (1.23.1)\r\n",
      "Requirement already satisfied: jaxlib>=0.1.65 in /usr/local/lib/python3.9/dist-packages (from numpyro) (0.3.15+cuda11.cudnn82)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from jax>=0.2.13->numpyro) (1.1.0)\r\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.9/dist-packages (from jax>=0.2.13->numpyro) (0.6.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from jax>=0.2.13->numpyro) (4.3.0)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.2.13->numpyro) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.2.13->numpyro) (1.8.1)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from multipledispatch->numpyro) (1.14.0)\r\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.2.13->numpyro) (3.8.1)\r\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.2.13->numpyro) (5.8.0)\r\n",
      "Installing collected packages: multipledispatch, numpyro\r\n",
      "Successfully installed multipledispatch-0.6.0 numpyro-0.10.1\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting distrax\r\n",
      "  Downloading distrax-0.1.2-py3-none-any.whl (272 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m272.0/272.0 kB\u001B[0m \u001B[31m35.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from distrax) (1.23.1)\r\n",
      "Collecting chex>=0.0.7\r\n",
      "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.3/85.3 kB\u001B[0m \u001B[31m33.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.9/dist-packages (from distrax) (0.3.17)\r\n",
      "Requirement already satisfied: jaxlib>=0.1.67 in /usr/local/lib/python3.9/dist-packages (from distrax) (0.3.15+cuda11.cudnn82)\r\n",
      "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from distrax) (1.1.0)\r\n",
      "Requirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from distrax) (0.18.0)\r\n",
      "Collecting toolz>=0.9.0\r\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.8/55.8 kB\u001B[0m \u001B[31m21.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from chex>=0.0.7->distrax) (0.1.7)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->distrax) (4.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->distrax) (1.8.1)\r\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->distrax) (0.6.0)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->distrax) (3.3.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability>=0.15.0->distrax) (2.1.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability>=0.15.0->distrax) (1.14.0)\r\n",
      "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability>=0.15.0->distrax) (0.4.0)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability>=0.15.0->distrax) (5.1.1)\r\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.1.55->distrax) (3.8.1)\r\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.1.55->distrax) (5.8.0)\r\n",
      "Installing collected packages: toolz, chex, distrax\r\n",
      "Successfully installed chex-0.1.5 distrax-0.1.2 toolz-0.12.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting git+https://github.com/blackjax-devs/blackjax.git\r\n",
      "  Cloning https://github.com/blackjax-devs/blackjax.git to /tmp/pip-req-build-w1mnn2cg\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/blackjax-devs/blackjax.git /tmp/pip-req-build-w1mnn2cg\r\n",
      "  Resolved https://github.com/blackjax-devs/blackjax.git to commit ab43b673ff477a3126b73c68cb8a26d97c3888bd\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting fastprogress>=0.2.0\r\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: jax>=0.3.13 in /usr/local/lib/python3.9/dist-packages (from blackjax==0.8.3) (0.3.17)\r\n",
      "Requirement already satisfied: jaxlib>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from blackjax==0.8.3) (0.3.15+cuda11.cudnn82)\r\n",
      "Collecting jaxopt>=0.4.2\r\n",
      "  Downloading jaxopt-0.5-py3-none-any.whl (128 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.5/128.5 kB\u001B[0m \u001B[31m27.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (1.8.1)\r\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (0.6.0)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (1.23.1)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.8.3) (4.3.0)\r\n",
      "Requirement already satisfied: matplotlib>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from jaxopt>=0.4.2->blackjax==0.8.3) (3.5.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (4.34.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (9.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (1.4.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (3.0.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (0.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (2.8.2)\r\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.3.13->blackjax==0.8.3) (3.8.1)\r\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[epath]->jax>=0.3.13->blackjax==0.8.3) (5.8.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.1->jaxopt>=0.4.2->blackjax==0.8.3) (1.14.0)\r\n",
      "Building wheels for collected packages: blackjax\r\n",
      "  Building wheel for blackjax (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for blackjax: filename=blackjax-0.8.3-py3-none-any.whl size=114525 sha256=7a1ee8d4923aeb1fc322c2362ae5fed0de4b9cbffab01e5016c278fe0677ac6e\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p4y7d4n3/wheels/e6/1e/f6/a6e0408a4e374b9cdb789b1769716b4ed61eef520a2dd702b1\r\n",
      "Successfully built blackjax\r\n",
      "Installing collected packages: fastprogress, jaxopt, blackjax\r\n",
      "Successfully installed blackjax-0.8.3 fastprogress-1.0.3 jaxopt-0.5\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install tensorflow-probability\n",
    "!pip install numpyro\n",
    "!pip install distrax\n",
    "!pip install git+https://github.com/blackjax-devs/blackjax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.stats as stats\n",
    "import numpyro as npyro\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tfd = tfp.distributions\n",
    "plt.style.use('ggplot')\n",
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'gpu'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.default_backend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def run_fs_clf(clf, X_train, X_test, y_train, y_test, feats):\n",
    "    results = {\"cv_score\": [], \"test_score\": []}\n",
    "    for fts in feats:\n",
    "        X_s_train, X_s_test = X_train[:,np.array(fts, dtype=np.int32)].astype(np.int64), X_test[:,np.array(fts, dtype=np.int32)].astype(np.int64)\n",
    "        y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
    "        if fts.size == 1:\n",
    "            X_s_train, X_s_test = X_s_train.reshape(-1, 1), X_s_test.reshape(-1, 1)\n",
    "        cv_score = np.mean(cross_val_score(clf, X_s_train, y_train, scoring=\"roc_auc\"))\n",
    "        clf_est = clf.fit(X_s_train, y_train)\n",
    "        test_score = roc_auc_score(y_test, clf_est.predict_proba(X_s_test)[:,1])\n",
    "        # print({\"moses_cv_score\": cv_score, \"moses_test_score\": test_score, \"log_cv_score\": cv_score, \"log_test_score\": test_score})\n",
    "        results[\"cv_score\"].append(cv_score)\n",
    "        results[\"test_score\"].append(test_score)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def fisher_exact_test(X, y, thres=0.05):\n",
    "    cols = X.columns\n",
    "    p_values = np.zeros(len(cols))\n",
    "    for i, col in enumerate(cols):\n",
    "        table = pd.crosstab(y, X[col])\n",
    "        _, p_val = stats.fisher_exact(table, alternative=\"two-sided\")\n",
    "        p_values[i] = p_val\n",
    "\n",
    "    idx_sig = np.argwhere(p_values < thres)\n",
    "    print(f\"Total of {len(idx_sig)} variables are significant (p_val = {thres})\")\n",
    "\n",
    "    return idx_sig\n",
    "\n",
    "\n",
    "def build_network(X):\n",
    "    p = X.shape[1]\n",
    "    J = np.zeros((p, p))\n",
    "    cols = X.columns\n",
    "    intrs = []\n",
    "    intrs_rev = []\n",
    "    for i, g1 in enumerate(cols):\n",
    "        try:\n",
    "            g_intrs = list(net_intr[g1])\n",
    "            for g2 in g_intrs:\n",
    "                if (g2, g1) not in intrs_rev: # check if we haven't encountered the reverse interaction\n",
    "                    j = cols.get_loc(g2)\n",
    "                    J[i, j] = 1.0\n",
    "                    J[j, i] = 1.0\n",
    "                    intrs.append((g1, g2))\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        # Check the reverse direction\n",
    "        try:\n",
    "            g_intrs_rev = list(net_intr_rev[g1])\n",
    "            for g2 in g_intrs_rev:\n",
    "                if (g1, g2) not in intrs:\n",
    "                    j = cols.get_loc(g2)\n",
    "                    J[i, j] = 1.0\n",
    "                    J[j, i] = 1.0\n",
    "                    intrs_rev.append((g2, g1))\n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "\n",
    "    return J\n",
    "\n",
    "def get_ess(n_chain, samples):\n",
    "    k = int(samples.shape[0] / n_chain)\n",
    "    chains = samples.reshape(n_chain, k, samples.shape[-1])\n",
    "    ess = npyro.diagnostics.effective_sample_size(jax.device_get(chains))\n",
    "    ess[np.isnan(ess)] = 1.0\n",
    "    return np.mean(ess)\n",
    "\n",
    "def prepare_data(seed, X, y, p_val=0.01):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y, random_state=seed)\n",
    "\n",
    "    try:\n",
    "        idx_sig = np.load(f\"{data_dir}/exp_data_2/npy/idx_sig_s_{seed}.npy\")\n",
    "    except FileNotFoundError:\n",
    "        idx_sig = np.squeeze(fisher_exact_test(X_train, y_train, p_val))\n",
    "        jnp.save(f\"{data_dir}/exp_data_2/npy/idx_sig_s_{seed}.npy\", idx_sig)\n",
    "\n",
    "    X_train_sig, X_test_sig = X_train.iloc[:,idx_sig], X_test.iloc[:,idx_sig]\n",
    "\n",
    "\n",
    "\n",
    "    return X_train_sig, X_test_sig, y_train, y_test\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "def setup_logger(log_path, seed):\n",
    "    logging.getLogger().handlers = []\n",
    "    logging.getLogger().setLevel(logging.NOTSET)\n",
    "\n",
    "    formatter = logging.Formatter(\"%(asctime)s [%(levelname)s], %(message)s\")\n",
    "\n",
    "    console = logging.StreamHandler(sys.stdout)\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger().addHandler(console)\n",
    "\n",
    "    rotatingHandler = logging.handlers.RotatingFileHandler(filename=f\"{log_path}/logs/log_s_{seed}.log\", maxBytes=(1048576*5),\n",
    "                                                           backupCount=7)\n",
    "    rotatingHandler.setLevel(logging.INFO)\n",
    "    rotatingHandler.setFormatter(formatter)\n",
    "    logging.getLogger().addHandler(rotatingHandler)\n",
    "    log = logging.getLogger()\n",
    "    return log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from typing import Callable, NamedTuple\n",
    "from blackjax.types import PRNGKey, PyTree\n",
    "\n",
    "\n",
    "class MixedMALAState(NamedTuple):\n",
    "    \"\"\"Holds info about the discrete and the continuous r.vs in the mixed support\"\"\"\n",
    "\n",
    "    discrete_position: PyTree\n",
    "    contin_position: PyTree\n",
    "\n",
    "    disc_logprob: float\n",
    "    contin_logprob: float\n",
    "\n",
    "    discrete_logprob_grad: PyTree\n",
    "    contin_logprob_grad: PyTree\n",
    "\n",
    "    disc_step_size: float\n",
    "    contin_step_size: float\n",
    "\n",
    "\n",
    "from blackjax.mcmc.diffusion import generate_gaussian_noise\n",
    "from blackjax.mcmc.mala import MALAState\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "\n",
    "def diff_fn(state, step_size):\n",
    "    theta = jax.tree_util.tree_map(lambda x, g: -0.5 * (g) * (2. * x - 1) - (1. / (2. * step_size)),\n",
    "                                   state.position, state.logprob_grad)\n",
    "\n",
    "    return jax.nn.sigmoid(theta)\n",
    "\n",
    "\n",
    "def take_discrete_step(rng_key: PRNGKey, disc_state: MALAState, contin_state: MALAState,\n",
    "                       logprob_fn: Callable, disc_grad_fn: Callable,\n",
    "                       step_size: float) -> MALAState:\n",
    "    _, key_rmh, key_accept = jax.random.split(rng_key, 3)\n",
    "    theta_cur = disc_state.position\n",
    "\n",
    "    u = jax.random.uniform(key_rmh, shape=disc_state.position.shape)\n",
    "    p_curr = diff_fn(disc_state, step_size)\n",
    "    ind = jnp.array(u < p_curr)\n",
    "    pos_new = (1. - theta_cur) * ind + theta_cur * (1. - ind)\n",
    "\n",
    "    logprob_new = logprob_fn(pos_new, contin_state.position)\n",
    "    logprob_grad_new = disc_grad_fn(pos_new, contin_state.position)\n",
    "    new_state = MALAState(pos_new, logprob_new, logprob_grad_new)  # No metropolis update just accept the move\n",
    "\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def take_contin_step(rng_key: PRNGKey, disc_state: MALAState, contin_state: MALAState,\n",
    "                     logprob_fn: Callable, contin_grad_fn: Callable,\n",
    "                     step_size: float) -> MALAState:\n",
    "    key_integrator, key_rmh = jax.random.split(rng_key)\n",
    "    noise = generate_gaussian_noise(key_integrator, contin_state.position)\n",
    "    new_position = jax.tree_util.tree_map(\n",
    "        lambda p, g, n: p + step_size * g + jnp.sqrt(2 * step_size) * n,\n",
    "        contin_state.position,\n",
    "        contin_state.logprob_grad,\n",
    "        noise,\n",
    "    )\n",
    "\n",
    "    logprob_new = logprob_fn(disc_state.position, new_position)\n",
    "    logprob_grad_new = contin_grad_fn(disc_state.position, new_position)\n",
    "    new_state = MALAState(new_position, logprob_new, logprob_grad_new)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def one_step(\n",
    "        rng_key: PRNGKey, state: MixedMALAState,\n",
    "        discrete_logprob_fn: Callable, contin_logprob_fn: Callable,\n",
    "        discrete_step_size: float, contin_step_size: float\n",
    ") -> MixedMALAState:\n",
    "    disc_grad_fn = jax.grad(discrete_logprob_fn)\n",
    "    contin_grad_fn = jax.grad(contin_logprob_fn, argnums=1)\n",
    "    # Evolve each variable in tandem and combine the results\n",
    "\n",
    "    disc_state = MALAState(state.discrete_position, state.disc_logprob, state.discrete_logprob_grad)\n",
    "    contin_state = MALAState(state.contin_position, state.contin_logprob, state.contin_logprob_grad)\n",
    "    # print(f\"disc pos: {disc_state.position}, contin pos: {contin_state.position}\")\n",
    "    # Take a step for the discrete variable - sample from p(discrete | contin)\n",
    "    new_disc_state = take_discrete_step(rng_key, disc_state, contin_state,\n",
    "                                        discrete_logprob_fn, disc_grad_fn, discrete_step_size)\n",
    "    # Take a step for the contin variable - sample from p(contin | new_discrete)\n",
    "    new_contin_state = take_contin_step(rng_key, new_disc_state, contin_state,\n",
    "                                        contin_logprob_fn, contin_grad_fn, contin_step_size)\n",
    "\n",
    "    new_state = MixedMALAState(new_disc_state.position, new_contin_state.position,\n",
    "                               new_disc_state.logprob, new_contin_state.logprob,\n",
    "                               new_disc_state.logprob_grad, new_contin_state.logprob_grad,\n",
    "                               discrete_step_size, contin_step_size)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "def init(disc_position: PyTree,contin_position: PyTree,\n",
    "         disc_logprob_fn: Callable, contin_logprob_fn: Callable,\n",
    "         init_disc_step: float, init_contin_step: float) -> MixedMALAState:\n",
    "\n",
    "    disc_logprob, disc_grad_logprob = jax.value_and_grad(disc_logprob_fn)(disc_position, contin_position)\n",
    "    contin_logprob, contin_grad_logprob = jax.value_and_grad(contin_logprob_fn, argnums=1)(disc_position, contin_position)\n",
    "\n",
    "    return MixedMALAState(disc_position, contin_position,\n",
    "                          disc_logprob, contin_logprob,\n",
    "                          disc_grad_logprob, contin_grad_logprob,\n",
    "                          init_disc_step, init_contin_step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def inference_loop(rng_key, kernel, initial_state, num_samples):\n",
    "    @jax.jit\n",
    "    def one_step(state, rng_key):\n",
    "        state = kernel(rng_key, state)\n",
    "        return state, state\n",
    "\n",
    "    keys = jax.random.split(rng_key, num_samples)\n",
    "    _, states = jax.lax.scan(one_step, initial_state, keys)\n",
    "\n",
    "    return states\n",
    "\n",
    "def inference_loop_multiple_chains(rng_key, kernel, initial_state, num_samples, num_chains):\n",
    "\n",
    "    def one_step(states, rng_key):\n",
    "        keys = jax.random.split(rng_key, num_chains)\n",
    "        states = jax.vmap(kernel)(keys, states)\n",
    "        return states, states\n",
    "\n",
    "    keys = jax.random.split(rng_key, num_samples)\n",
    "    _, states = jax.lax.scan(one_step, initial_state, keys)\n",
    "\n",
    "    return states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def gamma_energy(theta, J, eta, mu):\n",
    "    xg = theta.T @ J\n",
    "    xgx = xg @ theta\n",
    "    return eta*xgx - mu*jnp.sum(theta)\n",
    "\n",
    "def generate_disc_logprob_fn(X, y, J, mu, eta):\n",
    "\n",
    "    def discrete_logprob_fn(gamma, beta):\n",
    "        # beta = pos[\"beta\"]\n",
    "        X_gamma = (X @ jnp.diag(gamma))\n",
    "        ising_logp = gamma_energy(gamma, J, eta, mu)\n",
    "        ll_dist = tfd.Bernoulli(logits=(X_gamma @ beta))\n",
    "        log_ll = jnp.sum(ll_dist.log_prob(y), axis=0)\n",
    "\n",
    "        # print(f\"gamma logp: {ising_logp}, log_ll: {log_ll}\")\n",
    "\n",
    "        return ising_logp + log_ll\n",
    "\n",
    "    return discrete_logprob_fn\n",
    "\n",
    "\n",
    "def generate_contin_logprob_fn(X, y, tau, c):\n",
    "    n, p = X.shape\n",
    "    cov = X.T @ X\n",
    "    R = np.identity(p)\n",
    "    v, l = 1., 1.\n",
    "\n",
    "    def contin_logprob_fn(gamma, beta):\n",
    "        # beta = pos[\"beta\"]\n",
    "\n",
    "        D = (gamma*c*tau) + (1 - gamma)*(tau)\n",
    "        # D_inv = jnp.linalg.inv(jnp.diag(D))\n",
    "\n",
    "        # A = jnp.linalg.inv((1./sigma**2)*cov + (D_inv @ R @ D_inv))\n",
    "        beta_dist = tfd.MultivariateNormalDiag(loc=jnp.zeros(p), scale_diag=D)\n",
    "        # print(beta_dist.sample(seed=rng_key))\n",
    "        beta_logp = beta_dist.log_prob(beta)\n",
    "        X_gamma = (X @ jnp.diag(gamma))\n",
    "        ll_dist = tfd.Bernoulli(logits=(X_gamma @ beta))\n",
    "        log_ll = jnp.sum(ll_dist.log_prob(y), axis=0)\n",
    "\n",
    "        # print(f\"beta logp: {beta_logp}, log_ll: {log_ll}\")\n",
    "\n",
    "        return beta_logp + log_ll\n",
    "\n",
    "    return contin_logprob_fn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       posOutcome        4111        4110       10661         131        4438  \\\ncount  642.000000  642.000000  642.000000  642.000000  642.000000  642.000000   \nmean     0.733645    0.225857    0.450156    0.255452    0.459502    0.367601   \nstd      0.442397    0.418471    0.497897    0.436455    0.498746    0.482528   \nmin      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n50%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n75%      1.000000    0.000000    1.000000    1.000000    1.000000    1.000000   \nmax      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n\n              330        1109        2637        2642  ...        7634  \\\ncount  642.000000  642.000000  642.000000  642.000000  ...  642.000000   \nmean     0.490654    0.311526    0.478193    0.481308  ...    0.404984   \nstd      0.500302    0.463479    0.499914    0.500040  ...    0.491272   \nmin      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n25%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n50%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n75%      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \nmax      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n\n           55769       7637       7644         741      54993      79364  \\\ncount  642.00000  642.00000  642.00000  642.000000  642.00000  642.00000   \nmean     0.50000    0.50000    0.50000    0.356698    0.50000    0.50000   \nstd      0.50039    0.50039    0.50039    0.479398    0.50039    0.50039   \nmin      0.00000    0.00000    0.00000    0.000000    0.00000    0.00000   \n25%      0.00000    0.00000    0.00000    0.000000    0.00000    0.00000   \n50%      0.50000    0.50000    0.50000    0.000000    0.50000    0.50000   \n75%      1.00000    1.00000    1.00000    1.000000    1.00000    1.00000   \nmax      1.00000    1.00000    1.00000    1.000000    1.00000    1.00000   \n\n            7791       23140      26009  \ncount  642.00000  642.000000  642.00000  \nmean     0.50000    0.470405    0.50000  \nstd      0.50039    0.499513    0.50039  \nmin      0.00000    0.000000    0.00000  \n25%      0.00000    0.000000    0.00000  \n50%      0.50000    0.000000    0.50000  \n75%      1.00000    1.000000    1.00000  \nmax      1.00000    1.000000    1.00000  \n\n[8 rows x 8414 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posOutcome</th>\n      <th>4111</th>\n      <th>4110</th>\n      <th>10661</th>\n      <th>131</th>\n      <th>4438</th>\n      <th>330</th>\n      <th>1109</th>\n      <th>2637</th>\n      <th>2642</th>\n      <th>...</th>\n      <th>7634</th>\n      <th>55769</th>\n      <th>7637</th>\n      <th>7644</th>\n      <th>741</th>\n      <th>54993</th>\n      <th>79364</th>\n      <th>7791</th>\n      <th>23140</th>\n      <th>26009</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>642.000000</td>\n      <td>...</td>\n      <td>642.000000</td>\n      <td>642.00000</td>\n      <td>642.00000</td>\n      <td>642.00000</td>\n      <td>642.000000</td>\n      <td>642.00000</td>\n      <td>642.00000</td>\n      <td>642.00000</td>\n      <td>642.000000</td>\n      <td>642.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.733645</td>\n      <td>0.225857</td>\n      <td>0.450156</td>\n      <td>0.255452</td>\n      <td>0.459502</td>\n      <td>0.367601</td>\n      <td>0.490654</td>\n      <td>0.311526</td>\n      <td>0.478193</td>\n      <td>0.481308</td>\n      <td>...</td>\n      <td>0.404984</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.356698</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.470405</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.442397</td>\n      <td>0.418471</td>\n      <td>0.497897</td>\n      <td>0.436455</td>\n      <td>0.498746</td>\n      <td>0.482528</td>\n      <td>0.500302</td>\n      <td>0.463479</td>\n      <td>0.499914</td>\n      <td>0.500040</td>\n      <td>...</td>\n      <td>0.491272</td>\n      <td>0.50039</td>\n      <td>0.50039</td>\n      <td>0.50039</td>\n      <td>0.479398</td>\n      <td>0.50039</td>\n      <td>0.50039</td>\n      <td>0.50039</td>\n      <td>0.499513</td>\n      <td>0.50039</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.000000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.50000</td>\n      <td>0.000000</td>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 8414 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_dir = \"/home/xabush/code/snet/moses-incons-pen-xp/data\"\n",
    "data_dir = \".\"\n",
    "tamox_df = pd.read_csv(f\"{data_dir}/tamoxBinaryEntrez.csv\")\n",
    "tamox_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 372774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50/3470585798.py:1: DtypeWarning: Columns (1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  regnet_df = pd.read_table(f\"{data_dir}/human.source\", sep=\"\\t\", header=None, names= [\"REGULATOR SYMBOL\", \"REGULATOR ID\", \"TARGET SYMBOL\", \"TARGET ID\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": "  REGULATOR SYMBOL REGULATOR ID TARGET SYMBOL TARGET ID\n0             USF1         7391        S100A6      6277\n1             USF1         7391         DUSP1      1843\n2             USF1         7391           C4A       720\n3             USF1         7391         ABCA1        19\n4             TP53         7157          TP73      7161",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>REGULATOR SYMBOL</th>\n      <th>REGULATOR ID</th>\n      <th>TARGET SYMBOL</th>\n      <th>TARGET ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>USF1</td>\n      <td>7391</td>\n      <td>S100A6</td>\n      <td>6277</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>USF1</td>\n      <td>7391</td>\n      <td>DUSP1</td>\n      <td>1843</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USF1</td>\n      <td>7391</td>\n      <td>C4A</td>\n      <td>720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USF1</td>\n      <td>7391</td>\n      <td>ABCA1</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TP53</td>\n      <td>7157</td>\n      <td>TP73</td>\n      <td>7161</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regnet_df = pd.read_table(f\"{data_dir}/human.source\", sep=\"\\t\", header=None, names= [\"REGULATOR SYMBOL\", \"REGULATOR ID\", \"TARGET SYMBOL\", \"TARGET ID\"])\n",
    "print(f\"Total interactions: {regnet_df.shape[0]}\")\n",
    "regnet_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "net_intr = pd.Series(regnet_df[\"REGULATOR ID\"].values, index=regnet_df[\"TARGET ID\"])\n",
    "net_intr_rev = pd.Series(regnet_df[\"TARGET ID\"].values, index=regnet_df[\"REGULATOR ID\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "exp_seeds = []\n",
    "with open(f\"{data_dir}/seeds.txt\", \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        exp_seeds.append(int(line.strip()))\n",
    "\n",
    "print(len(exp_seeds))\n",
    "jax_exp_seeds = []\n",
    "for seed in exp_seeds:\n",
    "    jax_exp_seeds.append(jax.random.PRNGKey(seed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_df, y_df = tamox_df.iloc[:,1:], tamox_df[\"posOutcome\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.        ,  0.1       ,  0.16681005,  0.27825594,  0.46415888,\n        0.77426368,  1.29154967,  2.15443469,  3.59381366,  5.9948425 ,\n       10.        ])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.round(np.linspace(0.1, 0.9, 9), decimals=1)\n",
    "param_vals = np.logspace(-1, 1, 10)\n",
    "param_vals = np.insert(param_vals, 0, 0.)\n",
    "param_vals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def run_exp(X, y, seeds, jax_seeds):\n",
    "\n",
    "    num_samples = 10000\n",
    "    num_chains = 3\n",
    "    burn_in = 0.1\n",
    "    tau, c = 0.01, 1000\n",
    "    disc_step_size = 0.1\n",
    "    contin_step_size = 1e-5\n",
    "\n",
    "    for s, seed in enumerate(seeds):\n",
    "        np.random.seed(seed)\n",
    "        rng_key = jax_seeds[s]\n",
    "        log = setup_logger(f\"{data_dir}/exp_data_3\" ,seed)\n",
    "        start_time = time.time()\n",
    "        log.info(f\"========= Running seed - {seed} =========\")\n",
    "        X_train_sig, X_test_sig, y_train, y_test = prepare_data(seed, X, y, p_val=0.05)\n",
    "        J = build_network(X_train_sig)\n",
    "        p = J.shape[1]\n",
    "        np.fill_diagonal(J, 0.)\n",
    "        log.info(f\"Num of sig feats - {p}\")\n",
    "        beta_dist = tfd.MultivariateNormalDiag(loc=jnp.zeros(p), scale_diag=10 * jnp.ones(p))\n",
    "        gamma_dist = tfd.Bernoulli(probs=0.5 * jnp.ones(p))\n",
    "\n",
    "        res_dict = {\"seed\": [], \"eta\": [], \"mu\": [], \"thres\": [], \"cv_score\": [], \"test_score\": [], \"len\": [], \"num_edges\": [],\n",
    "                    \"beta_cv_score\": [], \"beta_test_score\": [] }\n",
    "\n",
    "        init_beta = beta_dist.sample(seed=rng_key, sample_shape=(num_chains,))\n",
    "        init_gamma = gamma_dist.sample(seed=rng_key, sample_shape=(num_chains,)) * 1.\n",
    "\n",
    "        X_train, X_test = jax.device_put(X_train_sig.to_numpy()), jax.device_put(X_test_sig.to_numpy())\n",
    "        y_train, y_test = jax.device_put(y_train.to_numpy()), jax.device_put(y_test.to_numpy())\n",
    "\n",
    "        for i, eta in enumerate(param_vals):\n",
    "            for j, mu in enumerate(param_vals):\n",
    "                # print(f\"eta - {eta:.2f}, mu - {mu:.2f}\")\n",
    "\n",
    "                contin_init_pos = init_beta\n",
    "                disc_init_pos = init_gamma\n",
    "\n",
    "                disc_logprob = generate_disc_logprob_fn(X_train, y_train, J, mu, eta)\n",
    "                contin_logprob = generate_contin_logprob_fn(X_train, y_train, tau, c)\n",
    "                kernel = jax.jit(lambda key, state: one_step(key, state, disc_logprob, contin_logprob, disc_step_size, contin_step_size))\n",
    "\n",
    "                init_state = jax.vmap(init, in_axes=(0, 0, None, None, None, None))(disc_init_pos, contin_init_pos, disc_logprob,\n",
    "                                                                                    contin_logprob,\n",
    "                                                                                    disc_step_size, contin_step_size)\n",
    "                states = inference_loop_multiple_chains(rng_key, kernel, init_state, num_samples=num_samples, num_chains=num_chains)\n",
    "\n",
    "                gamma_samples = states.discrete_position[int(burn_in*num_samples):]\n",
    "                beta_samples = states.contin_position[int(burn_in*num_samples):]\n",
    "                gamma_samples = gamma_samples.reshape(-1, p)\n",
    "                beta_samples = beta_samples.reshape(-1, p)\n",
    "\n",
    "                for t in thresholds:\n",
    "                    res_dict[\"seed\"].append(seed)\n",
    "                    res_dict[\"eta\"].append(eta)\n",
    "                    res_dict[\"mu\"].append(mu)\n",
    "                    res_dict[\"thres\"].append(t)\n",
    "                    idx = jnp.squeeze(jnp.argwhere((jnp.mean(gamma_samples, axis=0) > t)))\n",
    "\n",
    "                    num_edges = jnp.count_nonzero(J[idx,:][:,idx]) if idx.size > 1 else 0\n",
    "\n",
    "\n",
    "                    res_dict[\"len\"].append(idx.size)\n",
    "                    res_dict[\"num_edges\"].append(num_edges)\n",
    "                    clf = SVC(kernel=\"rbf\", probability=True)\n",
    "                    if idx.size > 0:\n",
    "                        res_idx_df = run_fs_clf(clf, X_train, X_test, y_train, y_test, [idx])\n",
    "\n",
    "                        res_dict[\"cv_score\"].append(res_idx_df[\"cv_score\"][0])\n",
    "                        res_dict[\"test_score\"].append(res_idx_df[\"test_score\"][0])\n",
    "\n",
    "                        beta_sel = jnp.mean(beta_samples[:,idx], axis=0)\n",
    "\n",
    "                        if idx.size == 1:\n",
    "                            beta_sel = beta_sel.reshape(-1, 1)\n",
    "                            X_train_idx_sel = X_train[:,idx].reshape(-1, 1)\n",
    "                            X_test_idx_sel = X_test[:,idx].reshape(-1, 1)\n",
    "\n",
    "                        else:\n",
    "                            X_train_idx_sel = X_train[:,idx]\n",
    "                            X_test_idx_sel = X_test[:,idx]\n",
    "\n",
    "                        train_roc = roc_auc_score(y_train, jax.nn.sigmoid((X_train_idx_sel @ beta_sel)))\n",
    "                        test_roc = roc_auc_score(y_test, jax.nn.sigmoid((X_test_idx_sel @ beta_sel)))\n",
    "                        res_dict[\"beta_cv_score\"].append(train_roc)\n",
    "                        res_dict[\"beta_test_score\"].append(test_roc)\n",
    "\n",
    "                    else:\n",
    "                        res_dict[\"cv_score\"].append(np.nan)\n",
    "                        res_dict[\"test_score\"].append(np.nan)\n",
    "                        res_dict[\"beta_cv_score\"].append(np.nan)\n",
    "                        res_dict[\"beta_test_score\"].append(np.nan)\n",
    "\n",
    "        res_df = pd.DataFrame(res_dict)\n",
    "\n",
    "        res_df.to_csv(f\"{data_dir}/exp_data_3/res_param_seed_{seed}.csv\", index=False)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        log.info(f\"========= Done for seed - {seed} , Elapsed time - {datetime.timedelta(seconds=elapsed_time)} =========\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[919, 256, 206, 507, 98, 97, 675, 539, 425, 233, 781, 886, 837, 350, 482, 503, 713, 950, 947, 337, 5, 356, 38, 210, 359, 67, 61, 499, 925, 506, 805, 490]\n"
     ]
    }
   ],
   "source": [
    "k = 18\n",
    "print(exp_seeds[k:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_seeds = exp_seeds[k:]\n",
    "curr_jax_seeds = jax_exp_seeds[k:]\n",
    "len(curr_seeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:38:40,826 [INFO], ========= Running seed - 919 =========\n",
      "2022-09-21 11:38:46,104 [INFO], Num of sig feats - 1076\n"
     ]
    }
   ],
   "source": [
    "run_exp(X_df, y_df, curr_seeds, curr_jax_seeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}