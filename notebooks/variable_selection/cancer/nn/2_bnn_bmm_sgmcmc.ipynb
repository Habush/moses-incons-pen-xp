{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -U jax[cuda112]==0.3.17 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install -U jaxlib[cuda112]==0.3.17 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install optax\n",
    "!pip install dm-haiku\n",
    "!pip install tensorflow-probability==0.17\n",
    "!pip install lark==1.1.2\n",
    "!pip install git+https://github.com/blackjax-devs/blackjax.git\n",
    "!apt update\n",
    "!apt install -y graphviz\n",
    "!apt-get -y install swig\n",
    "!pip install smac\n",
    "!pip install graphviz\n",
    "!pip install gplearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "SERVER = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not SERVER:\n",
    "    %cd /home/xabush/code/snet/moses-incons-pen-xp/notebooks/variable_selection/cancer/nn\n",
    "import jax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import blackjax\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "tfd = tfp.distributions\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nn_util import *\n",
    "from gibbs_sampler import *\n",
    "plt.style.use('ggplot')\n",
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jax.default_backend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SERVER:\n",
    "    data_dir = \".\"\n",
    "else:\n",
    "    data_dir = \"/home/xabush/code/snet/moses-incons-pen-xp/data\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = 100\n",
    "seeds, data_dfs, net_dfs, feat_ls = load_bmm_files(f\"{data_dir}/bmm_data_thr_5_F_8_f{p}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "seed_idx = 6\n",
    "seed, net, data = prepare_data(seeds, seed_idx, data_dfs, net_dfs, test_size=0.2, out_val_size=0.4)\n",
    "print(f\"seed: {seed}\")\n",
    "X_train, X_out_val, X_test, y_train, y_out_val, y_test = data\n",
    "# X_train, X_out_val, y_train, y_out_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=seed, shuffle=True)\n",
    "X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                   jax.device_put(y_train), jax.device_put(y_test)\n",
    "\n",
    "X_out_val, y_out_val = jax.device_put(X_out_val), jax.device_put(y_out_val)\n",
    "# p = X_train.shape[1]\n",
    "rng_key = jax.random.PRNGKey(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "log_param_grid = {\"C\":np.logspace(-2, 1, 10)}\n",
    "log_grid_cv = GridSearchCV(estimator=LogisticRegression(max_iter=10000), param_grid=log_param_grid, verbose=1, scoring=\"roc_auc\", cv=cv).fit(X_train, y_train)\n",
    "clf = LogisticRegression(max_iter=10000, C=log_grid_cv.best_params_[\"C\"])\n",
    "cv_score = np.mean(cross_val_score(clf, X_train, y_train, scoring=\"roc_auc\", cv=cv))\n",
    "clf.fit(X_train, y_train)\n",
    "test_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "print(f\"cv score: {cv_score}, test_score: {test_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from smac.facade.smac_mf_facade import SMAC4MF\n",
    "from smac.scenario.scenario import Scenario\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "from smac.configspace import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import (\n",
    "    CategoricalHyperparameter,\n",
    "    UniformFloatHyperparameter,\n",
    "    UniformIntegerHyperparameter,\n",
    ")\n",
    "\n",
    "from ConfigSpace import InCondition, Configuration\n",
    "\n",
    "\n",
    "\n",
    "def get_configspace(input_size)-> ConfigurationSpace:\n",
    "    # Build Configuration Space which defines all parameters and their ranges.\n",
    "\n",
    "    if input_size == 100:\n",
    "        layer_dims  = [50, 60, 70, 80]\n",
    "    else:\n",
    "        layer_dims = [250, 300, 350, 400]\n",
    "\n",
    "    cs  = ConfigurationSpace()\n",
    "\n",
    "    layer_dim = CategoricalHyperparameter(\"layer_dim\", layer_dims, default_value=layer_dims[0])\n",
    "    activation = CategoricalHyperparameter(\"activation\", [\"relu\", \"tanh\"], default_value=\"tanh\")\n",
    "    # lr_schedule = CategoricalHyperparameter(\"lr_schedule\", [\"cyclical\"], default_value=\"cyclical\")\n",
    "    disc_lr = CategoricalHyperparameter(\"disc_lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.5] , default_value=1e-1)\n",
    "    contin_lr = CategoricalHyperparameter(\"contin_lr\", [1e-5, 1e-4, 1e-3, 1e-2], default_value=1e-5) #TODO Extend range\n",
    "    # num_cycles = CategoricalHyperparameter(\"num_cycles\", [3, 4, 5], default_value=5)\n",
    "    # beta = CategoricalHyperparameter(\"beta\", [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95], default_value=0.9)\n",
    "    batch_sze = CategoricalHyperparameter(\"batch_size\", [32, 64, 128, 256], default_value=32)\n",
    "    thinning_interval = CategoricalHyperparameter(\"thinning_interval\", [50, 100, 150, 200], default_value=100)\n",
    "    # eta = UniformFloatHyperparameter(\"eta\", lower=0.1, upper=100., log=True)\n",
    "    eta = CategoricalHyperparameter(\"eta\", [0.1, 1., 5, 10., 50., 100.], default_value=1.)\n",
    "    # mu = UniformFloatHyperparameter(\"mu\", lower=0.1, upper=100, log=True)\n",
    "    mu = CategoricalHyperparameter(\"mu\", [0.1, 1., 5, 10., 50., 100.], default_value=1.)\n",
    "    temp = CategoricalHyperparameter(\"temp\", [1e-3, 1e-2, 1e-1, 0.5,  1.], default_value=1e-1)\n",
    "    sigma = CategoricalHyperparameter(\"sigma\", [1e-3, 1e-2, 1e-1, 0.5, 1., 10.], default_value=1.)\n",
    "    # Add hyper-parameters\n",
    "    cs.add_hyperparameters([layer_dim, activation, disc_lr, contin_lr, eta, mu, temp, sigma, batch_sze, thinning_interval])\n",
    "\n",
    "    # # Cyclical SG-MCMC condition\n",
    "    # use_cycle_len = InCondition(child=cycle_len, parent=lr_schedule, values=[\"cyclical\"])\n",
    "    # use_beta = InCondition(child=beta, parent=lr_schedule, values=[\"cyclical\"])\n",
    "    #\n",
    "    # cs.add_conditions([use_cycle_len, use_beta])\n",
    "\n",
    "    return cs\n",
    "\n",
    "def generate_train_cs(seed, X, y):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    # X_tr, X_val, y_tr, y_val = train_test_split(X, y, stratify=y, test_size=0.1, shuffle=seed)\n",
    "    def train_cs(config: Configuration, budget: int)-> float:\n",
    "\n",
    "        params = {\"disc_lr\": config[\"disc_lr\"], \"contin_lr\": config[\"contin_lr\"], \"batch_size\": config[\"batch_size\"],\n",
    "                  \"mu\": config[\"mu\"], \"eta\": config[\"eta\"], \"temp\": config[\"temp\"],\n",
    "                  \"sigma\": config[\"sigma\"], \"thinning_interval\": config[\"thinning_interval\"]}\n",
    "\n",
    "        # print(params)\n",
    "\n",
    "        mixed_sgmcmc = MixedSGMCMC(seed=seed, n_samples=budget, n_warmup=1000, lr_schedule=\"exponential\",\n",
    "                            n_chains=5, layer_dims=[config[\"layer_dim\"]], **params)\n",
    "\n",
    "        cv_score_1 = np.mean(cross_val_score(mixed_sgmcmc, X, y,  cv=cv, fit_params={\n",
    "            \"activation_fns\": [config[\"activation\"]], \"J\": net\n",
    "        }))\n",
    "\n",
    "\n",
    "        # mixed_sgmcmc.fit(X_tr, y_tr, activation_fns=[config[\"activation\"]], J=net)\n",
    "        # gamma_means = jnp.mean(jnp.mean(mixed_sgmcmc.states_.discrete_position, axis=0), axis=0)\n",
    "        # gamma_means_idx_s = np.argsort(gamma_means)[::-1]\n",
    "        #\n",
    "        # bnn_sel_fts = gamma_means_idx_s[:ft_len]\n",
    "        # #\n",
    "        # X_tr_sel, X_val_sel = X_tr[:,bnn_sel_fts], X_val[:,bnn_sel_fts]\n",
    "        #\n",
    "        # _, _, val_score = run_logistic_regression(X_tr_sel, X_val_sel, y_tr, y_val, cv, verbose=0)\n",
    "\n",
    "        return 1 - (cv_score_1)\n",
    "\n",
    "\n",
    "    return train_cs\n",
    "\n",
    "\n",
    "def optimize_hyper_parameters(seed, X, y, total_time=60):\n",
    "    cs = get_configspace(X.shape[1])\n",
    "    scenario = Scenario({\n",
    "        \"run_obj\": \"quality\",\n",
    "        \"wallclock-limit\": total_time,\n",
    "        \"cs\": cs,\n",
    "        \"deterministic\": True,\n",
    "        \"cutoff\": 10,  # runtime limit for the target algorithm\n",
    "        \"verbose_level\": \"DEBUG\", \n",
    "        \"seed\": seed\n",
    "    })\n",
    "\n",
    "    max_steps = 5000\n",
    "\n",
    "    train_cs = generate_train_cs(seed, X, y)\n",
    "\n",
    "    intensifier_kwargs = {\"initial_budget\": 1500, \"max_budget\": max_steps}\n",
    "\n",
    "    smac = SMAC4MF(scenario=scenario, rng=np.random.RandomState(seed),\n",
    "                   tae_runner=train_cs, intensifier_kwargs=intensifier_kwargs)\n",
    "\n",
    "    tae = smac.get_tae_runner()\n",
    "\n",
    "    try:\n",
    "        incumbent = smac.optimize()\n",
    "\n",
    "    finally:\n",
    "        incumbent = smac.solver.incumbent\n",
    "\n",
    "\n",
    "    inc_val = tae.run(config=incumbent, budget=max_steps, seed=seed)\n",
    "\n",
    "    return incumbent, 1 - inc_val[1], smac\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                   jax.device_put(y_train), jax.device_put(y_test)\n",
    "p = X_train.shape[1]\n",
    "rng_key = jax.random.PRNGKey(seed)\n",
    "config, cv_score, smac = optimize_hyper_parameters(seed, X_train, y_train, total_time=180)\n",
    "cv_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smac.get_trajectory()[-1].budget"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sgmcmc import MixedSGMCMC\n",
    "params = {\"disc_lr\": config[\"disc_lr\"], \"contin_lr\": config[\"contin_lr\"], \"batch_size\": config[\"batch_size\"],\n",
    "          \"mu\": config[\"mu\"], \"eta\": config[\"eta\"], \"temp\": config[\"temp\"],\n",
    "          \"sigma\":config[\"sigma\"], \"thinning_interval\": config[\"thinning_interval\"]}\n",
    "\n",
    "mixed_sgmcmc = MixedSGMCMC(seed=seed, n_samples=2000, n_warmup=500, n_chains=5, lr_schedule=\"exponential\",\n",
    "                     layer_dims=[config[\"layer_dim\"]], **params)\n",
    "\n",
    "# cv_score_bnn = np.mean(cross_val_score(mixed_sgmcmc, X_train, y_train,  cv=cv, fit_params={\n",
    "#             \"activation_fns\": [config[\"activation\"]], \"J\": net\n",
    "#         }))\n",
    "# print(cv_score_bnn)\n",
    "mixed_sgmcmc.fit(X_train, y_train, activation_fns=[config[\"activation\"]], J=net)\n",
    "print(f\"Num models: {mixed_sgmcmc.states_.discrete_position.shape[0]}\")\n",
    "test_score_bnn = mixed_sgmcmc.score(X_test, y_test)\n",
    "\n",
    "print(test_score_bnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "disc_states = mixed_sgmcmc.states_.discrete_position.reshape(mixed_sgmcmc.n_chains, -1,\n",
    "                                         mixed_sgmcmc.states_.discrete_position.shape[-1])\n",
    "contin_states = jax.tree_util.tree_map(lambda x: jnp.moveaxis(x.reshape(mixed_sgmcmc.n_chains, -1, x.shape[-1]), 0, 1), mixed_sgmcmc.states_.contin_position)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contin_states = tree_utils.tree_unstack(mixed_sgmcmc.states_.contin_position)\n",
    "disc_states = mixed_sgmcmc.states_.discrete_position\n",
    "\n",
    "disc_logprior_fn = generate_disc_logprior_fn(net, mixed_sgmcmc.eta, mixed_sgmcmc.mu)\n",
    "contin_logprior_fn = generate_contin_logprior_fn(mixed_sgmcmc.sigma)\n",
    "\n",
    "contin_log_probs = []\n",
    "disc_log_probs = []\n",
    "log_lls = []\n",
    "\n",
    "for c in range(mixed_sgmcmc.n_chains):\n",
    "    chain_disc_log_probs = []\n",
    "    chain_contin_log_probs = []\n",
    "    for i in range(len(mixed_sgmcmc.disc_states[c])):\n",
    "        # idxs = jax.random.choice(keys[i], jnp.arange(data_size), (32,), replace=False)\n",
    "        # batches = make_batch(idxs, train_data.x, train_data.y)\n",
    "        chain_disc_log_probs.append(disc_logprior_fn(mixed_sgmcmc.disc_states[c][i]))\n",
    "        chain_contin_log_probs.append(contin_logprior_fn(mixed_sgmcmc.contin_states[c][i]))\n",
    "\n",
    "    disc_log_probs.append(chain_disc_log_probs)\n",
    "    contin_log_probs.append(chain_contin_log_probs)\n",
    "    # log_lls.append(mixed_loglikelihood_fn(sgmcmc.model_, sgmcmc.contin_states[i], batches, sgmcmc.disc_states[i]))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))\n",
    "\n",
    "for c in range(mixed_sgmcmc.n_chains):\n",
    "    ax1.plot(disc_log_probs[c], label=f\"chain {c + 1} Disc logprob\")\n",
    "    ax2.plot(contin_log_probs[c], label=f\"chain {c + 1} Contin logprob\")\n",
    "# ax2[0].plot(log_lls, label=f\"log LL\")\n",
    "\n",
    "ax1.set_title(f\"Disc lr: {config_1['disc_lr']:.3f}\")\n",
    "ax2.set_title(f\"Contin lr: {config_1['contin_lr']:.5f}\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gamma_means = jnp.mean(mixed_sgmcmc.states_.discrete_position, axis=0)\n",
    "gamma_means_idx_s = np.argsort(gamma_means)[::-1]\n",
    "plt.hist(gamma_means)\n",
    "plt.xlabel(\"frequency\")\n",
    "plt.ylabel(\"num features\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tqdm import tqdm\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "\n",
    "X, y = data_dfs[seed_idx].iloc[:,:-1].to_numpy().astype(float), \\\n",
    "       data_dfs[seed_idx].iloc[:,-1].to_numpy().astype(float)\n",
    "\n",
    "net = net_dfs[seed_idx].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True, stratify=y, test_size=0.3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                   jax.device_put(y_train), jax.device_put(y_test)\n",
    "\n",
    "\n",
    "rand_v_bnn_sel_fts_dict = {\"seed\": [], \"feat_sel\": [], \"num_feats\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "all_feats = np.arange(p - 1)\n",
    "\n",
    "feat_lens = [5, 10, 15]\n",
    "\n",
    "cv = StratifiedKFold(random_state=seed, shuffle=True, n_splits=5)\n",
    "log_best_params, _, _ = run_logistic_regression(X_train, X_test, y_train, y_test, cv, verbose=0)\n",
    "print(log_best_params)\n",
    "log_clf = LogisticRegression(max_iter=10000, **log_best_params)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "log_coef = log_clf.coef_[0]\n",
    "\n",
    "log_coef_sorted = np.argsort(log_coef)[::-1]\n",
    "\n",
    "# # print(gamma_means)\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True, stratify=y, test_size=0.3)\n",
    "\n",
    "rng_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "for ft_len in feat_lens:\n",
    "    # rand_sel_fts = jax.random.choice(rng_key, all_feats, (ft_len,), replace=False)\n",
    "    #\n",
    "    # X_train_rand_sel, X_test_rand_sel = X_train[:,rand_sel_fts], X_test[:,rand_sel_fts]\n",
    "    #\n",
    "    # _, rand_cv_score, rand_test_score = run_logistic_regression(X_train_rand_sel, X_test_rand_sel,\n",
    "    #                                                            y_train, y_test, cv, verbose=0)\n",
    "    #\n",
    "    # log_sel_fts = log_coef_sorted[:ft_len]\n",
    "    #\n",
    "    # X_train_log_sel, X_test_log_sel, = X_train[:,log_sel_fts], X_test[:,log_sel_fts]\n",
    "    #\n",
    "    # _, log_cv_score, log_test_score = run_logistic_regression(X_train_log_sel, X_test_log_sel,\n",
    "    #                                                          y_train, y_test, cv, verbose=0)\n",
    "\n",
    "    bnn_sel_fts = gamma_means_idx_s[:ft_len]\n",
    "\n",
    "    X_train_sel, X_test_sel = X_train[:,bnn_sel_fts], X_test[:,bnn_sel_fts]\n",
    "\n",
    "    _, bnn_cv_score, bnn_test_score = run_logistic_regression(X_train_sel, X_test_sel,\n",
    "                                                     y_train, y_test, cv, verbose=0)\n",
    "\n",
    "    # rand_v_bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "    # rand_v_bnn_sel_fts_dict[\"feat_sel\"].append(\"random\")\n",
    "    # rand_v_bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "    # rand_v_bnn_sel_fts_dict[\"cv_score\"].append(rand_cv_score)\n",
    "    # rand_v_bnn_sel_fts_dict[\"test_score\"].append(rand_test_score)\n",
    "\n",
    "\n",
    "    rand_v_bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "    rand_v_bnn_sel_fts_dict[\"feat_sel\"].append(\"bnn\")\n",
    "    rand_v_bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "    rand_v_bnn_sel_fts_dict[\"cv_score\"].append(bnn_cv_score)\n",
    "    rand_v_bnn_sel_fts_dict[\"test_score\"].append(bnn_test_score)\n",
    "\n",
    "        # rand_v_bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        # rand_v_bnn_sel_fts_dict[\"feat_sel\"].append(\"lr\")\n",
    "        # rand_v_bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        # # rand_v_bnn_sel_fts_dict[\"kernel\"].append(svm_log_params[\"kernel\"])\n",
    "        # rand_v_bnn_sel_fts_dict[\"cv_score\"].append(log_cv_score)\n",
    "        # rand_v_bnn_sel_fts_dict[\"test_score\"].append(log_test_score)\n",
    "\n",
    "\n",
    "rand_v_bnn_sel_fts_df = pd.DataFrame(rand_v_bnn_sel_fts_dict)\n",
    "rand_v_bnn_sel_fts_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variable Elimination"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_bnn(model, X, y, params, gammas):\n",
    "    eval_fn = lambda p, g: model.apply(p, X, g).ravel()\n",
    "    logits = jax.vmap(eval_fn)(params, gammas)\n",
    "    logits = logits.reshape(-1, logits.shape[-1])\n",
    "    losses = jax.vmap(optax.sigmoid_binary_cross_entropy, in_axes=(0, None))(logits, y)\n",
    "    mean_loss = jnp.mean(losses, axis=-1)\n",
    "    return jnp.sum(mean_loss)\n",
    "\n",
    "def get_feats_dropout_loss(sgmcmc, X, y):\n",
    "    var_loss_dict = {\"feats_idx\": [], \"num_models\": [] , \"loss_on\": [], \"loss_off\": [], \"loss_diff\": []}\n",
    "    # disc_states = sgmcmc.states_.discrete_position.reshape(-1, sgmcmc.states_.discrete_position.shape[-1])\n",
    "    disc_states = sgmcmc.states_.discrete_position\n",
    "    contin_states = tree_utils.tree_unstack(sgmcmc.states_.contin_position)\n",
    "\n",
    "    num_models = disc_states.shape[0]\n",
    "\n",
    "    p = X.shape[1]\n",
    "\n",
    "    for idx in range(p):\n",
    "        # idx = feats_idx[i]\n",
    "        idx_on = np.argwhere(disc_states[:,idx] == 1.).ravel()\n",
    "        loss_on, loss_off = 0., 0.\n",
    "        if idx_on.size == 0: ## irrelevant feature\n",
    "            loss_diff = 1e9\n",
    "        else:\n",
    "            disc_states_on = disc_states[idx_on]\n",
    "            if idx_on.size > 1:\n",
    "                params_on = tree_utils.tree_stack(itemgetter(*idx_on)(contin_states))\n",
    "            else:\n",
    "                params_on = tree_utils.tree_stack([contin_states[idx_on[0]]])\n",
    "            loss_on = evaluate_bnn(sgmcmc.model_, X, y, params_on, disc_states_on)\n",
    "\n",
    "            # Turn-off the variable, and see hwo the loss changes\n",
    "            disc_states_off = disc_states_on.at[:,idx].set(0)\n",
    "            loss_off = evaluate_bnn(sgmcmc.model_, X, y, params_on, disc_states_off)\n",
    "\n",
    "            loss_diff = (loss_on - loss_off) * (len(idx_on) / num_models)\n",
    "\n",
    "\n",
    "        var_loss_dict[\"feats_idx\"].append(idx)\n",
    "        var_loss_dict[\"num_models\"].append(idx_on.size)\n",
    "        var_loss_dict[\"loss_on\"].append(loss_on)\n",
    "        var_loss_dict[\"loss_off\"].append(loss_off)\n",
    "        var_loss_dict[\"loss_diff\"].append(loss_diff)\n",
    "\n",
    "\n",
    "    var_loss_df = pd.DataFrame(var_loss_dict).sort_values(by=\"loss_diff\")\n",
    "\n",
    "    return var_loss_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir_100 = f\"{data_dir}/exp_data_4/bmm/f100\"\n",
    "dropout_loss_df = pd.read_csv(f\"{save_dir_100}/drop_out_loss_s_{seed}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout_loss_df = get_feats_dropout_loss(mixed_sgmcmc, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout_loss_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_fts = 5\n",
    "X_out_val_sel, X_test_sel = X_out_val[:,log_coef_sorted[:num_fts]], X_test[:,log_coef_sorted[:num_fts]]\n",
    "\n",
    "_, val_score, test_score = run_logistic_regression(X_out_val_sel, X_test_sel, y_out_val, y_test, cv)\n",
    "print(val_score)\n",
    "print(test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_coef_sorted[:num_fts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "feats_sel = dropout_loss_df[\"feats_idx\"][:num_fts].to_list()\n",
    "\n",
    "X_train_val_comb, X_test_sel = np.concatenate([X_train, X_out_val], axis=0)[:,feats_sel], X_test[:,feats_sel]\n",
    "y_train_val_comb = np.concatenate([y_train, y_out_val], axis=0)\n",
    "\n",
    "_, val_score, test_score = run_logistic_regression(X_train_val_comb, X_test_sel, y_train_val_comb, y_test, cv)\n",
    "print(val_score)\n",
    "print(test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feats_sel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GP Learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ft_len = 20\n",
    "# sel_idx = gamma_means_idx_s[:feats_sel]\n",
    "# sel_idx = log_coef_sorted[:ft_len]\n",
    "X_gp_train, X_gp_val, X_gp_test = X_out_val[:,feats_sel].astype(int), X_train[:,feats_sel].astype(int), X_test[:,feats_sel].astype(int)\n",
    "X_gp_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer, SymbolicClassifier\n",
    "from gplearn.functions import make_function\n",
    "import operator\n",
    "\n",
    "\n",
    "def get_best_programs(gp, num_models, ascending=True, sort_fit=\"OOB_fitness\"):\n",
    "    gp_dict = {'Gen': [], \"Ind\": [], \"Fitness\": [], 'OOB_fitness': []}\n",
    "\n",
    "    for idGen in range(len(gp._programs)):\n",
    "        for idPopulation in range(gp.population_size):\n",
    "            if (gp._programs[idGen][idPopulation] != None):\n",
    "                gp_dict[\"Gen\"].append(idGen)\n",
    "                gp_dict[\"Ind\"].append(idPopulation)\n",
    "                gp_dict[\"Fitness\"].append(gp._programs[idGen][idPopulation].fitness_)\n",
    "                gp_dict[\"OOB_fitness\"].append(gp._programs[idGen][idPopulation].oob_fitness_)\n",
    "\n",
    "    gp_df = pd.DataFrame(gp_dict).sort_values(sort_fit, ascending=ascending)[:num_models]\n",
    "    programs = []\n",
    "    for i in range(num_models):\n",
    "        gen, ind = int(gp_df.iloc[i][\"Gen\"]), int(gp_df.iloc[i][\"Ind\"])\n",
    "        programs.append(gp._programs[gen][ind])\n",
    "\n",
    "    return programs\n",
    "\n",
    "\n",
    "def gp_transform(est, X, classifier=False, num_models=100, sort_fit=\"Fitness\"):\n",
    "    if classifier:\n",
    "        programs = get_best_programs(gp, num_models, classifier, sort_fit)\n",
    "        out = np.zeros((X.shape[0], len(programs)))\n",
    "        for i, prog in enumerate(programs):\n",
    "            out[:, i] = prog.execute(X)\n",
    "\n",
    "        return out\n",
    "\n",
    "    return est.transform(X)\n",
    "\n",
    "\n",
    "function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                'abs', 'neg', 'inv', 'max', 'min']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def and_(x1, x2):\n",
    "    return np.logical_and(x1, x2)\n",
    "\n",
    "def or_(x1, x2):\n",
    "    return np.logical_or(x1, x2)\n",
    "\n",
    "def xor_(x1, x2):\n",
    "    return np.logical_xor(x1, x2)\n",
    "\n",
    "def not_(x1):\n",
    "    return np.logical_not(x1)\n",
    "\n",
    "# def if_else_then(x1, x2, x3):\n",
    "#     if x1: return x2\n",
    "#     return x3\n",
    "\n",
    "# and_op = make_function(function=and_, name=\"and_\", arity=2)\n",
    "# or_op = make_function(function=or_, name=\"or_\", arity=2)\n",
    "# xor_op = make_function(function=xor_, name=\"xor_\", arity=2)\n",
    "# not_op = make_function(function=not_, name=\"not_\", arity=1)\n",
    "# if_else_op = make_function(function=if_else_then, name=\"if_else_\", arity=3)\n",
    "\n",
    "# function_set = [and_op, or_op, xor_op, not_op]\n",
    "\n",
    "# gp = SymbolicTransformer(generations=500, population_size=1000, hall_of_fame=100, n_components=10,\n",
    "#                          function_set=function_set, parsimony_coefficient=0.003,\n",
    "#                          random_state=seed, max_samples=0.8, verbose=1,\n",
    "#                          p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.01,\n",
    "#                          p_point_mutation=0.1, p_point_replace=0.05, metric=\"spearman\")\n",
    "\n",
    "gp = SymbolicClassifier(generations=500, population_size=1000,\n",
    "                         function_set=function_set, parsimony_coefficient=0.001,\n",
    "                         random_state=seed, max_samples=0.8, verbose=1,\n",
    "                         p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.01,\n",
    "                         p_point_mutation=0.1, p_point_replace=0.05)\n",
    "\n",
    "gp.fit(X_gp_train, y_out_val)\n",
    "\n",
    "gp_features_val = gp_transform(gp, X_gp_val, classifier=True, sort_fit=\"Fitness\")\n",
    "gp_features_test = gp_transform(gp, X_gp_test, classifier=True, sort_fit=\"Fitness\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = gp._programs[-1][0].export_graphviz()\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    " \n",
    "X_val_comb, X_test_comb = np.concatenate([X_gp_val, gp_features_val], axis=1), np.concatenate([X_gp_test, gp_features_test], axis=1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "log_best_param_1, log_cv_score_1, log_test_score_1 = run_logistic_regression(X_val_comb, X_test_comb, y_train,\n",
    "                                                                             y_test, cv)\n",
    "print(f\"Param: {log_best_param_1}, cv_score: {log_cv_score_1}, test_score: {log_test_score_1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gp_df_sorted = gp_df.sort_values('Fitness', ascending=True)[:5]\n",
    "gp_df_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_row = gp_df_sorted.iloc[2]\n",
    "program = gp._programs[int(top_row[\"Gen\"])][int(top_row[\"Ind\"])]\n",
    "dot_data = program.export_graphviz()\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "\n",
    "gp_features_val = np.zeros((X_gp_val.shape[0], gp_df_sorted.shape[0]))\n",
    "gp_features_test = np.zeros((X_gp_test.shape[0], gp_df_sorted.shape[0]))\n",
    "\n",
    "for i in range(gp_df_sorted.shape[0]):\n",
    "    row = gp_df_sorted.iloc[i]\n",
    "    gen, ind = row[\"Gen\"], row[\"Ind\"]\n",
    "    prog = gp._programs[gen][ind]\n",
    "    val_out = prog.execute(X_gp_val)\n",
    "    test_out = prog.execute(X_gp_test)\n",
    "\n",
    "    gp_features_val[:,i] = val_out\n",
    "    gp_features_test[:,i] = test_out\n",
    "\n",
    "X_val_comb, X_test_comb = np.concatenate([X_gp_val, gp_features_val], axis=1), np.concatenate([X_gp_test, gp_features_test], axis=1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "log_best_param_1, log_cv_score_1, log_test_score_1 = run_logistic_regression(X_val_comb, X_test_comb, y_train,\n",
    "                                                                            y_test, cv)\n",
    "print(f\"Param: {log_best_param_1}, cv_score: {log_cv_score_1}, test_score: {log_test_score_1}\")\n",
    "# clf_1 = LogisticRegression(max_iter=10000, **log_best_param_1)\n",
    "# clf_1.fit(X_train_comb, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gp_features_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple Runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BNN Runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from nn_util import prepare_data\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "save_dir_100 = f\"{data_dir}/exp_data_4/bmm/f100\"\n",
    "\n",
    "bnn_lr_dict_100 = {\"seed\": [], \"classifier\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "log_param_grid = {\"C\":np.logspace(-2, 1, 10)}\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    seed, net, data = prepare_data(seeds, i, data_dfs, net_dfs, test_size=0.3, out_val_size=0.5)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    print(f\"Running - seed {seed}\")\n",
    "\n",
    "    X_train, _, X_test, y_train, _, y_test = data\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                       jax.device_put(y_train), jax.device_put(y_test)\n",
    "\n",
    "\n",
    "    log_grid_cv = GridSearchCV(estimator=LogisticRegression(max_iter=10000), param_grid=log_param_grid, verbose=0, scoring=\"roc_auc\", cv=cv).fit(X_train, y_train)\n",
    "    log_cv_score = log_grid_cv.best_score_\n",
    "    clf = LogisticRegression(max_iter=10000, C=log_grid_cv.best_params_[\"C\"])\n",
    "    clf.fit(X_train, y_train)\n",
    "    log_test_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    config, bnn_cv_score, _ = optimize_hyper_parameters(seed, X_train, y_train, total_time=180)\n",
    "    # config = pickle.load(open(f\"{save_dir_100}/bnn_params_s_{seed}.pickle\", \"rb\"))\n",
    "\n",
    "    params = {\"disc_lr\": config[\"disc_lr\"], \"contin_lr\": config[\"contin_lr\"], \"batch_size\": config[\"batch_size\"],\n",
    "              \"mu\": config[\"mu\"], \"eta\": config[\"eta\"], \"temp\": config[\"temp\"],\n",
    "              \"sigma\": config[\"sigma\"], \"thinning_interval\": config[\"thinning_interval\"]}\n",
    "\n",
    "    mixed_sgmcmc = MixedSGMCMC(seed=seed, n_samples=5000, n_warmup=1000, n_chains=5, lr_schedule=\"exponential\",\n",
    "                     layer_dims=[config[\"layer_dim\"]] ,**params)\n",
    "\n",
    "    # bnn_cv_score = np.mean(cross_val_score(mixed_sgmcmc, X_train, y_train, cv=cv,\n",
    "    #                                        fit_params={\"activation_fns\": [config[\"activation\"]],  \"J\": net}))\n",
    "\n",
    "    mixed_sgmcmc.fit(X_train, y_train, activation_fns=[config[\"activation\"]], J=net)\n",
    "\n",
    "    pickle.dump(config, open(f\"{save_dir_100}/bnn_params_s_{seed}.pickle\", \"wb\"))\n",
    "\n",
    "    bnn_test_score = mixed_sgmcmc.score(X_test, y_test)\n",
    "\n",
    "    bnn_disc_mean = jnp.mean(mixed_sgmcmc.states_.discrete_position.reshape(-1, X_train.shape[1]), axis=0)\n",
    "    np.save(f\"{save_dir_100}/bnn_disc_mean_s_{seed}.npy\", bnn_disc_mean)\n",
    "\n",
    "\n",
    "    bnn_lr_dict_100[\"seed\"].append(seed)\n",
    "    bnn_lr_dict_100[\"classifier\"].append(\"LR\")\n",
    "    bnn_lr_dict_100[\"cv_score\"].append(log_cv_score)\n",
    "    bnn_lr_dict_100[\"test_score\"].append(log_test_score)\n",
    "\n",
    "    bnn_lr_dict_100[\"seed\"].append(seed)\n",
    "    bnn_lr_dict_100[\"classifier\"].append(\"BNN\")\n",
    "    bnn_lr_dict_100[\"cv_score\"].append(bnn_cv_score)\n",
    "    bnn_lr_dict_100[\"test_score\"].append(bnn_test_score)\n",
    "\n",
    "    print(f\"Config: {config}\")\n",
    "\n",
    "    print(f\"Done - seed {seed}\\nLR cv_score: {log_cv_score}, LR test_score: {log_test_score}\")\n",
    "    print(f\"BNN cv_score: {bnn_cv_score}, BNN test_score: {bnn_test_score}\")\n",
    "\n",
    "bnn_lr_df_100 = pd.DataFrame(bnn_lr_dict_100)\n",
    "bnn_lr_df_100.to_csv(f\"{save_dir_100}/res_bmm_summary.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bnn_lr_df.to_csv(f\"{save_dir}/res_bmm_summary.csv\", index=False)\n",
    "bnn_lr_df_100 = pd.read_csv(f\"{data_dir}/exp_data_4/bmm/f100/res_bmm_summary.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_lr_df_100.groupby([\"classifier\"])[[\"cv_score\", \"test_score\"]].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Variable Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from tqdm import tqdm\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "import pickle\n",
    "save_dir_100 = f\"{data_dir}/exp_data_4/bmm/f100\"\n",
    "bnn_sel_fts_dict = {\"seed\": [], \"feat_sel\": [], \"num_feats\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "all_feats = np.arange(p - 1)\n",
    "\n",
    "feat_lens = [5, 10]\n",
    "\n",
    "for i in tqdm(range(len(seeds))):\n",
    "\n",
    "    seed, net, data = prepare_data(seeds, i, data_dfs, net_dfs, test_size=0.3)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    X_train, X_out_val, X_test, y_train, y_out_val, y_test = data\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                       jax.device_put(y_train), jax.device_put(y_test)\n",
    "\n",
    "    X_train_val_comb, y_train_val_comb = np.concatenate([X_train, X_out_val], axis=0), np.concatenate([y_train, y_out_val], axis=0)\n",
    "\n",
    "    log_best_params, _, _ = run_logistic_regression(X_train, X_test, y_train, y_test, cv, verbose=0)\n",
    "    log_clf = LogisticRegression(max_iter=10000, **log_best_params)\n",
    "    log_clf.fit(X_train, y_train)\n",
    "\n",
    "    log_coef = log_clf.coef_[0]\n",
    "\n",
    "    log_coef_sorted = np.argsort(log_coef)[::-1]\n",
    "\n",
    "\n",
    "    config = pickle.load(open(f\"{save_dir_100}/bnn_params_s_{seed}.pickle\", \"rb\"))\n",
    "    params = {\"disc_lr\": config[\"disc_lr\"], \"contin_lr\": config[\"contin_lr\"], \"batch_size\": config[\"batch_size\"],\n",
    "              \"mu\": config[\"mu\"], \"eta\": config[\"eta\"], \"temp\": config[\"temp\"],\n",
    "              \"sigma\": config[\"sigma\"], \"thinning_interval\": config[\"thinning_interval\"]}\n",
    "\n",
    "    mixed_sgmcmc = MixedSGMCMC(seed=seed, n_samples=5000, n_warmup=1000, n_chains=5, lr_schedule=\"exponential\",\n",
    "                     layer_dims=[config[\"layer_dim\"]] ,**params)\n",
    "\n",
    "    # bnn_cv_score = np.mean(cross_val_score(mixed_sgmcmc, X_train, y_train, cv=cv,\n",
    "    #                                        fit_params={\"activation_fns\": [config[\"activation\"]],  \"J\": net}))\n",
    "\n",
    "    mixed_sgmcmc.fit(X_train, y_train, activation_fns=[config[\"activation\"]], J=net)\n",
    "\n",
    "    gamma_means = jnp.mean(mixed_sgmcmc.states_.discrete_position.reshape(-1, X_train.shape[1]), axis=0)\n",
    "    gamma_means_idx_s = np.argsort(gamma_means)[::-1]\n",
    "\n",
    "    dropout_loss_df = get_feats_dropout_loss(mixed_sgmcmc, X_train, y_train)\n",
    "    dropout_loss_df.to_csv(f\"{save_dir_100}/drop_out_loss_s_{seed}.csv\", index=False)\n",
    "\n",
    "    for ft_len in feat_lens:\n",
    "\n",
    "        log_sel_fts = log_coef_sorted[:ft_len]\n",
    "\n",
    "        X_train_log_sel, X_test_log_sel, = X_train[:,log_sel_fts], X_test[:,log_sel_fts]\n",
    "\n",
    "        _, log_cv_score, log_test_score = run_logistic_regression(X_train_log_sel, X_test_log_sel,\n",
    "                                                                 y_train, y_test, cv, verbose=0)\n",
    "\n",
    "        bnn_mean_sel = gamma_means_idx_s[:ft_len]\n",
    "\n",
    "        X_train_sel_1, X_test_sel_1 = X_train_val_comb[:,bnn_mean_sel], X_test[:,bnn_mean_sel]\n",
    "\n",
    "        _, bnn_cv_score_1, bnn_test_score_1 = run_logistic_regression(X_train_sel_1, X_test_sel_1,\n",
    "                                                                  y_train_val_comb, y_test, cv, verbose=0)\n",
    "\n",
    "\n",
    "        bnn_dropout_sel = dropout_loss_df[\"feats_idx\"][:ft_len].to_list()\n",
    "\n",
    "        X_train_sel_2, X_test_sel_2 = X_train_val_comb[:,bnn_dropout_sel], X_test[:,bnn_dropout_sel]\n",
    "\n",
    "        _, bnn_cv_score_2, bnn_test_score_2 = run_logistic_regression(X_train_sel_2, X_test_sel_2,\n",
    "                                                                      y_train_val_comb, y_test, cv, verbose=0)\n",
    "\n",
    "\n",
    "        bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        bnn_sel_fts_dict[\"feat_sel\"].append(\"bnn_mean\")\n",
    "        bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        bnn_sel_fts_dict[\"cv_score\"].append(bnn_cv_score_1)\n",
    "        bnn_sel_fts_dict[\"test_score\"].append(bnn_test_score_1)\n",
    "\n",
    "        bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        bnn_sel_fts_dict[\"feat_sel\"].append(\"bnn_dropout\")\n",
    "        bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        bnn_sel_fts_dict[\"cv_score\"].append(bnn_cv_score_2)\n",
    "        bnn_sel_fts_dict[\"test_score\"].append(bnn_test_score_2)\n",
    "\n",
    "        bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        bnn_sel_fts_dict[\"feat_sel\"].append(\"lr\")\n",
    "        bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        bnn_sel_fts_dict[\"cv_score\"].append(log_cv_score)\n",
    "        bnn_sel_fts_dict[\"test_score\"].append(log_test_score)\n",
    "\n",
    "\n",
    "bnn_sel_fts_df = pd.DataFrame(bnn_sel_fts_dict)\n",
    "bnn_sel_fts_df.to_csv(f\"{save_dir_100}/bnn_sel_feats_comparison.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_sel_fts_df = pd.read_csv(f\"{save_dir_100}/bnn_sel_feats_comparison.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_sel_fts_df.groupby([\"feat_sel\", \"num_feats\"])[[\"cv_score\", \"test_score\"]].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_mean_5_cv_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_mean\") & (bnn_sel_fts_df[\"num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "bnn_dropout_5_cv_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_dropout\") & (bnn_sel_fts_df[\"num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_mean_5_test_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_mean\") & (bnn_sel_fts_df[\"num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "bnn_dropout_5_test_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_dropout\") & (bnn_sel_fts_df[\"num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"mean freq\", \"ens dropout\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_mean_5_cv_fts, bnn_dropout_5_cv_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_mean_5_test_fts, bnn_dropout_5_test_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 5/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "plt.legend([bplot2['medians'][0], bplot2['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_mean_10_cv_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_mean\") & (bnn_sel_fts_df[\"num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "bnn_dropout_10_cv_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_dropout\") & (bnn_sel_fts_df[\"num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_mean_10_test_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_mean\") & (bnn_sel_fts_df[\"num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "bnn_dropout_10_test_fts = bnn_sel_fts_df[(bnn_sel_fts_df[\"feat_sel\"] == \"bnn_dropout\") & (bnn_sel_fts_df[\"num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"mean freq\", \"ens dropout\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.grid(color='grey', axis='y', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "ax2.grid(color='grey', axis='y', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_mean_10_cv_fts, bnn_dropout_10_cv_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_mean_10_test_fts, bnn_dropout_10_test_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 10/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_sel_fts_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_dir_100 = f\"{data_dir}/exp_data_4/bmm/f100\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer, SymbolicClassifier\n",
    "from gplearn.functions import make_function\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "from run_nn_fisher_test_exp import run_logistic_regression\n",
    "\n",
    "function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                'abs', 'neg', 'inv', 'max', 'min']\n",
    "\n",
    "bnn_gp_dict = {\"seed\": [], \"orig_num_feats\": [], \"gp_num_feats\": [] ,\"classifier\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "feat_lens = [5, 10]\n",
    "\n",
    "num_models = [5, 10, 20, 50]\n",
    "\n",
    "for i in tqdm(range(len(seeds))):\n",
    "\n",
    "    seed, net, data = prepare_data(seeds, i, data_dfs, net_dfs, test_size=0.3)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    X_train, X_out_val, X_test, y_train, y_out_val, y_test = data\n",
    "   \n",
    "    X_train_val_comb, y_train_val_comb = np.concatenate([X_train, X_out_val], axis=0), np.concatenate([y_train, y_out_val], axis=0)\n",
    "    dropout_loss_df = pd.read_csv(f\"{save_dir_100}/drop_out_loss_s_{seed}.csv\")\n",
    "\n",
    "    for ft_len in feat_lens:\n",
    "\n",
    "        bnn_dropout_sel = dropout_loss_df[\"feats_idx\"][:ft_len].to_list()\n",
    "        X_train_sel_1, X_test_sel_1 = X_train_val_comb[:,bnn_dropout_sel], X_test[:,bnn_dropout_sel]\n",
    "\n",
    "        _, bnn_cv_score_1, bnn_test_score_1 = run_logistic_regression(X_train_sel_1, X_test_sel_1,\n",
    "                                                                      y_train_val_comb, y_test, cv, verbose=0)\n",
    "\n",
    "        X_gp_train_sel, X_gp_val_sel, X_gp_test_sel = X_out_val[:,bnn_dropout_sel], X_train[:,bnn_dropout_sel] ,X_test[:,bnn_dropout_sel]\n",
    "\n",
    "        gp = SymbolicClassifier(generations=500, population_size=1000,\n",
    "                         function_set=function_set, parsimony_coefficient=0.001,\n",
    "                         random_state=seed, max_samples=0.8, verbose=0,\n",
    "                         p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.01,\n",
    "                         p_point_mutation=0.1, p_point_replace=0.05)\n",
    "\n",
    "        # gp = SymbolicTransformer(generations=100, population_size=1000, hall_of_fame=100, n_components=20,\n",
    "        #                          function_set=function_set, parsimony_coefficient=0.001,\n",
    "        #                          random_state=seed, max_samples=0.8, verbose=0,\n",
    "        #                          p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.01,\n",
    "        #                          p_point_mutation=0.1, p_point_replace=0.05, metric=\"spearman\")\n",
    "\n",
    "        gp.fit(X_gp_train_sel, y_out_val)\n",
    "\n",
    "        gp_features_val_fit = gp_transform(gp, X_gp_val_sel, classifier=True, num_models=50, sort_fit=\"Fitness\")\n",
    "        gp_features_test_fit = gp_transform(gp, X_gp_test_sel, classifier=True, num_models=50, sort_fit=\"Fitness\")\n",
    "\n",
    "        gp_features_val_oob_fit = gp_transform(gp, X_gp_val_sel, classifier=True, num_models=50, sort_fit=\"OOB_fitness\")\n",
    "        gp_features_test_oob_fit = gp_transform(gp, X_gp_test_sel, classifier=True, num_models=50, sort_fit=\"OOB_fitness\")\n",
    "\n",
    "        best_cv_score_fit, best_test_score_fit = 0.0, 0.0\n",
    "        best_cv_score_oob_fit, best_test_score_oob_fit = 0.0, 0.0\n",
    "        best_n_models_fit, best_n_models_oob_fit = 0, 0\n",
    "        for j in num_models:\n",
    "            X_val_comb_fit, X_test_comb_fit = np.concatenate([X_gp_val_sel, gp_features_val_fit[:,:j]], axis=1), np.concatenate([X_gp_test_sel, gp_features_test_fit[:,:j]], axis=1)\n",
    "\n",
    "            _, log_bnn_gp_cv_fit, log_bnn_gp_test_fit = run_logistic_regression(X_val_comb_fit, X_test_comb_fit, y_train,\n",
    "                                                                                        y_test, cv)\n",
    "\n",
    "            if log_bnn_gp_cv_fit > best_cv_score_fit:\n",
    "                best_cv_score_fit = log_bnn_gp_cv_fit\n",
    "                best_test_score_fit = log_bnn_gp_test_fit\n",
    "                best_n_models_fit = j\n",
    "\n",
    "            X_val_comb_oob_fit, X_test_comb_oob_fit = np.concatenate([X_gp_val_sel, gp_features_val_oob_fit[:,:j]], axis=1), np.concatenate([X_gp_test_sel, gp_features_test_oob_fit[:,:j]], axis=1)\n",
    "\n",
    "            _, log_bnn_gp_cv_oob_fit, log_bnn_gp_test_oob_fit = run_logistic_regression(X_val_comb_oob_fit, X_test_comb_oob_fit, y_train,\n",
    "                                                                                        y_test, cv)\n",
    "            \n",
    "            if log_bnn_gp_cv_oob_fit > best_cv_score_oob_fit:\n",
    "                best_cv_score_oob_fit = log_bnn_gp_cv_oob_fit\n",
    "                best_test_score_oob_fit = log_bnn_gp_test_oob_fit\n",
    "                best_n_models_oob_fit = j\n",
    "\n",
    "        bnn_gp_dict[\"seed\"].append(seed)\n",
    "        bnn_gp_dict[\"classifier\"].append(\"BNN + LR\")\n",
    "        bnn_gp_dict[\"orig_num_feats\"].append(ft_len)\n",
    "        # bnn_gp_dict[\"gp_num_feats\"].append(0)\n",
    "        bnn_gp_dict[\"cv_score\"].append(bnn_cv_score_1)\n",
    "        bnn_gp_dict[\"test_score\"].append(bnn_test_score_1)\n",
    "\n",
    "        bnn_gp_dict[\"seed\"].append(seed)\n",
    "        bnn_gp_dict[\"classifier\"].append(\"BNN + LR + GP1\")\n",
    "        bnn_gp_dict[\"orig_num_feats\"].append(ft_len)\n",
    "        bnn_gp_dict[\"gp_num_feats\"].append(best_n_models_fit)\n",
    "        bnn_gp_dict[\"cv_score\"].append(best_cv_score_fit)\n",
    "        bnn_gp_dict[\"test_score\"].append(best_test_score_fit)\n",
    "\n",
    "        bnn_gp_dict[\"seed\"].append(seed)\n",
    "        bnn_gp_dict[\"classifier\"].append(\"BNN + LR + GP2\")\n",
    "        bnn_gp_dict[\"orig_num_feats\"].append(ft_len)\n",
    "        bnn_gp_dict[\"gp_num_feats\"].append(best_n_models_oob_fit)\n",
    "        bnn_gp_dict[\"cv_score\"].append(best_cv_score_oob_fit)\n",
    "        bnn_gp_dict[\"test_score\"].append(best_test_score_oob_fit)\n",
    "\n",
    "\n",
    "\n",
    "bnn_gp_df = pd.DataFrame(bnn_gp_dict)\n",
    "bnn_gp_df.to_csv(f\"{save_dir_100}/bnn_lr_gp.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gp_num_features = bnn_gp_dict[\"gp_num_feats\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bnn_gp_df = pd.DataFrame(bnn_gp_dict)\n",
    "# bnn_gp_df.to_csv(f\"{save_dir_100}/bnn_lr_gp.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_gp_df = pd.read_csv(f\"{save_dir_100}/bnn_lr_gp.csv\")\n",
    "bnn_gp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_gp_df.groupby([\"classifier\", \"orig_num_feats\"])[[\"cv_score\", \"test_score\"]].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_lr_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_1_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP1\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_2_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_lr_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "bnn_gp_1_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "bnn_gp_2_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"BNN + LR\", \"BNN + LR + GP1\", \"BNN + LR + GP2\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_lr_cv_5_fts, bnn_gp_1_cv_5_fts, bnn_gp_2_cv_5_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_lr_test_5_fts, bnn_gp_1_test_5_fts, bnn_gp_2_test_5_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen', \"lightpink\"]\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 5/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "plt.legend([bplot2['medians'][0], bplot2['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bnn_lr_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_1_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP1\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_2_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_lr_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "bnn_gp_1_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "bnn_gp_2_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"BNN + LR\", \"BNN + LR + GP1\", \"BNN + LR + GP2\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_lr_cv_10_fts, bnn_gp_1_cv_10_fts, bnn_gp_2_cv_10_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_lr_test_10_fts, bnn_gp_1_test_10_fts, bnn_gp_2_test_10_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen', \"lightpink\"]\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 10/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "plt.legend([bplot2['medians'][0], bplot2['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnn_lr_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_1_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP1\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_2_cv_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_lr_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "bnn_gp_1_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "bnn_gp_2_test_5_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 5)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"BNN + LR\", \"BNN + LR + GP1\", \"BNN + LR + GP2\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_lr_cv_5_fts, bnn_gp_1_cv_5_fts, bnn_gp_2_cv_5_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_lr_test_5_fts, bnn_gp_1_test_5_fts, bnn_gp_2_test_5_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen', \"lightpink\"]\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 5/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "plt.legend([bplot2['medians'][0], bplot2['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnn_lr_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_1_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP1\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "bnn_gp_2_cv_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"cv_score\"].to_numpy()\n",
    "\n",
    "bnn_lr_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "bnn_gp_1_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "bnn_gp_2_test_10_fts = bnn_gp_df[(bnn_gp_df[\"classifier\"] == \"BNN + LR + GP2\") & (bnn_gp_df[\"orig_num_feats\"] == 10)][\"test_score\"].to_numpy()\n",
    "\n",
    "labels = [\"BNN + LR\", \"BNN + LR + GP1\", \"BNN + LR + GP2\"]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "bplot1 = ax1.boxplot([bnn_lr_cv_10_fts, bnn_gp_1_cv_10_fts, bnn_gp_2_cv_10_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "bplot2 = ax2.boxplot([bnn_lr_test_10_fts, bnn_gp_1_test_10_fts, bnn_gp_2_test_10_fts], showmeans=True, patch_artist=True, labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "colors = ['lightblue', 'lightgreen', \"lightpink\"]\n",
    "for bplot in (bplot1, bplot2):\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "fig.suptitle(\"Feature selection - using 10/100 features for prediction\")\n",
    "plt.legend([bplot1['medians'][0], bplot1['means'][0]], ['median', 'mean'])\n",
    "plt.legend([bplot2['medians'][0], bplot2['means'][0]], ['median', 'mean'])\n",
    "\n",
    "ax1.set_ylabel(\"AUC\")\n",
    "ax1.set_title(\"CV Scores\")\n",
    "\n",
    "ax2.set_ylabel(\"AUC\")\n",
    "ax2.set_title(\"Test Scores\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Logistic Regression vs. BNN feat_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m save_dir_500 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/exp_data_4/bmm/f500\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "save_dir_500 = f\"{data_dir}/exp_data_4/bmm/f500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running - seed 422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 20>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m clf\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m     37\u001B[0m log_test_score \u001B[38;5;241m=\u001B[39m roc_auc_score(y_test, clf\u001B[38;5;241m.\u001B[39mpredict_proba(X_test)[:,\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m---> 39\u001B[0m config, bnn_cv_score \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_hyper_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# config = pickle.load(open(f\"{save_dir}/bnn_params_s_{seed}.pickle\", \"rb\"))\u001B[39;00m\n\u001B[1;32m     42\u001B[0m config_values\u001B[38;5;241m.\u001B[39mappend(config)\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36moptimize_hyper_parameters\u001B[0;34m(seed, X, y)\u001B[0m\n\u001B[1;32m     94\u001B[0m tae \u001B[38;5;241m=\u001B[39m smac\u001B[38;5;241m.\u001B[39mget_tae_runner()\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m     incumbent \u001B[38;5;241m=\u001B[39m \u001B[43msmac\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     incumbent \u001B[38;5;241m=\u001B[39m smac\u001B[38;5;241m.\u001B[39msolver\u001B[38;5;241m.\u001B[39mincumbent\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/facade/smac_ac_facade.py:723\u001B[0m, in \u001B[0;36mSMAC4AC.optimize\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    721\u001B[0m incumbent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    722\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 723\u001B[0m     incumbent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    725\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver\u001B[38;5;241m.\u001B[39msave()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/optimizer/smbo.py:279\u001B[0m, in \u001B[0;36mSMBO.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunhistory\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m    268\u001B[0m     config\u001B[38;5;241m=\u001B[39mrun_info\u001B[38;5;241m.\u001B[39mconfig,\n\u001B[1;32m    269\u001B[0m     cost\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m(MAXINT) \u001B[38;5;28;01mif\u001B[39;00m num_obj \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mfull(num_obj, \u001B[38;5;28mfloat\u001B[39m(MAXINT)),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    274\u001B[0m     budget\u001B[38;5;241m=\u001B[39mrun_info\u001B[38;5;241m.\u001B[39mbudget,\n\u001B[1;32m    275\u001B[0m )\n\u001B[1;32m    277\u001B[0m run_info\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mconfig_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunhistory\u001B[38;5;241m.\u001B[39mconfig_ids[run_info\u001B[38;5;241m.\u001B[39mconfig]\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtae_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;66;03m# There are 2 criteria that the stats object uses to know\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;66;03m# if the budged was exhausted.\u001B[39;00m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# The budget time, which can only be known when the run finishes,\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# And the number of ta executions. Because we submit the job at this point,\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;66;03m# we count this submission as a run. This prevent for using more\u001B[39;00m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# runner runs than what the scenario allows\u001B[39;00m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstats\u001B[38;5;241m.\u001B[39msubmitted_ta_runs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/tae/serial_runner.py:87\u001B[0m, in \u001B[0;36mSerialRunner.submit_run\u001B[0;34m(self, run_info)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubmit_run\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_info: RunInfo) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;124;03m\"\"\"This function submits a run_info object in a serial fashion.\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m    As there is a single worker for this task, this\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;03m        An object containing the configuration and the necessary data to run it\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_info\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/tae/base.py:220\u001B[0m, in \u001B[0;36mBaseRunner.run_wrapper\u001B[0;34m(self, run_info)\u001B[0m\n\u001B[1;32m    217\u001B[0m     cutoff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(math\u001B[38;5;241m.\u001B[39mceil(run_info\u001B[38;5;241m.\u001B[39mcutoff))\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     status, cost, runtime, additional_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43minstance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcutoff\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbudget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbudget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43minstance_specific\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance_specific\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    229\u001B[0m     status \u001B[38;5;241m=\u001B[39m StatusType\u001B[38;5;241m.\u001B[39mCRASHED\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/tae/execute_func.py:217\u001B[0m, in \u001B[0;36mAbstractTAFunc.run\u001B[0;34m(self, config, instance, cutoff, seed, budget, instance_specific)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;66;03m# call ta\u001B[39;00m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 217\u001B[0m     rval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_ta\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rval, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    220\u001B[0m         result \u001B[38;5;241m=\u001B[39m rval[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/smac/tae/execute_func.py:314\u001B[0m, in \u001B[0;36mExecuteTAFuncDict._call_ta\u001B[0;34m(self, obj, config, obj_kwargs)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_ta\u001B[39m(\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    309\u001B[0m     obj: Callable,\n\u001B[1;32m    310\u001B[0m     config: Configuration,\n\u001B[1;32m    311\u001B[0m     obj_kwargs: Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]],\n\u001B[1;32m    312\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, Dict]]:\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mobj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mobj_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36mgenerate_train_cs.<locals>.train_cs\u001B[0;34m(config, budget)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# print(seed)\u001B[39;00m\n\u001B[1;32m     63\u001B[0m sgmcmc \u001B[38;5;241m=\u001B[39m MixedSGMCMC(seed\u001B[38;5;241m=\u001B[39mseed, n_samples\u001B[38;5;241m=\u001B[39mbudget, n_warmup\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m     64\u001B[0m                     n_chains\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, layer_dims\u001B[38;5;241m=\u001B[39m[config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m]], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m---> 65\u001B[0m cv_score \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43msgmcmc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mactivation_fns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mactivation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mJ\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnet\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m cv_score\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py:1043\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1035\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1040\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1043\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1044\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1046\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:678\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    674\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mset_params(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcloned_parameters)\n\u001B[1;32m    676\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 678\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    679\u001B[0m X_test, y_test \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, test, train)\n\u001B[1;32m    681\u001B[0m result \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/metaestimators.py:311\u001B[0m, in \u001B[0;36m_safe_split\u001B[0;34m(estimator, X, y, indices, train_indices)\u001B[0m\n\u001B[1;32m    308\u001B[0m     X_subset \u001B[38;5;241m=\u001B[39m _safe_indexing(X, indices)\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 311\u001B[0m     y_subset \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    313\u001B[0m     y_subset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/__init__.py:361\u001B[0m, in \u001B[0;36m_safe_indexing\u001B[0;34m(X, indices, axis)\u001B[0m\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_array_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    363\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/__init__.py:185\u001B[0m, in \u001B[0;36m_array_indexing\u001B[0;34m(array, key, key_dtype, axis)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    184\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m--> 185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m array[:, key]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:3676\u001B[0m, in \u001B[0;36m_rewriting_take\u001B[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001B[0m\n\u001B[1;32m   3673\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m lax\u001B[38;5;241m.\u001B[39mdynamic_index_in_dim(arr, idx, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   3675\u001B[0m treedef, static_idx, dynamic_idx \u001B[38;5;241m=\u001B[39m _split_index_for_jit(idx, arr\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m-> 3676\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_gather\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtreedef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatic_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdynamic_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_are_sorted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3677\u001B[0m \u001B[43m               \u001B[49m\u001B[43munique_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfill_value\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:3685\u001B[0m, in \u001B[0;36m_gather\u001B[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001B[0m\n\u001B[1;32m   3682\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_gather\u001B[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001B[1;32m   3683\u001B[0m             unique_indices, mode, fill_value):\n\u001B[1;32m   3684\u001B[0m   idx \u001B[38;5;241m=\u001B[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001B[0;32m-> 3685\u001B[0m   indexer \u001B[38;5;241m=\u001B[39m \u001B[43m_index_to_gather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# shared with _scatter_update\u001B[39;00m\n\u001B[1;32m   3686\u001B[0m   y \u001B[38;5;241m=\u001B[39m arr\n\u001B[1;32m   3688\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fill_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:3812\u001B[0m, in \u001B[0;36m_index_to_gather\u001B[0;34m(x_shape, idx, normalize_indices)\u001B[0m\n\u001B[1;32m   3809\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m normalize_indices:\n\u001B[1;32m   3810\u001B[0m     advanced_pairs \u001B[38;5;241m=\u001B[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001B[1;32m   3811\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m e, i, j \u001B[38;5;129;01min\u001B[39;00m advanced_pairs)\n\u001B[0;32m-> 3812\u001B[0m   advanced_indexes, idx_advanced_axes, x_advanced_axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43madvanced_pairs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3813\u001B[0m   advanced_axes_are_contiguous \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mall(np\u001B[38;5;241m.\u001B[39mdiff(idx_advanced_axes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m   3815\u001B[0m x_axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# Current axis in x.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:3810\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   3806\u001B[0m advanced_pairs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   3807\u001B[0m   (asarray(e), i, j) \u001B[38;5;28;01mfor\u001B[39;00m j, (i, e) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(idx_no_nones)\n\u001B[1;32m   3808\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m isscalar(e) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, (Sequence, ndarray, np\u001B[38;5;241m.\u001B[39mndarray)))\n\u001B[1;32m   3809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m normalize_indices:\n\u001B[0;32m-> 3810\u001B[0m   advanced_pairs \u001B[38;5;241m=\u001B[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001B[1;32m   3811\u001B[0m                     \u001B[38;5;28;01mfor\u001B[39;00m e, i, j \u001B[38;5;129;01min\u001B[39;00m advanced_pairs)\n\u001B[1;32m   3812\u001B[0m advanced_indexes, idx_advanced_axes, x_advanced_axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39madvanced_pairs)\n\u001B[1;32m   3813\u001B[0m advanced_axes_are_contiguous \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mall(np\u001B[38;5;241m.\u001B[39mdiff(idx_advanced_axes) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:3807\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_advanced_int_indexer(idx):\n\u001B[1;32m   3805\u001B[0m   idx_no_nones \u001B[38;5;241m=\u001B[39m [(i, d) \u001B[38;5;28;01mfor\u001B[39;00m i, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(idx) \u001B[38;5;28;01mif\u001B[39;00m d \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m   3806\u001B[0m   advanced_pairs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m-> 3807\u001B[0m     (\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m, i, j) \u001B[38;5;28;01mfor\u001B[39;00m j, (i, e) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(idx_no_nones)\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m isscalar(e) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, (Sequence, ndarray, np\u001B[38;5;241m.\u001B[39mndarray)))\n\u001B[1;32m   3809\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m normalize_indices:\n\u001B[1;32m   3810\u001B[0m     advanced_pairs \u001B[38;5;241m=\u001B[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001B[1;32m   3811\u001B[0m                       \u001B[38;5;28;01mfor\u001B[39;00m e, i, j \u001B[38;5;129;01min\u001B[39;00m advanced_pairs)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:1931\u001B[0m, in \u001B[0;36masarray\u001B[0;34m(a, dtype, order)\u001B[0m\n\u001B[1;32m   1929\u001B[0m lax_internal\u001B[38;5;241m.\u001B[39m_check_user_dtype_supported(dtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masarray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1930\u001B[0m dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mcanonicalize_dtype(dtype) \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype\n\u001B[0;32m-> 1931\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/numpy/lax_numpy.py:1912\u001B[0m, in \u001B[0;36marray\u001B[0;34m(object, dtype, copy, order, ndmin)\u001B[0m\n\u001B[1;32m   1908\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m array(np\u001B[38;5;241m.\u001B[39masarray(view), dtype, copy, ndmin\u001B[38;5;241m=\u001B[39mndmin)\n\u001B[1;32m   1910\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected input type for array: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1912\u001B[0m out_array: Array \u001B[38;5;241m=\u001B[39m \u001B[43mlax_internal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_element_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweak_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweak_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ndmin \u001B[38;5;241m>\u001B[39m ndim(out_array):\n\u001B[1;32m   1914\u001B[0m   out_array \u001B[38;5;241m=\u001B[39m lax\u001B[38;5;241m.\u001B[39mexpand_dims(out_array, \u001B[38;5;28mrange\u001B[39m(ndmin \u001B[38;5;241m-\u001B[39m ndim(out_array)))\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/lax/lax.py:594\u001B[0m, in \u001B[0;36m_convert_element_type\u001B[0;34m(operand, new_dtype, weak_type)\u001B[0m\n\u001B[1;32m    592\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m type_cast(Array, operand)\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 594\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvert_element_type_p\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mweak_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mweak_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/core.py:328\u001B[0m, in \u001B[0;36mPrimitive.bind\u001B[0;34m(self, *args, **params)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams):\n\u001B[1;32m    326\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39mjax_enable_checks \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m    327\u001B[0m           \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(arg, Tracer) \u001B[38;5;129;01mor\u001B[39;00m valid_jaxtype(arg) \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args)), args\n\u001B[0;32m--> 328\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind_with_trace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfind_top_trace\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/core.py:331\u001B[0m, in \u001B[0;36mPrimitive.bind_with_trace\u001B[0;34m(self, trace, args, params)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbind_with_trace\u001B[39m(\u001B[38;5;28mself\u001B[39m, trace, args, params):\n\u001B[0;32m--> 331\u001B[0m   out \u001B[38;5;241m=\u001B[39m \u001B[43mtrace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_primitive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfull_raise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    332\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmap\u001B[39m(full_lower, out) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultiple_results \u001B[38;5;28;01melse\u001B[39;00m full_lower(out)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/core.py:698\u001B[0m, in \u001B[0;36mEvalTrace.process_primitive\u001B[0;34m(self, primitive, tracers, params)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_primitive\u001B[39m(\u001B[38;5;28mself\u001B[39m, primitive, tracers, params):\n\u001B[0;32m--> 698\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprimitive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtracers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:114\u001B[0m, in \u001B[0;36mapply_primitive\u001B[0;34m(prim, *args, **params)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124;03m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001B[39;00m\n\u001B[1;32m    112\u001B[0m compiled_fun \u001B[38;5;241m=\u001B[39m xla_primitive_callable(prim, \u001B[38;5;241m*\u001B[39munsafe_map(arg_spec, args),\n\u001B[1;32m    113\u001B[0m                                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompiled_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:199\u001B[0m, in \u001B[0;36mxla_primitive_callable.<locals>.<lambda>\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    196\u001B[0m compiled \u001B[38;5;241m=\u001B[39m _xla_callable_uncached(lu\u001B[38;5;241m.\u001B[39mwrap_init(prim_fun), device, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    197\u001B[0m                                   prim\u001B[38;5;241m.\u001B[39mname, donated_invars, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39marg_specs)\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m prim\u001B[38;5;241m.\u001B[39mmultiple_results:\n\u001B[0;32m--> 199\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: \u001B[43mcompiled\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    201\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m compiled\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:925\u001B[0m, in \u001B[0;36m_execute_trivial\u001B[0;34m(jaxpr, device, consts, avals, handlers, has_unordered_effects, ordered_effects, kept_var_idx, host_callbacks, *args)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28mmap\u001B[39m(env\u001B[38;5;241m.\u001B[39msetdefault, jaxpr\u001B[38;5;241m.\u001B[39mconstvars, consts)\n\u001B[1;32m    923\u001B[0m outs \u001B[38;5;241m=\u001B[39m [xla\u001B[38;5;241m.\u001B[39mcanonicalize_dtype(v\u001B[38;5;241m.\u001B[39mval) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(v) \u001B[38;5;129;01mis\u001B[39;00m core\u001B[38;5;241m.\u001B[39mLiteral \u001B[38;5;28;01melse\u001B[39;00m env[v]\n\u001B[1;32m    924\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m jaxpr\u001B[38;5;241m.\u001B[39moutvars]\n\u001B[0;32m--> 925\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [_copy_device_array_to_device(x, device) \u001B[38;5;28;01mif\u001B[39;00m device_array\u001B[38;5;241m.\u001B[39mtype_is_device_array(x)\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m h(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39mdevice_put(x, device)) \u001B[38;5;28;01mfor\u001B[39;00m h, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(handlers, outs)]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:926\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28mmap\u001B[39m(env\u001B[38;5;241m.\u001B[39msetdefault, jaxpr\u001B[38;5;241m.\u001B[39mconstvars, consts)\n\u001B[1;32m    923\u001B[0m outs \u001B[38;5;241m=\u001B[39m [xla\u001B[38;5;241m.\u001B[39mcanonicalize_dtype(v\u001B[38;5;241m.\u001B[39mval) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(v) \u001B[38;5;129;01mis\u001B[39;00m core\u001B[38;5;241m.\u001B[39mLiteral \u001B[38;5;28;01melse\u001B[39;00m env[v]\n\u001B[1;32m    924\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m jaxpr\u001B[38;5;241m.\u001B[39moutvars]\n\u001B[1;32m    925\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [_copy_device_array_to_device(x, device) \u001B[38;5;28;01mif\u001B[39;00m device_array\u001B[38;5;241m.\u001B[39mtype_is_device_array(x)\n\u001B[0;32m--> 926\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m h(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[43mdevice_put\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m h, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(handlers, outs)]\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:1199\u001B[0m, in \u001B[0;36mdevice_put\u001B[0;34m(x, device)\u001B[0m\n\u001B[1;32m   1197\u001B[0m x \u001B[38;5;241m=\u001B[39m xla\u001B[38;5;241m.\u001B[39mcanonicalize_dtype(x)\n\u001B[1;32m   1198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1199\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdevice_put_handlers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m   1201\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo device_put handler for type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/dispatch.py:1210\u001B[0m, in \u001B[0;36m_device_put_array\u001B[0;34m(x, device)\u001B[0m\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mfloat0:\n\u001B[1;32m   1209\u001B[0m   x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(x\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;28mbool\u001B[39m))\n\u001B[0;32m-> 1210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuffer_from_pyval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m,)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from nn_util import prepare_data\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "config_values = []\n",
    "\n",
    "bnn_lr_dict_500 = {\"seed\": [], \"classifier\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "log_param_grid = {\"C\":np.logspace(-2, 1, 10)}\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    seed, net, data = prepare_data(seeds, i, data_dfs, net_dfs, test_size=0.3)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    print(f\"Running - seed {seed}\")\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    rng_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                       jax.device_put(y_train), jax.device_put(y_test)\n",
    "\n",
    "\n",
    "    log_grid_cv = GridSearchCV(estimator=LogisticRegression(max_iter=10000), param_grid=log_param_grid, verbose=0, scoring=\"roc_auc\", cv=cv).fit(X_train, y_train)\n",
    "    log_cv_score = log_grid_cv.best_score_\n",
    "    clf = LogisticRegression(max_iter=10000, C=log_grid_cv.best_params_[\"C\"])\n",
    "    clf.fit(X_train, y_train)\n",
    "    log_test_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "    config, bnn_cv_score = optimize_hyper_parameters(seed, X_train, y_train)\n",
    "\n",
    "    # config = pickle.load(open(f\"{save_dir}/bnn_params_s_{seed}.pickle\", \"rb\"))\n",
    "    config_values.append(config)\n",
    "\n",
    "    pickle.dump(config, open(f\"{save_dir_500}/bnn_params_s_{seed}.pickle\", \"wb\"))\n",
    "\n",
    "    params = {\"disc_lr\": config[\"disc_lr\"], \"contin_lr\": config[\"contin_lr\"], \"batch_size\": config[\"batch_size\"],\n",
    "              \"mu\": config[\"mu\"], \"eta\": config[\"eta\"], \"temp\": config[\"temp\"],\n",
    "              \"sigma\": config[\"sigma\"], \"cycle_len\": config[\"cycle_len\"], \"beta\": config[\"beta\"]}\n",
    "\n",
    "    mixed_sgmcmc = MixedSGMCMC(seed=seed, n_samples=2000, n_warmup=0,\n",
    "                               n_chains=1, layer_dims=[config[\"layer_dim\"]], **params)\n",
    "\n",
    "    # bnn_cv_score = np.mean(cross_val_score(mixed_sgmcmc, X_train, y_train, cv=cv,\n",
    "    #                                        fit_params={\"activation_fns\": [config[\"activation\"]],  \"J\": net}))\n",
    "\n",
    "    mixed_sgmcmc.fit(X_train, y_train, activation_fns=[config[\"activation\"]], J=net)\n",
    "\n",
    "    bnn_test_score = mixed_sgmcmc.score(X_test, y_test)\n",
    "\n",
    "    bnn_disc_mean = jnp.mean(mixed_sgmcmc.states_.discrete_position, axis=0)\n",
    "    np.save(f\"{save_dir_500}/bnn_disc_mean_s_{seed}.npy\", bnn_disc_mean)\n",
    "\n",
    "\n",
    "    bnn_lr_dict_500[\"seed\"].append(seed)\n",
    "    bnn_lr_dict_500[\"classifier\"].append(\"LR\")\n",
    "    bnn_lr_dict_500[\"cv_score\"].append(log_cv_score)\n",
    "    bnn_lr_dict_500[\"test_score\"].append(log_test_score)\n",
    "\n",
    "    bnn_lr_dict_500[\"seed\"].append(seed)\n",
    "    bnn_lr_dict_500[\"classifier\"].append(\"BNN\")\n",
    "    bnn_lr_dict_500[\"cv_score\"].append(bnn_cv_score)\n",
    "    bnn_lr_dict_500[\"test_score\"].append(bnn_test_score)\n",
    "\n",
    "    print(f\"Config: {config}\")\n",
    "\n",
    "    print(f\"Done - seed {seed}\\nLR cv_score: {log_cv_score}, LR test_score: {log_test_score}\")\n",
    "    print(f\"BNN cv_score: {bnn_cv_score}, BNN test_score: {bnn_test_score}\")\n",
    "\n",
    "bnn_lr_df_500 = pd.DataFrame(bnn_lr_dict_500)\n",
    "bnn_lr_df_500.to_csv(f\"{save_dir_500}/res_bmm_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>classifier</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.558040</td>\n",
       "      <td>0.492985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>0.543771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.537980</td>\n",
       "      <td>0.549244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.527738</td>\n",
       "      <td>0.529176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.552338</td>\n",
       "      <td>0.455197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>968</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.508821</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>282</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.567325</td>\n",
       "      <td>0.502264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>282</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.566687</td>\n",
       "      <td>0.534309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.677096</td>\n",
       "      <td>0.722995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>739</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.676894</td>\n",
       "      <td>0.713584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>573</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.583870</td>\n",
       "      <td>0.503202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>573</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.576286</td>\n",
       "      <td>0.515734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>220</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.669890</td>\n",
       "      <td>0.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>220</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.664444</td>\n",
       "      <td>0.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>413</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.567172</td>\n",
       "      <td>0.445625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>413</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.575036</td>\n",
       "      <td>0.437812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>745</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.587840</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>745</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.589883</td>\n",
       "      <td>0.522572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>775</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.600236</td>\n",
       "      <td>0.537896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>775</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.600186</td>\n",
       "      <td>0.494910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>482</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.598407</td>\n",
       "      <td>0.472448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>482</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.598691</td>\n",
       "      <td>0.490350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>442</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.623667</td>\n",
       "      <td>0.612323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>442</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.645693</td>\n",
       "      <td>0.614570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>210</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.480215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>210</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.564912</td>\n",
       "      <td>0.490662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>423</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.473460</td>\n",
       "      <td>0.467267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>423</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.508795</td>\n",
       "      <td>0.500409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>760</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.610281</td>\n",
       "      <td>0.586875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>760</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.617220</td>\n",
       "      <td>0.550938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>57</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.570461</td>\n",
       "      <td>0.515767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>57</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.550247</td>\n",
       "      <td>0.557086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>769</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.656270</td>\n",
       "      <td>0.582351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>769</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.642265</td>\n",
       "      <td>0.525438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>920</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.642312</td>\n",
       "      <td>0.537905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>920</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.630198</td>\n",
       "      <td>0.527488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>226</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.589758</td>\n",
       "      <td>0.397500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>226</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.587198</td>\n",
       "      <td>0.456250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>196</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.569685</td>\n",
       "      <td>0.599589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>196</td>\n",
       "      <td>BNN</td>\n",
       "      <td>0.522728</td>\n",
       "      <td>0.651880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seed classifier  cv_score  test_score\n",
       "0    422         LR  0.558040    0.492985\n",
       "1    422        BNN  0.525300    0.543771\n",
       "2    261         LR  0.537980    0.549244\n",
       "3    261        BNN  0.527738    0.529176\n",
       "4    968         LR  0.552338    0.455197\n",
       "5    968        BNN  0.508821    0.555556\n",
       "6    282         LR  0.567325    0.502264\n",
       "7    282        BNN  0.566687    0.534309\n",
       "8    739         LR  0.677096    0.722995\n",
       "9    739        BNN  0.676894    0.713584\n",
       "10   573         LR  0.583870    0.503202\n",
       "11   573        BNN  0.576286    0.515734\n",
       "12   220         LR  0.669890    0.569500\n",
       "13   220        BNN  0.664444    0.571500\n",
       "14   413         LR  0.567172    0.445625\n",
       "15   413        BNN  0.575036    0.437812\n",
       "16   745         LR  0.587840    0.590287\n",
       "17   745        BNN  0.589883    0.522572\n",
       "18   775         LR  0.600236    0.537896\n",
       "19   775        BNN  0.600186    0.494910\n",
       "20   482         LR  0.598407    0.472448\n",
       "21   482        BNN  0.598691    0.490350\n",
       "22   442         LR  0.623667    0.612323\n",
       "23   442        BNN  0.645693    0.614570\n",
       "24   210         LR  0.561111    0.480215\n",
       "25   210        BNN  0.564912    0.490662\n",
       "26   423         LR  0.473460    0.467267\n",
       "27   423        BNN  0.508795    0.500409\n",
       "28   760         LR  0.610281    0.586875\n",
       "29   760        BNN  0.617220    0.550938\n",
       "30    57         LR  0.570461    0.515767\n",
       "31    57        BNN  0.550247    0.557086\n",
       "32   769         LR  0.656270    0.582351\n",
       "33   769        BNN  0.642265    0.525438\n",
       "34   920         LR  0.642312    0.537905\n",
       "35   920        BNN  0.630198    0.527488\n",
       "36   226         LR  0.589758    0.397500\n",
       "37   226        BNN  0.587198    0.456250\n",
       "38   196         LR  0.569685    0.599589\n",
       "39   196        BNN  0.522728    0.651880"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn_lr_df_500 = pd.read_csv(f\"{save_dir_500}/res_bmm_summary.csv\")\n",
    "bnn_lr_df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNN</th>\n",
       "      <td>0.583961</td>\n",
       "      <td>0.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.589860</td>\n",
       "      <td>0.531072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cv_score  test_score\n",
       "classifier                      \n",
       "BNN         0.583961    0.539200\n",
       "LR          0.589860    0.531072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnn_lr_df_500.groupby([\"classifier\"])[[\"cv_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration(values={\n",
       "  'activation': 'tanh',\n",
       "  'batch_size': 64,\n",
       "  'beta': 0.9901000815779375,\n",
       "  'contin_lr': 0.000553849670496185,\n",
       "  'disc_lr': 0.015499881752989718,\n",
       "  'eta': 13.42890174428199,\n",
       "  'layer_dim': 50,\n",
       "  'mu': 355.8300138691474,\n",
       "  'sigma': 6.261816495065096,\n",
       "  'temp': 0.0040914487548523466,\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_sel</th>\n",
       "      <th>num_feats</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bnn</th>\n",
       "      <th>5</th>\n",
       "      <td>0.508902</td>\n",
       "      <td>0.506224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.511703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.511703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">random</th>\n",
       "      <th>5</th>\n",
       "      <td>0.523177</td>\n",
       "      <td>0.518667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.564427</td>\n",
       "      <td>0.578557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.566813</td>\n",
       "      <td>0.574128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cv_score  test_score\n",
       "feat_sel num_feats                      \n",
       "bnn      5          0.508902    0.506224\n",
       "         10         0.517699    0.511703\n",
       "         15         0.517699    0.511703\n",
       "random   5          0.523177    0.518667\n",
       "         10         0.564427    0.578557\n",
       "         15         0.566813    0.574128"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_v_bnn_sel_fts_df.groupby([\"feat_sel\", \"num_feats\"])[[\"cv_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num features')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gamma_means = jnp.mean(mixed_sgmcmc.states_.discrete_position, axis=0)\n",
    "bnn_disc_mean_s_442 = np.load(f\"{save_dir_500}/bnn_disc_mean_s_{seed}.npy\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.hist(bnn_disc_mean_s_442)\n",
    "ax1.set_xlabel(\"frequency\")\n",
    "ax1.set_ylabel(\"num features\")\n",
    "\n",
    "ax2.hist(gamma_means)\n",
    "ax2.set_xlabel(\"frequency\")\n",
    "ax2.set_ylabel(\"num features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "bnn_sel_ft_5 = rand_v_bnn_sel_fts_df[(rand_v_bnn_sel_fts_df[\"feat_sel\"] == \"bnn\" ) & (rand_v_bnn_sel_fts_df[\"num_feats\"] == 5)]\n",
    "rand_fisher_sel_ft_5 = rand_v_bnn_sel_fts_df[(rand_v_bnn_sel_fts_df[\"feat_sel\"] == \"random\") & (rand_v_bnn_sel_fts_df[\"num_feats\"] == 5)]\n",
    "\n",
    "bnn_sel_ft_10 = rand_v_bnn_sel_fts_df[(rand_v_bnn_sel_fts_df[\"feat_sel\"] == \"bnn\" ) & (rand_v_bnn_sel_fts_df[\"num_feats\"] == 10)]\n",
    "rand_fisher_sel_ft_10 = rand_v_bnn_sel_fts_df[(rand_v_bnn_sel_fts_df[\"feat_sel\"] == \"random\") & (rand_v_bnn_sel_fts_df[\"num_feats\"] == 10)]\n",
    "\n",
    "cv_score_bnn_sel_ft_5 = bnn_sel_ft_5[\"cv_score\"]\n",
    "cv_score_rand_sel_ft_5 = rand_fisher_sel_ft_5[\"cv_score\"]\n",
    "\n",
    "cv_score_bnn_sel_ft_10 = bnn_sel_ft_10[\"cv_score\"]\n",
    "cv_score_rand_sel_ft_10 = rand_fisher_sel_ft_10[\"cv_score\"]\n",
    "\n",
    "test_score_bnn_sel_ft_5 = bnn_sel_ft_5[\"test_score\"]\n",
    "test_score_rand_sel_ft_5 = rand_fisher_sel_ft_5[\"test_score\"]\n",
    "\n",
    "test_score_bnn_sel_ft_10 = bnn_sel_ft_10[\"test_score\"]\n",
    "test_score_rand_sel_ft_10 = rand_fisher_sel_ft_10[\"test_score\"]\n",
    "\n",
    "p_val_cv_score_5 = stats.ttest_ind(cv_score_bnn_sel_ft_5, cv_score_rand_sel_ft_5, alternative=\"two-sided\", equal_var=False).pvalue\n",
    "p_val_test_score_5 = stats.ttest_ind(test_score_bnn_sel_ft_5, test_score_rand_sel_ft_5, alternative=\"two-sided\", equal_var=False).pvalue\n",
    "\n",
    "p_val_cv_score_10 = stats.ttest_ind(cv_score_bnn_sel_ft_10, cv_score_rand_sel_ft_10, alternative=\"two-sided\", equal_var=False).pvalue\n",
    "p_val_test_score_10 = stats.ttest_ind(test_score_bnn_sel_ft_10, test_score_rand_sel_ft_5, alternative=\"two-sided\", equal_var=False).pvalue\n",
    "\n",
    "print(\"=========== Num feats: 5 =====================\")\n",
    "print(f\"CV Scores: BNN vs Random - p_value (two-sided): {p_val_cv_score_5}\")\n",
    "print(f\"Test Scores: BNN vs Random - p_value (two-sided): {p_val_test_score_5}\")\n",
    "\n",
    "print(\"\\n=========== Num feats: 10 =====================\")\n",
    "print(f\"CV Scores: BNN vs Random - p_value (two-sided): {p_val_cv_score_10}\")\n",
    "print(f\"Test Scores: BNN vs Random - p_value (two-sided): {p_val_test_score_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Num feats: 5 =====================\n",
      "CV Scores: BNN vs Random - p_value (one-sided): 9.539647905564428e-15\n",
      "Test Scores: BNN vs Random - p_value (one-sided): 2.4414652092392635e-12\n",
      "\n",
      "=========== Num feats: 10 =====================\n",
      "CV Scores: BNN vs Random - p_value (one-sided): 2.301495416941404e-08\n",
      "Test Scores: BNN vs Random - p_value (one-sided): 1.1606598065503922e-11\n"
     ]
    }
   ],
   "source": [
    "p_val_cv_score_5 = stats.ttest_ind(cv_score_bnn_sel_ft_5, cv_score_rand_sel_ft_5, alternative=\"greater\", equal_var=False).pvalue\n",
    "p_val_test_score_5 = stats.ttest_ind(test_score_bnn_sel_ft_5, test_score_rand_sel_ft_5, alternative=\"greater\", equal_var=False).pvalue\n",
    "\n",
    "p_val_cv_score_10 = stats.ttest_ind(cv_score_bnn_sel_ft_10, cv_score_rand_sel_ft_10, alternative=\"greater\", equal_var=False).pvalue\n",
    "p_val_test_score_10 = stats.ttest_ind(test_score_bnn_sel_ft_10, test_score_rand_sel_ft_5, alternative=\"greater\", equal_var=False).pvalue\n",
    "\n",
    "print(\"=========== Num feats: 5 =====================\")\n",
    "print(f\"CV Scores: BNN vs Random - p_value (one-sided): {p_val_cv_score_5}\")\n",
    "print(f\"Test Scores: BNN vs Random - p_value (one-sided): {p_val_test_score_5}\")\n",
    "\n",
    "print(\"\\n=========== Num feats: 10 =====================\")\n",
    "print(f\"CV Scores: BNN vs Random - p_value (one-sided): {p_val_cv_score_10}\")\n",
    "print(f\"Test Scores: BNN vs Random - p_value (one-sided): {p_val_test_score_10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_348/1906722657.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X, y = data_dfs[seed_idx].iloc[:,:-1].to_numpy().astype(np.float),  \\\n",
      "/tmp/ipykernel_348/1906722657.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data_dfs[seed_idx].iloc[:,-1].to_numpy().astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration(values={\n",
      "  'activation': 'relu',\n",
      "  'batch_size': 32,\n",
      "  'beta': 0.9223176022517695,\n",
      "  'contin_lr': 2.921565057716431e-05,\n",
      "  'cycle_len': 7,\n",
      "  'disc_lr': 0.0255358112072285,\n",
      "  'eta': 0.15141244695593806,\n",
      "  'layer_dim': 300,\n",
      "  'mu': 0.5222315154956412,\n",
      "  'sigma': 7.401408430020509,\n",
      "  'temp': 0.09070826467316453,\n",
      "})\n",
      "\n",
      "0.5378787869760631\n",
      "0.5632159934179469\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import pickle\n",
    "from sgmcmc import MixedSGMCMC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed_idx = 4\n",
    "\n",
    "seed = seeds[seed_idx]\n",
    "X, y = data_dfs[seed_idx].iloc[:,:-1].to_numpy().astype(np.float),  \\\n",
    "       data_dfs[seed_idx].iloc[:,-1].to_numpy().astype(np.float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True, stratify=y, test_size=0.3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = jax.device_put(X_train), jax.device_put(X_test), \\\n",
    "                                   jax.device_put(y_train), jax.device_put(y_test)\n",
    "net = net_dfs[seed_idx].to_numpy()\n",
    "\n",
    "bnn_params_s_442 = pickle.load(open(f\"{save_dir_500}/bnn_params_s_{seed}.pickle\", \"rb\"))\n",
    "\n",
    "print(bnn_params_s_442)\n",
    "\n",
    "params = {\"disc_lr\": 0.1, \"contin_lr\": 0.001, \"batch_size\": bnn_params_s_442[\"batch_size\"],\n",
    "          \"mu\": 1000, \"eta\": 10, \"temp\": bnn_params_s_442[\"temp\"],\n",
    "          \"sigma\": bnn_params_s_442[\"sigma\"], \"cycle_len\": 5, \"beta\": 0.95}\n",
    "\n",
    "cv = StratifiedKFold(shuffle=True, random_state=seed)\n",
    "mixed_sgmcmc = MixedSGMCMC(seed=442, n_samples=1000, n_warmup=0,\n",
    "                           n_chains=1, layer_dims=[bnn_params_s_442[\"layer_dim\"]], **params)\n",
    "\n",
    "bnn_cv_score = np.mean(cross_val_score(mixed_sgmcmc, X_train, y_train, cv=cv,\n",
    "                                       fit_params={\"activation_fns\": [bnn_params_s_442[\"activation\"]],  \"J\": net}))\n",
    "\n",
    "print(bnn_cv_score)\n",
    "mixed_sgmcmc.fit(X_train, y_train, activation_fns=[bnn_params_s_442[\"activation\"]], J=net)\n",
    "\n",
    "print(mixed_sgmcmc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mixed_sgmcmc.disc_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'num features')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gamma_means = jnp.mean(mixed_sgmcmc.states_.discrete_position, axis=0)\n",
    "bnn_disc_mean_s_442 = np.load(f\"{save_dir_500}/bnn_disc_mean_s_{seed}.npy\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.hist(bnn_disc_mean_s_442)\n",
    "ax1.set_xlabel(\"frequency\")\n",
    "ax1.set_ylabel(\"num features\")\n",
    "\n",
    "ax2.hist(gamma_means)\n",
    "ax2.set_xlabel(\"frequency\")\n",
    "ax2.set_ylabel(\"num features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50/723526.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X, y = data_dfs[seed_idx].iloc[:,:-1].to_numpy().astype(np.float), \\\n",
      "/tmp/ipykernel_50/723526.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data_dfs[seed_idx].iloc[:,-1].to_numpy().astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.46415888336127775}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:21<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from run_moses_cosmic_exp import run_logistc_regression\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed_idx = 2\n",
    "seed = seeds[seed_idx]\n",
    "X, y = data_dfs[seed_idx].iloc[:,:-1].to_numpy().astype(np.float), \\\n",
    "       data_dfs[seed_idx].iloc[:,-1].to_numpy().astype(np.float)\n",
    "\n",
    "net = net_dfs[seed_idx].to_numpy()\n",
    "\n",
    "gamma_means_idx_s = np.argsort(gamma_means)[::-1]\n",
    "\n",
    "log_v_bnn_sel_fts_dict = {\"seed\": [], \"feat_sel\": [], \"num_feats\": [], \"cv_score\": [], \"test_score\": []}\n",
    "\n",
    "all_feats = np.arange(p - 1)\n",
    "\n",
    "feat_lens = [5, 10]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True, stratify=y, test_size=0.3)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(random_state=seed, shuffle=True, n_splits=5)\n",
    "log_best_params, _, _ = run_logistc_regression(X_train, X_test, y_train, y_test, cv, verbose=0)\n",
    "print(log_best_params)\n",
    "log_clf = LogisticRegression(max_iter=10000, **log_best_params)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "log_coef = log_clf.coef_[0]\n",
    "\n",
    "log_coef_sorted = np.argsort(log_coef)[::-1]\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "\n",
    "    cv = StratifiedKFold(random_state=seed, shuffle=True, n_splits=5)\n",
    "\n",
    "    # print(gamma_means)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True, stratify=y, test_size=0.3)\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    for ft_len in feat_lens:\n",
    "\n",
    "        log_sel_fts = log_coef_sorted[:ft_len]\n",
    "\n",
    "        X_train_log_sel, X_test_log_sel, = X_train[:,log_sel_fts], X_test[:,log_sel_fts]\n",
    "\n",
    "        _, log_cv_score, log_test_score = run_logistc_regression(X_train_log_sel, X_test_log_sel,\n",
    "                                                                 y_train, y_test, cv, verbose=0)\n",
    "\n",
    "        bnn_sel_fts = gamma_means_idx_s[:ft_len]\n",
    "\n",
    "        X_train_sel, X_test_sel = X_train[:,bnn_sel_fts], X_test[:,bnn_sel_fts]\n",
    "\n",
    "        _, bnn_cv_score, bnn_test_score = run_logistc_regression(X_train_sel, X_test_sel,\n",
    "                                                                 y_train, y_test, cv, verbose=0)\n",
    "\n",
    "\n",
    "        log_v_bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        log_v_bnn_sel_fts_dict[\"feat_sel\"].append(\"lr\")\n",
    "        log_v_bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        # log_v_bnn_sel_fts_dict[\"kernel\"].append(svm_log_params[\"kernel\"])\n",
    "        log_v_bnn_sel_fts_dict[\"cv_score\"].append(log_cv_score)\n",
    "        log_v_bnn_sel_fts_dict[\"test_score\"].append(log_test_score)\n",
    "\n",
    "        log_v_bnn_sel_fts_dict[\"seed\"].append(seed)\n",
    "        log_v_bnn_sel_fts_dict[\"feat_sel\"].append(\"bnn\")\n",
    "        log_v_bnn_sel_fts_dict[\"num_feats\"].append(ft_len)\n",
    "        # log_v_bnn_sel_fts_dict[\"kernel\"].append(svm_bnn_params[\"kernel\"])\n",
    "        log_v_bnn_sel_fts_dict[\"cv_score\"].append(bnn_cv_score)\n",
    "        log_v_bnn_sel_fts_dict[\"test_score\"].append(bnn_test_score)\n",
    "\n",
    "\n",
    "log_v_bnn_sel_fts_df = pd.DataFrame(log_v_bnn_sel_fts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cv_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_sel</th>\n",
       "      <th>num_feats</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bnn</th>\n",
       "      <th>5</th>\n",
       "      <td>0.513978</td>\n",
       "      <td>0.526661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.615466</td>\n",
       "      <td>0.612497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">lr</th>\n",
       "      <th>5</th>\n",
       "      <td>0.655775</td>\n",
       "      <td>0.642661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.657482</td>\n",
       "      <td>0.651044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cv_score  test_score\n",
       "feat_sel num_feats                      \n",
       "bnn      5          0.513978    0.526661\n",
       "         10         0.615466    0.612497\n",
       "lr       5          0.655775    0.642661\n",
       "         10         0.657482    0.651044"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_v_bnn_sel_fts_df.groupby([\"feat_sel\", \"num_feats\"])[[\"cv_score\", \"test_score\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}