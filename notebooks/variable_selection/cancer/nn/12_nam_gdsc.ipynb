{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\r\n",
      "Requirement already satisfied: jaxlib in /usr/local/lib/python3.9/dist-packages (0.3.8+cuda11.cudnn82)\r\n",
      "Collecting jaxlib\r\n",
      "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.1%2Bcuda11.cudnn86-cp39-cp39-manylinux2014_x86_64.whl (155.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m155.9/155.9 MB\u001B[0m \u001B[31m12.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jaxlib) (1.23.1)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jaxlib) (1.8.1)\r\n",
      "Installing collected packages: jaxlib\r\n",
      "  Attempting uninstall: jaxlib\r\n",
      "    Found existing installation: jaxlib 0.3.8+cuda11.cudnn82\r\n",
      "    Uninstalling jaxlib-0.3.8+cuda11.cudnn82:\r\n",
      "      Successfully uninstalled jaxlib-0.3.8+cuda11.cudnn82\r\n",
      "Successfully installed jaxlib-0.4.1+cuda11.cudnn86\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mLooking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\r\n",
      "Requirement already satisfied: jax in /usr/local/lib/python3.9/dist-packages (0.3.14)\r\n",
      "Collecting jax\r\n",
      "  Downloading jax-0.4.1.tar.gz (1.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m67.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jax) (1.23.1)\r\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.9/dist-packages (from jax) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax) (1.8.1)\r\n",
      "Building wheels for collected packages: jax\r\n",
      "  Building wheel for jax (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for jax: filename=jax-0.4.1-py3-none-any.whl size=1332463 sha256=4bbcbcce00b1b15b547e8d11d456428abd3490a25136ad8f741c9257140b5a2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/f7/56/3b5d10a573be427643de12e27ff806d622d843a5d30b0cc164\r\n",
      "Successfully built jax\r\n",
      "Installing collected packages: jax\r\n",
      "  Attempting uninstall: jax\r\n",
      "    Found existing installation: jax 0.3.14\r\n",
      "    Uninstalling jax-0.3.14:\r\n",
      "      Successfully uninstalled jax-0.3.14\r\n",
      "Successfully installed jax-0.4.1\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting optax\r\n",
      "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m154.9/154.9 kB\u001B[0m \u001B[31m27.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.9/dist-packages (from optax) (4.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from optax) (1.23.1)\r\n",
      "Collecting chex>=0.1.5\r\n",
      "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.3/85.3 kB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from optax) (1.1.0)\r\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.9/dist-packages (from optax) (0.4.1+cuda11.cudnn86)\r\n",
      "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.9/dist-packages (from optax) (0.4.1)\r\n",
      "Collecting dm-tree>=0.1.5\r\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m153.0/153.0 kB\u001B[0m \u001B[31m38.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting toolz>=0.9.0\r\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.8/55.8 kB\u001B[0m \u001B[31m18.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->optax) (1.8.1)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.1.55->optax) (3.3.0)\r\n",
      "Installing collected packages: dm-tree, toolz, chex, optax\r\n",
      "Successfully installed chex-0.1.5 dm-tree-0.1.8 optax-0.1.4 toolz-0.12.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting dm-haiku\r\n",
      "  Downloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m352.1/352.1 kB\u001B[0m \u001B[31m36.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (1.1.0)\r\n",
      "Collecting tabulate>=0.8.9\r\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Collecting jmp>=0.0.2\r\n",
      "  Downloading jmp-0.0.3-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from dm-haiku) (1.23.1)\r\n",
      "Installing collected packages: tabulate, jmp, dm-haiku\r\n",
      "Successfully installed dm-haiku-0.0.9 jmp-0.0.3 tabulate-0.9.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting tensorflow-probability==0.17\r\n",
      "  Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl (6.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m62.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (0.4.0)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-probability==0.17) (1.14.0)\r\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (0.1.8)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (5.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (1.23.1)\r\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow-probability==0.17) (2.1.0)\r\n",
      "Installing collected packages: tensorflow-probability\r\n",
      "Successfully installed tensorflow-probability-0.17.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting git+https://github.com/blackjax-devs/blackjax.git\r\n",
      "  Cloning https://github.com/blackjax-devs/blackjax.git to /tmp/pip-req-build-_2cpfgsq\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/blackjax-devs/blackjax.git /tmp/pip-req-build-_2cpfgsq\r\n",
      "  Resolved https://github.com/blackjax-devs/blackjax.git to commit 017f441d9af2ce337309de40f9b0362ba8e5e395\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: optax in /usr/local/lib/python3.9/dist-packages (from blackjax==0.9.7.dev129+g017f441) (0.1.4)\r\n",
      "Collecting fastprogress>=0.2.0\r\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: jaxlib>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from blackjax==0.9.7.dev129+g017f441) (0.4.1+cuda11.cudnn86)\r\n",
      "Collecting typing-extensions>=4.4.0\r\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\r\n",
      "Collecting jaxopt>=0.5.5\r\n",
      "  Downloading jaxopt-0.5.5-py3-none-any.whl (132 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m132.3/132.3 kB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jax>=0.3.13 in /usr/local/lib/python3.9/dist-packages (from blackjax==0.9.7.dev129+g017f441) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.9.7.dev129+g017f441) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.9.7.dev129+g017f441) (1.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.13->blackjax==0.9.7.dev129+g017f441) (1.23.1)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (1.1.0)\r\n",
      "Requirement already satisfied: matplotlib>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (3.5.2)\r\n",
      "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from optax->blackjax==0.9.7.dev129+g017f441) (0.1.5)\r\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax->blackjax==0.9.7.dev129+g017f441) (0.1.8)\r\n",
      "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from chex>=0.1.5->optax->blackjax==0.9.7.dev129+g017f441) (0.12.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (4.34.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (1.4.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (9.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (2.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (21.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (0.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.1->jaxopt>=0.5.5->blackjax==0.9.7.dev129+g017f441) (1.14.0)\r\n",
      "Building wheels for collected packages: blackjax\r\n",
      "  Building wheel for blackjax (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for blackjax: filename=blackjax-0.9.7.dev129+g017f441-py3-none-any.whl size=320048 sha256=cb7a1f725f7bd1708091974509a87fba5aae42d7e0175756e5becf690ebb56b0\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-87rkkkyg/wheels/e6/1e/f6/a6e0408a4e374b9cdb789b1769716b4ed61eef520a2dd702b1\r\n",
      "Successfully built blackjax\r\n",
      "Installing collected packages: typing-extensions, fastprogress, jaxopt, blackjax\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.3.0\r\n",
      "    Uninstalling typing_extensions-4.3.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.3.0\r\n",
      "Successfully installed blackjax-0.9.7.dev129+g017f441 fastprogress-1.0.3 jaxopt-0.5.5 typing-extensions-4.4.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "Get:1 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]\r\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \u001B[0m\u001B[33m\r\n",
      "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB] \u001B[0m\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]                \u001B[0m\u001B[33m\r\n",
      "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\u001B[33m\u001B[33m\r\n",
      "Get:6 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [773 B]   \u001B[0m\u001B[33m\r\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2437 kB][33m\r\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\r\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\r\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\r\n",
      "Get:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [984 kB]\u001B[33m\r\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]0m\u001B[33m\u001B[33m\r\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\u001B[0m\u001B[33m\r\n",
      "Get:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1879 kB]3m\r\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2003 kB][33m\r\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1285 kB]m\r\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2910 kB]\u001B[33m\r\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\r\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\r\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]33m\r\n",
      "Get:22 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.7 kB]3m\r\n",
      "Fetched 25.1 MB in 2s (11.2 MB/s)[33m                        \u001B[0m\u001B[33m\u001B[33m\u001B[33m\u001B[33m\u001B[33m\u001B[33m\r\n",
      "Reading package lists... Done\r\n",
      "Building dependency tree       \r\n",
      "Reading state information... Done\r\n",
      "117 packages can be upgraded. Run 'apt list --upgradable' to see them.\r\n",
      "Reading package lists... Done\r\n",
      "Building dependency tree       \r\n",
      "Reading state information... Done\r\n",
      "The following additional packages will be installed:\r\n",
      "  fonts-liberation libann0 libcdt5 libcgraph6 libgts-0.7-5 libgts-bin libgvc6\r\n",
      "  libgvpr2 liblab-gamut1 libpathplan4\r\n",
      "Suggested packages:\r\n",
      "  gsfonts graphviz-doc\r\n",
      "The following NEW packages will be installed:\r\n",
      "  fonts-liberation graphviz libann0 libcdt5 libcgraph6 libgts-0.7-5 libgts-bin\r\n",
      "  libgvc6 libgvpr2 liblab-gamut1 libpathplan4\r\n",
      "0 upgraded, 11 newly installed, 0 to remove and 117 not upgraded.\r\n",
      "Need to get 2701 kB of archives.\r\n",
      "After this operation, 11.3 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-liberation all 1:1.07.4-11 [822 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libann0 amd64 1.1.2+doc-7build1 [26.0 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcdt5 amd64 2.42.2-3build2 [18.7 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcgraph6 amd64 2.42.2-3build2 [41.3 kB]\r\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgts-0.7-5 amd64 0.7.6+darcs121130-4 [150 kB]\r\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpathplan4 amd64 2.42.2-3build2 [21.9 kB]\r\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgvc6 amd64 2.42.2-3build2 [647 kB]\r\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgvpr2 amd64 2.42.2-3build2 [167 kB]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/universe amd64 liblab-gamut1 amd64 2.42.2-3build2 [177 kB]\r\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 graphviz amd64 2.42.2-3build2 [590 kB]\r\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgts-bin amd64 0.7.6+darcs121130-4 [41.3 kB]\r\n",
      "Fetched 2701 kB in 1s (2756 kB/s)      \u001B[0m\u001B[33m\r\n",
      "\n",
      "\u001B7\u001B[0;23r\u001B8\u001B[1ASelecting previously unselected package fonts-liberation.\r\n",
      "(Reading database ... 78556 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-fonts-liberation_1%3a1.07.4-11_all.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  0%]\u001B[49m\u001B[39m [..........................................................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  2%]\u001B[49m\u001B[39m [#.........................................................] \u001B8Unpacking fonts-liberation (1:1.07.4-11) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  4%]\u001B[49m\u001B[39m [##........................................................] \u001B8Selecting previously unselected package libann0.\r\n",
      "Preparing to unpack .../01-libann0_1.1.2+doc-7build1_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  7%]\u001B[49m\u001B[39m [###.......................................................] \u001B8Unpacking libann0 (1.1.2+doc-7build1) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  9%]\u001B[49m\u001B[39m [#####.....................................................] \u001B8Selecting previously unselected package libcdt5:amd64.\r\n",
      "Preparing to unpack .../02-libcdt5_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 11%]\u001B[49m\u001B[39m [######....................................................] \u001B8Unpacking libcdt5:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 13%]\u001B[49m\u001B[39m [#######...................................................] \u001B8Selecting previously unselected package libcgraph6:amd64.\r\n",
      "Preparing to unpack .../03-libcgraph6_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 16%]\u001B[49m\u001B[39m [#########.................................................] \u001B8Unpacking libcgraph6:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 18%]\u001B[49m\u001B[39m [##########................................................] \u001B8Selecting previously unselected package libgts-0.7-5:amd64.\r\n",
      "Preparing to unpack .../04-libgts-0.7-5_0.7.6+darcs121130-4_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 20%]\u001B[49m\u001B[39m [###########...............................................] \u001B8Unpacking libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 22%]\u001B[49m\u001B[39m [############..............................................] \u001B8Selecting previously unselected package libpathplan4:amd64.\r\n",
      "Preparing to unpack .../05-libpathplan4_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 24%]\u001B[49m\u001B[39m [##############............................................] \u001B8Unpacking libpathplan4:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 27%]\u001B[49m\u001B[39m [###############...........................................] \u001B8Selecting previously unselected package libgvc6.\r\n",
      "Preparing to unpack .../06-libgvc6_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 29%]\u001B[49m\u001B[39m [################..........................................] \u001B8Unpacking libgvc6 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 31%]\u001B[49m\u001B[39m [##################........................................] \u001B8Selecting previously unselected package libgvpr2:amd64.\r\n",
      "Preparing to unpack .../07-libgvpr2_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 33%]\u001B[49m\u001B[39m [###################.......................................] \u001B8Unpacking libgvpr2:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 36%]\u001B[49m\u001B[39m [####################......................................] \u001B8Selecting previously unselected package liblab-gamut1:amd64.\r\n",
      "Preparing to unpack .../08-liblab-gamut1_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 38%]\u001B[49m\u001B[39m [#####################.....................................] \u001B8Unpacking liblab-gamut1:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 40%]\u001B[49m\u001B[39m [#######################...................................] \u001B8Selecting previously unselected package graphviz.\r\n",
      "Preparing to unpack .../09-graphviz_2.42.2-3build2_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 42%]\u001B[49m\u001B[39m [########################..................................] \u001B8Unpacking graphviz (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 44%]\u001B[49m\u001B[39m [#########################.................................] \u001B8Selecting previously unselected package libgts-bin.\r\n",
      "Preparing to unpack .../10-libgts-bin_0.7.6+darcs121130-4_amd64.deb ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 47%]\u001B[49m\u001B[39m [###########################...............................] \u001B8Unpacking libgts-bin (0.7.6+darcs121130-4) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 49%]\u001B[49m\u001B[39m [############################..............................] \u001B8Setting up liblab-gamut1:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 51%]\u001B[49m\u001B[39m [#############################.............................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 53%]\u001B[49m\u001B[39m [##############################............................] \u001B8Setting up libgts-0.7-5:amd64 (0.7.6+darcs121130-4) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 56%]\u001B[49m\u001B[39m [################################..........................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 58%]\u001B[49m\u001B[39m [#################################.........................] \u001B8Setting up libpathplan4:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 60%]\u001B[49m\u001B[39m [##################################........................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 62%]\u001B[49m\u001B[39m [####################################......................] \u001B8Setting up libann0 (1.1.2+doc-7build1) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 64%]\u001B[49m\u001B[39m [#####################################.....................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 67%]\u001B[49m\u001B[39m [######################################....................] \u001B8Setting up fonts-liberation (1:1.07.4-11) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 69%]\u001B[49m\u001B[39m [#######################################...................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 71%]\u001B[49m\u001B[39m [#########################################.................] \u001B8Setting up libcdt5:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 73%]\u001B[49m\u001B[39m [##########################################................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 76%]\u001B[49m\u001B[39m [###########################################...............] \u001B8Setting up libcgraph6:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 78%]\u001B[49m\u001B[39m [#############################################.............] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 80%]\u001B[49m\u001B[39m [##############################################............] \u001B8Setting up libgts-bin (0.7.6+darcs121130-4) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 82%]\u001B[49m\u001B[39m [###############################################...........] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 84%]\u001B[49m\u001B[39m [################################################..........] \u001B8Setting up libgvc6 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 87%]\u001B[49m\u001B[39m [##################################################........] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 89%]\u001B[49m\u001B[39m [###################################################.......] \u001B8Setting up libgvpr2:amd64 (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 91%]\u001B[49m\u001B[39m [####################################################......] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 93%]\u001B[49m\u001B[39m [######################################################....] \u001B8Setting up graphviz (2.42.2-3build2) ...\r\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 96%]\u001B[49m\u001B[39m [#######################################################...] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 98%]\u001B[49m\u001B[39m [########################################################..] \u001B8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\r\n",
      "Processing triggers for man-db (2.9.1-1) ...\r\n",
      "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\r\n",
      "\r\n",
      "\u001B7\u001B[0;24r\u001B8\u001B[1A\u001B[JCollecting graphviz\r\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.0/47.0 kB\u001B[0m \u001B[31m12.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: graphviz\r\n",
      "Successfully installed graphviz-0.20.1\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting gplearn\r\n",
      "  Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from gplearn) (1.1.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from gplearn) (1.1.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.23.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.8.1)\r\n",
      "Installing collected packages: gplearn\r\n",
      "Successfully installed gplearn-0.4.2\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting optuna\r\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m365.3/365.3 kB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting alembic>=1.5.0\r\n",
      "  Downloading alembic-1.9.2-py3-none-any.whl (210 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m210.6/210.6 kB\u001B[0m \u001B[31m47.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting cmaes>=0.9.1\r\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.23.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (21.3)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.39)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.64.0)\r\n",
      "Collecting colorlog\r\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (5.4.1)\r\n",
      "Collecting Mako\r\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.7/78.7 kB\u001B[0m \u001B[31m18.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->optuna) (3.0.9)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\r\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\r\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U jaxlib -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install -U jax -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install optax\n",
    "!pip install dm-haiku\n",
    "!pip install tensorflow-probability==0.17\n",
    "!pip install git+https://github.com/blackjax-devs/blackjax.git\n",
    "!apt update\n",
    "!apt install -y graphviz\n",
    "!pip install graphviz\n",
    "!pip install gplearn\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "SERVER = 1\n",
    "\n",
    "if not SERVER:\n",
    "    %cd /home/xabush/code/snet/moses-incons-pen-xp/notebooks/variable_selection/cancer/nn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tfd = tfp.distributions\n",
    "import jax\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import optax\n",
    "from nn_util import *\n",
    "from optim_util import *\n",
    "plt.style.use('ggplot')\n",
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'gpu'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.default_backend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "if SERVER:\n",
    "    data_dir = \".\"\n",
    "else:\n",
    "    data_dir = \"/home/xabush/code/snet/moses-incons-pen-xp/data\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GDSC Cell Line"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gdsc_dir = f\"{data_dir}/cell_line/gdsc2\"\n",
    "gdsc_exp_data = pd.read_csv(f\"{gdsc_dir}/gdsc_gene_expr.csv\", index_col=\"model_id\")\n",
    "gdsc_response_data = pd.read_csv(f\"{gdsc_dir}/GDSC2_fitted_dose_response_24Jul22.csv\", index_col=\"SANGER_MODEL_ID\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bortezomib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(406, 37264)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bortezomib_response = gdsc_response_data[gdsc_response_data[\"DRUG_NAME\"] == \"Bortezomib\"]\n",
    "gdsc_exp_bortezomib_data = pd.merge(gdsc_exp_data, bortezomib_response[\"LN_IC50\"], left_index=True, right_index=True)\n",
    "gdsc_exp_bortezomib_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X, target = gdsc_exp_bortezomib_data.iloc[:,:-1], gdsc_exp_bortezomib_data.iloc[:,-1]\n",
    "# change to -log10(IC_50) to make it comparable\n",
    "target = -np.log10(np.exp(target)) # exp b/c the values are natural logs of raw IC_50\n",
    "cancer_driver_genes_df = pd.read_csv(f\"{data_dir}/cell_line/driver_genes_20221018.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "cols = X.columns.to_list()\n",
    "driver_syms = cancer_driver_genes_df[\"symbol\"].to_list()\n",
    "driver_sym_list = [sym.strip() for sym in cols if sym in driver_syms]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(406, 768)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected = X[driver_sym_list]\n",
    "X_selected.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "seed = 196\n",
    "X_train_outer_df, X_test_df, y_train_outer_df, y_test_df = train_test_split(X_selected, target, random_state=seed, shuffle=True, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:2583: UserWarning: n_quantiles (1000) is greater than the total number of samples (324). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer, RobustScaler, MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "train_transformer = QuantileTransformer(random_state=seed).fit(X_train_outer_df)\n",
    "# train_transformer = PowerTransformer().fit(X_train_df)\n",
    "train_transformed = train_transformer.transform(X_train_outer_df)\n",
    "test_transformed = train_transformer.transform(X_test_df)\n",
    "\n",
    "X_train_outer_df = pd.DataFrame(train_transformed, columns=X_train_outer_df.columns)\n",
    "X_test_df = pd.DataFrame(test_transformed, columns=X_test_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train_df, X_val_df, y_train_df, y_val_df = train_test_split(X_train_outer_df, y_train_outer_df, shuffle=True,\n",
    "                                                              random_state=seed, test_size=0.2)\n",
    "train_indices, val_indices = X_train_df.index.to_list(), X_val_df.index.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_train_outer, y_train_outer = X_train_outer_df.values, y_train_outer_df.values\n",
    "X_train, y_train = jax.device_put(X_train_df.values), jax.device_put(y_train_df.values)\n",
    "X_val, y_val = jax.device_put(X_val_df.values), jax.device_put(y_val_df.values)\n",
    "X_test, y_test = X_test_df.values, y_test_df.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NAM Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "    params: hk.Params\n",
    "    avg_params: hk.Params\n",
    "    opt_state: optax.OptState\n",
    "\n",
    "def exu(x, weight, bias):\n",
    "    \"\"\"ExU hidden unit modification.\"\"\"\n",
    "    return relu_n((x - bias) @ jnp.exp(weight))\n",
    "\n",
    "\n",
    "# Activation Functions\n",
    "def relu(x, weight, bias):\n",
    "    \"\"\"ReLU activation.\"\"\"\n",
    "    return jax.nn.relu((x - bias) @ weight)\n",
    "\n",
    "\n",
    "def relu_n(x, n = 1):\n",
    "    \"\"\"ReLU activation clipped at n.\"\"\"\n",
    "    return jnp.clip(x, 0, n)\n",
    "\n",
    "\n",
    "class FeatureNet(hk.Module):\n",
    "    \"\"\"Neural Network model for each individual feature.\n",
    "    Attributes:\n",
    "      hidden_layers: A list containing hidden layers. The first layer is an\n",
    "        `ActivationLayer` containing `num_units` neurons with specified\n",
    "        `activation`. If `shallow` is False, then it additionally contains 2\n",
    "        tf.keras.layers.Dense ReLU layers with 64, 32 hidden units respectively.\n",
    "      linear: Fully connected layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 num_units,\n",
    "                 dropout = 0.5,\n",
    "                 shallow = True,\n",
    "                 feature_num = 0,\n",
    "                 activation = 'exu',\n",
    "                 name=None):\n",
    "        \"\"\"Initializes FeatureNN hyperparameters.\n",
    "        Args:\n",
    "          num_units: Number of hidden units in first hidden layer.\n",
    "          dropout: Coefficient for dropout regularization.\n",
    "          shallow: If True, then a shallow network with a single hidden layer is\n",
    "            created, otherwise, a network with 3 hidden layers is created.\n",
    "          feature_num: Feature Index used for naming the hidden layers.\n",
    "          activation: Activation and type of hidden unit(ExUs/Standard) used in the\n",
    "            first hidden layer.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # if name is not None:\n",
    "        super().__init__(name)\n",
    "        # else:\n",
    "        #     super().__init__(f\"f_{feature_num}\")\n",
    "        self._input_shape = input_shape\n",
    "        self._num_units = num_units\n",
    "        self._dropout = dropout\n",
    "        self._feature_num = feature_num\n",
    "        self._shallow = shallow\n",
    "\n",
    "        self._activation = activation\n",
    "\n",
    "        if activation == \"exu\":\n",
    "            self._act_fn = exu\n",
    "            self._initializer = hk.initializers.TruncatedNormal(mean=4, stddev=0.5)\n",
    "\n",
    "        else:\n",
    "            self._act_fn = relu\n",
    "            self._initializer = hk.initializers.UniformScaling()\n",
    "\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        key = hk.next_rng_key()\n",
    "        k1, k2 = jax.random.split(key, 2)\n",
    "        w = hk.get_parameter(\"w\", [self._input_shape, self._num_units], init=self._initializer)\n",
    "        c = hk.get_parameter(\"c\", [self._input_shape], init=hk.initializers.TruncatedNormal(stddev=0.5))\n",
    "        # x = relu_n(self._act_fn(x, w, b), 1)\n",
    "        x = self._act_fn(x[...,None], w, c)\n",
    "        if not self._shallow:\n",
    "            x = hk.Linear(64, w_init=hk.initializers.UniformScaling())(x)\n",
    "            x = jax.nn.relu(x)\n",
    "            if is_training:\n",
    "                x = hk.dropout(k1, self._dropout, x)\n",
    "            x = hk.Linear(32, w_init=hk.initializers.UniformScaling())(x)\n",
    "            x = jax.nn.relu(x)\n",
    "            if is_training:\n",
    "                x = hk.dropout(k2, self._dropout, x)\n",
    "\n",
    "\n",
    "        x = hk.Linear(1, with_bias=False, w_init=hk.initializers.UniformScaling())(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class NAM:\n",
    "    \"\"\"Neural additive model.\n",
    "    Attributes:\n",
    "      feature_nns: List of FeatureNN, one per input feature.\n",
    "    \"\"\"\n",
    "    def __init__(self, *,\n",
    "                 num_inputs,\n",
    "                 num_units,\n",
    "                 step_size_fn,\n",
    "                 loss_fn,\n",
    "                 shallow = True,\n",
    "                 feature_dropout = 0.0,\n",
    "                 dropout = 0.0,\n",
    "                 output_reg = 0.0,\n",
    "                 l2_reg = 0.0,\n",
    "                 activation=\"exu\"):\n",
    "\n",
    "        \"\"\"Initializes NAM hyperparameters.\n",
    "        Args:\n",
    "          num_units: Number of hidden units in first layer of each feature net.\n",
    "          trainable: Whether the NAM parameters are trainable or not.\n",
    "          shallow: If True, then shallow feature nets with a single hidden layer are\n",
    "            created, otherwise, feature nets with 3 hidden layers are created.\n",
    "          feature_dropout: Coefficient for dropping out entire Feature NNs.\n",
    "          dropout: Coefficient for dropout within each Feature NNs.\n",
    "          **kwargs: Arbitrary keyword arguments. Used for passing the `activation`\n",
    "            function as well as the `name_scope`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._num_inputs = num_inputs\n",
    "        self._shallow = shallow\n",
    "        self._feature_dropout = feature_dropout\n",
    "        self._dropout = dropout\n",
    "        self.loss_fn = loss_fn\n",
    "        self._activation = activation\n",
    "        self.output_reg = output_reg\n",
    "        self.l2_reg = l2_reg\n",
    "        # if isinstance(num_units, list):\n",
    "        #     assert len(num_units) == num_inputs\n",
    "        #     self._num_units = num_units\n",
    "        # elif isinstance(num_units, int):\n",
    "        #     self._num_units = [num_units for _ in range(self._num_inputs)]\n",
    "\n",
    "        self._num_units = num_units\n",
    "        self.optimiser = optax.chain(optax.scale_by_adam(), optax.scale_by_schedule(step_size_fn), optax.scale(-1.0))\n",
    "\n",
    "        self._forward = hk.transform(self._forward_fn)\n",
    "        # self.loss = jax.jit(self.loss)\n",
    "        self.update = jax.jit(self.update)\n",
    "\n",
    "    def init(self, key, x):\n",
    "        params = self._forward.init(key, x, True)\n",
    "        opt_state = self.optimiser.init(params)\n",
    "        return TrainingState(params, params, opt_state)\n",
    "\n",
    "    def apply(self, params, key, x, is_training=True):\n",
    "        pred, per_feat_pred =  self._forward.apply(params, key, x, is_training)\n",
    "        return pred, per_feat_pred\n",
    "\n",
    "    def update(self, state, key, x, y):\n",
    "        grads, per_feat_pred = jax.grad(self.loss, has_aux=True)(state.params, key, x, y, True)\n",
    "        updates, opt_state = self.optimiser.update(grads, state.opt_state)\n",
    "        params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "        avg_params = optax.incremental_update(params, state.avg_params, step_size=1e-3)\n",
    "        return TrainingState(params, avg_params, opt_state), per_feat_pred\n",
    "\n",
    "\n",
    "    def loss(self, params, key, x, y, is_training):\n",
    "        preds, per_feat_pred = self.apply(params, key, x, is_training)\n",
    "        loss = self.loss_fn(preds, y)\n",
    "        reg_loss = 0.0\n",
    "\n",
    "        per_feature_norm = [jnp.mean(jnp.square(outputs)) for outputs in per_feat_pred]\n",
    "        per_feature_norm = sum(per_feature_norm) / len(per_feature_norm)\n",
    "        l2_features = self.output_reg*per_feature_norm\n",
    "        reg_loss += l2_features\n",
    "\n",
    "        l2_per_coef = 0.5 * sum(\n",
    "            jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(params)) / len(per_feat_pred)\n",
    "\n",
    "        reg_loss += self.l2_reg*l2_per_coef\n",
    "\n",
    "        return loss + reg_loss, per_feat_pred\n",
    "\n",
    "    def _forward_fn(self, x, is_training):\n",
    "        key = hk.next_rng_key()\n",
    "        x = jnp.array(jnp.split(x, self._num_inputs, axis=-1)).squeeze()\n",
    "        # per_feat_out = []\n",
    "        # for i in range(self._num_inputs):\n",
    "        #     per_feat_out.append(FeatureNet(1, self._num_units[i], self._dropout, self._shallow, i, self._activation)(x[i], is_training).squeeze())\n",
    "        per_feat_out = jax.vmap(lambda i, f: FeatureNet(1, self._num_units, self._dropout, self._shallow, i, self._activation)(f, is_training).squeeze())(jnp.arange(self._num_inputs), x)\n",
    "        if is_training:\n",
    "            mask = jax.random.bernoulli(key, 1 - self._feature_dropout, shape=(self._num_inputs,))\n",
    "\n",
    "            out = jnp.sum(per_feat_out.T @ jnp.diag(mask), axis=1)\n",
    "        else:\n",
    "            out = jnp.sum(per_feat_out, axis=0)\n",
    "\n",
    "        b = hk.get_parameter(\"b\", [1,], init=hk.initializers.Constant(0))\n",
    "\n",
    "        return out + b, per_feat_out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def mse_loss(preds, target):\n",
    "    return jnp.mean((preds - target)**2)\n",
    "\n",
    "def reg_eval(params, model, rng, x, y):\n",
    "    preds, _ = model.apply(params, rng, x, False)\n",
    "    return jnp.sqrt(mse_loss(preds, y))\n",
    "\n",
    "\n",
    "\n",
    "def train_loop(seed, train_loader, x_val, y_val,\n",
    "               epochs, output_reg, dropout, schedule_fn,\n",
    "               l2_reg=0.0, feature_dropout=0.0,  num_units = 64,\n",
    "               activation = 'relu',\n",
    "               eval_epoch=50, shallow=True):\n",
    "\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    loss_fn = mse_loss\n",
    "    eval_fn = reg_eval\n",
    "\n",
    "    # num_unique_vals = [\n",
    "    #     len(jnp.unique(x_train[:, i])) for i in range(x_train.shape[1])\n",
    "    # ]\n",
    "    # num_units = [\n",
    "    #     min(num_basis_functions, i * units_multiplier) for i in num_unique_vals\n",
    "    # ]\n",
    "\n",
    "    model = NAM(num_inputs=x_val.shape[-1] ,num_units=num_units,\n",
    "                step_size_fn=schedule_fn,\n",
    "                dropout=jnp.float32(dropout),\n",
    "                feature_dropout=jnp.float32(feature_dropout),\n",
    "                activation=activation,\n",
    "                shallow=shallow,\n",
    "                output_reg=output_reg,\n",
    "                l2_reg=l2_reg, loss_fn=loss_fn)\n",
    "\n",
    "    state = model.init(key, next(iter(train_loader))[0])\n",
    "\n",
    "    val_losses = []\n",
    "    pgbar = tqdm(range(epochs))\n",
    "    best_pram = None\n",
    "    lst_loss = 1e9\n",
    "    patience = 0\n",
    "    for epoch in pgbar:\n",
    "        for x, y in train_loader:\n",
    "            _, key = jax.random.split(key, 2)\n",
    "            state, _ = model.update(state, key, x, y)\n",
    "            # print(state.avg_params)\n",
    "\n",
    "        if epoch % eval_epoch == 0:\n",
    "            loss = eval_fn(state.params, model, key, x_val, y_val)\n",
    "            if epoch != 0:\n",
    "                if loss > val_losses[-1]:\n",
    "                    patience += 1\n",
    "                else:\n",
    "                    if loss < lst_loss:\n",
    "                        lst_loss = loss\n",
    "                        best_pram = state.params\n",
    "\n",
    "            if patience > 30:\n",
    "                break\n",
    "\n",
    "            val_losses.append(loss)\n",
    "\n",
    "            pgbar.set_postfix({\"va_loss\": loss, \"patience\": patience})\n",
    "\n",
    "    return model, best_pram, val_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 49/500 [01:53<17:21,  2.31s/it, va_loss=128.06178, patience=0]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m schedule_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m t: lr_0\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# schedule_fn = optax.cosine_decay_schedule(lr_0, total_steps)\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m model, params, val_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mout_reg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschedule_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_reg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshallow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_units\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_dropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(seed, train_loader, x_val, y_val, epochs, output_reg, dropout, schedule_fn, l2_reg, feature_dropout, num_units, activation, eval_epoch, shallow)\u001B[0m\n\u001B[1;32m     46\u001B[0m patience \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m pgbar:\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     49\u001B[0m         _, key \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39msplit(key, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     50\u001B[0m         state, _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mupdate(state, key, x, y)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:652\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    650\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    651\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 652\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    655\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    656\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:692\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    691\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 692\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/notebooks/nn_util.py:639\u001B[0m, in \u001B[0;36mnumpy_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mtuple\u001B[39m,\u001B[38;5;28mlist\u001B[39m)):\n\u001B[1;32m    638\u001B[0m   transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)\n\u001B[0;32m--> 639\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [numpy_collate(samples) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    641\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(batch)\n",
      "File \u001B[0;32m/notebooks/nn_util.py:639\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mtuple\u001B[39m,\u001B[38;5;28mlist\u001B[39m)):\n\u001B[1;32m    638\u001B[0m   transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)\n\u001B[0;32m--> 639\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mnumpy_collate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    641\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(batch)\n",
      "File \u001B[0;32m/notebooks/nn_util.py:641\u001B[0m, in \u001B[0;36mnumpy_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    639\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [numpy_collate(samples) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 641\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/array.py:341\u001B[0m, in \u001B[0;36mArrayImpl.__array__\u001B[0;34m(self, dtype, context)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 341\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_value\u001B[49m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/jax/_src/array.py:487\u001B[0m, in \u001B[0;36mArrayImpl._value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    486\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_fully_replicated:\n\u001B[0;32m--> 487\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arrays\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lr_0 = 1e-3\n",
    "l2_reg, out_reg = 1e-6, 0.0\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "rng_key = jax.random.PRNGKey(seed)\n",
    "torch.manual_seed(seed)\n",
    "data_loader = NumpyLoader(NumpyData(X_train, y_train), batch_size=batch_size, shuffle=False)\n",
    "total_steps = epochs*len(data_loader)\n",
    "schedule_fn = lambda t: lr_0\n",
    "# schedule_fn = optax.cosine_decay_schedule(lr_0, total_steps)\n",
    "model, params, val_loss = train_loop(seed, data_loader, X_val, y_val, epochs,\n",
    "                                    out_reg, 0.2, schedule_fn, l2_reg, shallow=True,\n",
    "                                    activation=\"exu\", eval_epoch=50, num_units=64, feature_dropout=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss = reg_eval(params, model, rng_key, X_test, y_test)\n",
    "test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_pred, per_feat_pred = model.apply(params, rng_key, X_test, False)\n",
    "r2_score(y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sort(np.mean(per_feat_pred, axis=-1))[::-1][:50]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def compute_mean_feature_importance(model, params, key, x, cols):\n",
    "    _, per_feat_preds = model.apply(params,key, x, False)\n",
    "    feature_predictions = np.array(per_feat_preds)\n",
    "    mean_feat_preds = np.mean(feature_predictions, axis=-1)\n",
    "\n",
    "    feat_importance = {}\n",
    "    feat_scores = np.zeros(len(cols))\n",
    "    for i, col in enumerate(cols):\n",
    "        mean_pred = mean_feat_preds[i]\n",
    "        feat_preds = feature_predictions[i]\n",
    "        mean_abs_score = np.mean(np.abs(feat_preds - mean_pred[...,None]), axis=-1)\n",
    "        feat_scores[i] = mean_abs_score\n",
    "        feat_importance[col] = mean_abs_score\n",
    "\n",
    "    return feat_importance, feat_scores\n",
    "\n",
    "def plot_mean_feature_importance(feat_importance, cols, width = 0.3, name=\"GDSC\"):\n",
    "    x1, x2 = zip(*feat_importance.items())\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    ind = np.arange(len(x1))  # the x locations for the groups\n",
    "    x1_indices = np.argsort(x2)\n",
    "    cols_here = [cols[i] for i in x1_indices]\n",
    "    x2_here = [x2[i] for i in x1_indices]\n",
    "\n",
    "    ax.bar(ind, x2_here, width, label='NAMs')\n",
    "    ax.set_xticks(ind + width/2, cols_here, rotation=90, fontsize='large')\n",
    "    ax.set_ylabel('Mean Absolute Score', fontsize='x-large')\n",
    "    ax.legend(loc='upper left', fontsize='large')\n",
    "    ax.set_title(f'Overall Importance: {name}', fontsize='x-large')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "cols = X_train_outer_df.columns.to_list()\n",
    "feature_importance_dict, feat_scores = compute_mean_feature_importance(model, params, rng_key, X_test, cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 360x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFICAYAAACBXE8pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABPRUlEQVR4nO2deZgdRfWw384kmSwQloQlCTsEQkAQIYCg7GAEJAh4WGSJBoIIouJPlg9URFRQZJUoCMgOOWwhgOxhFZCwKMoekkASAiELIWSbZKa/P041t+fOvTN9Z+6dO5k57/PMM7erq6tOV1efOn1qi+I4xnEcx6kO3aotgOM4TlfGlbDjOE4VcSXsOI5TRVwJO47jVBFXwo7jOFXElbDjOE4VcSXstCtRFI2KomhF6niPKIriKIrWq6ZcjlMtXAl3EqIoWieKoiuiKJoWRVFdFEWfRFF0VxRFX662bG0liqJzoyiaXG05WiKKohVRFI2qthzlIIqiI6MoeiKKovlRFC2JoujdKIrGRVG0VypO0oDGURQ1RFG0MIqiN6IouiqKoq0LpHlQFEXPRlE0L4qiRVEUTY6i6JYoivrlxds/iqKHoyiaG/J+O4qiv0ZRtHl73Ht740q4ExBF0frAS8AuwEnAZsABQB3wQhRFI9pBhp6VzqOj0tnuPYqia4HrgeeBbwFbAIeF4ysLXPIVYBCwLXA6sB7wShRFkkpzL+Bu4FHga8A2wMnAZ0BtKt4vgfuAycAhwFDg+1hdPr98d9mBiOPY/1byP2AC8BHQr8C5f4RzvYEhQAzskhdnpxA+JByvAlwGzAQWA68Ch6TibxTifzekvwi4EIiAvwHvAUuAKcDvgNrUtaOAFanjPUJa6zVzf+cCk/OPAQHeDTKOB/phL+7bwELgTmC11HXXA48BP03d2x3Amqk4EfB/Qfa6cC8/yZNnGqYQxgJzgX+FsDj9F+KuAdwMfBDK5G3gZ0BUQK4xwPuYYpoArJOX7z7AM0HuBcBTwKap80cA/waWBnkuBvqWWJcODfJ/p8j5tNxFnx0wDvg0KX/gUuClFvLePqR3ZpHza1T7XavI+1ttAfyvjQ/QXvJ64Jwi578eKvZB4fg54C95ccYCz4XfEfAE8CRmsWwSlEMdsHeIs1FIcwamiDcOf92A32JKfSPgIGAW8OtUXqMojxJeBDyAWVS7A58Aj2CNwrZB9o+BC1PXXZ9ScF8Keb8L3JOKczKmLMdgjdYPglIbnYozLaRzLrA5MAxYC1gB/BhYF1g3xF0XOBOzFjcGjgY+B76XJ9cC4DZga+CrwFTgplScfcJzvjTc31BgNDA0Va7zgWPCM9sNeC0vjVGhrDdqpqzHA+9krHtFnx05hXpYOD4DU8o7NpPepeG59qz2e9Wu73C1BfC/Nj5A2DFU9m8XOb9mOP/zcPwDYF5S0YGemDV3YjjeIyid1fLSuQ4YH35vFNL8RQb5fgq8mzoeRXmU8ApgQCrsyqCk1kqFXUbK+grK7nMaW8f7hfw3C8fTgT/k5X8JMCV1PA14vICcK4BRGcrkMuDRPLlm0/iL4QxgVur4GeD+ZtKcBvwgL2y3cG9rhONvA28Bg5tJ5w3g3rywH4ZyS/6+3tKzA3qFc6eH4z5Y4xdjDfO9WIPVP3XNP4DXqv1Otfef+4S7HuOwF+LAcHwg0DeEAwzHFPPMKIo+T/4wC25IXlov5iceRdEJURT9K4qij8N1vwc2rMB9zIzjeE7q+CPgoziOP8kLWzvvujfiOF6QOv5n+D8sdBCtBzydd81TwEZRFPVJhTW590JEUdQtiqIzoyj6dxRFc0KZ/ICmZfJWHMfLUscfAuukjrfHLP1CeawV0rs475k9GKJsBhDH8T1xHA+N43hmS2LnHd8CfBkYgdWVmhauT6cRh7wXx3F8EPY1cBbmDjoLeDuKoi2L5NslcCW88jMZq+hNeqMDW4X/bwPEcTwf6/g4NoQfC0yI4/jTcNwN+zT+ct7fMOCbeWkvSh9EUfQdzCIdB+wPbAecB/Qo7ZYysTzvOC4SVqk6vqjlKID5f88CLgf2xcryGqyhS1OXdxyTXSkl9/hjGj+zbbGG878Z0wF4B9gyHRDH8YI4jidj1nZWkno3JS+taXEcXx/H8Q9DPjHWmQdWRzftbB2dLeFKeCUnjuN52GfcKflDfQJnYb7RR1NhNwD7R1G0BaYsb0ydewlYHegVx/HkvL8PWhBnN+DVOI4vjuP45TiO38VcFx2JLfPKaZfw/404jj/D/Ny75V2zOzA1juPFLaRdR1MrcTfgoTiOr4vj+NWgzPK/KLLwMuY6aUIcxx9jbpQtCjyzyXEcLy0hn5uBzaIoOqIVMqb5OeYDfqxYhGAQpL9Wbsa+0k4rFD+KojXaKFOHpHu1BXDKwslYh9vEKIrOAV7HOoR+CuwFHBzH8ZJU/IewTpzbw/+HUucmYi/O3VEUnY517qyBKaulcRz/rRk53gZGR1E0Evgf5uo4pO23V1Zi4MZQTmtilvuEoBzB3Cd/iqLoXaxzci9s2N/JGdKeCuwZRdGDQF1wl7wNHBNF0Z7YJ/ixWMfl/BLl/g3wYBRFl2L++WVYB97zcRy/DZwNXBtF0XzM37ocszS/GcfxiQBRFH073N/exVwScRzfGUXRDcANYYz5/ZiCXws4MkSrz7tsrTABp0/I84eY1f/dxPUTRdG52KibBzCLehXgOOwL7rKQ90tRFJ0H/DYMuxyHjRYZhI2EGRz+dy6q7ZT2v/L8YUr3SqzS1gFzgLuA7YrEvwRTSJcUONcbuABTKnWYtfIQsFc4v1G49mt51/UArsI6/j4DbgVOIQzXCnFGUaYhanlxzgGm5YWdCcxIHV+PNTD/h3UOLQ5llO4cijArbiqmyKZQeIhak9EomM/0zVBmcQhbDdBQHnPDM/pNWtZErry0jk6XWwj7BjZWdwnmMnoC2CR1/uBwfnHI79/AL/PKvtnREXn5P4lZs8tDed0NHFDg2SV/i8L9XwVsnZfenphSnYZ1/M7B/PHfLZD3tzD/97wQ921sBM9m1X7PKvEXhZt2nE5PFEXXY8p+n2rL4jgJ7hN2HMepIq6EHcdxqoi7IxzHcaqIW8KO4zhVxIeoNcY/CxzHqRQFJ9+4Es7jww8/LCn+wIEDKySJ4zgdlVmzZpUUf9CgQUXPuTvCcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq4h1zGVm6dCn19fVEUeMOzlI78jozcRzTrVs3+vfvT8+eXWo1QsdpNa6EM7B8uS1T27dv3ybnevSoxFK5Ky9xHPPRRx+x7rrruiJ2nAy4OyIDdXV11NbWthzRIYoievfuzdy5c6stiuOsFLgSzki+G8IpThRFNDQ0VFsMx1kpcCWcAVfApeNl5jjZcCXsOI5TRVwJO47jVJF2HR0hIiOw/aRqgGtU9YK887XYppPbY1vBHK6q08K5s4DR2P5Wp6rqwyH8Omwvs9mq2mTHYRH5GXARsJaqzsk/31rqTzjI/pcrwTx6Xf9gy5GA7bffniVLljBp0qQvRm/cfPPN3HnnnYwfPx6wEQvDhw+nV69ePPvss42uP/jgg3nuueeYOHEiW2+dK77jjjuOBx98kHvuuYddd921PDflOE4T2s0SFpEabH+tb2Lbpx8pIsPyoo0G5qvqZtgeaBeGa4cBR2DbaI8Axob0wPbnGlEkz/WxHWpb2iV4paa+vp6//a34/pvPP/88c+bM4f333+fVV19tcn7TTTdFVb84njdvHi+99BIDBgyoiLyO4+RoT3fEjsBkVZ2iqnXYTr8j8+KMxLZjB7gT2FtEohB+u6ouU9WpwOSQHqr6NLYhYCEuAU6nky9RefLJJzN27FgWLFhQ8Py4ceMYMWIEe++9N+PGjWty/tBDD+Xee++lvt7s+nvuuYf999+/0RjoV155hX333ZdNNtmEYcOG8Ytf/KIyN+M4XYz2VMKDsa2zE2aEsIJxVHUFtqNs/4zXNkJERgIzVfU/LcQbIyIvichLAAMGDGjyV1tbS/fu3Rv9dSS23XZbdtllF8aOHdvk3OLFi7nvvvs47LDDOPTQQxk/fjx1dXWN4qy77rpsvvnmPPnkkwCoKiKNdxY/++yzOeGEE5gyZQovvvgiI0fmt5+O03UopCea+2uOjqVNyoSI9AH+H+aKaBZVvRq4OhzGc+Y0dRsvW7aMmpqaJuEdiTPOOIMDDzyQE044oVH4Aw88QG1tLXvssQcrVqxg+fLlPProoxxwwAGN4okIqsoGG2zAggULGD58eKPzPXr0YOrUqcydO5f+/fuzww47VPyeHKejUkhPNEdHWU94JrB+6ni9EFYwjoh0B1bDOuiyXJtmU2Bj4D8iMi3Ef0VE1m2D/B2aLbfckn333ZfLL7+8Ufi4ceM46KCD6N69O7169eLAAw8s6JI44IADeOaZZ7j22mv5zne+0+T8pZdeypQpU9h1113Zb7/9eOSRRyp2L47TlWhPS3gSMERENsYU6BHAUXlxJgDHAc8DhwETVTUWkQnArSJyMTAIGAK8WCwjVf0vsHZyHBTxDuUcHdEROf3009lnn3046aSTAFtc6Nlnn+XVV1/l/vvvB2DJkiUsW7bsC4s2oU+fPuy9995cf/31vPhi06LdZJNNuOqqq2hoaOCBBx5g9OjRvPXWWwXX03AcJzvtZgkHH+8pwMPAmxakr4vIeSJyUIh2LdBfRCYDpwFnhmtfBxR4A3gIOFlV6wFE5DZMaW8hIjNEZHR73VNHY5NNNuHggw/mmmuuAeCOO+5g0003/WII2sSJE3n++ecZOHAg99xzT5Przz77bMaPH88GG2zQ5Nwdd9zBnDlz6NatG/369QOgWzcfZu44bcW3vG9MXGhpysWLF9OnT5+CF1R7FbXtt9+eiy++mN133x2AmTNnsvPOO7P99tsze/Zsvv/973P88cc3uuaKK65gwoQJPProoxx88MEcdthhHH300U3S3nbbbRk7diy77rorJ510Ek899RSLFy9m/fXX56yzzmL//fcvKlddXV2zfjDHWZlp5R5zBefyuxJuzEqnhDsqroSdzkw5lbB/TzqO41QRV8KO4zhVxJWw4zhOFXElnAH3m5eOl5njZMOVcEZcqWQn2fDTcZyW8TclAz179mTZsmXVFmOlII5jlixZ0mgiiOM4xemUa0eUmx49elBfX8+iRYuabNvTu3fvKknV8UgsYN9p2XGy40o4I7169SoYPnDgwHaWxHGczoS7IxzHcaqIK2HHcZwq4krYcRynirgSdhzHqSKuhB3HcapI5tERIrIFcCK2oPoJqvpRWAf4/Zb2cXMcx3EKk8kSFpGvA/8GtsX2bUvWdRwG/LIikjmO43QBsrojfgecp6p7A+mteicStp53HMdxSierEt4WaLo7JHwMrFU+cRzHcboWWZXwUmzn43w2Bz4pnziO4zhdi6xK+B/AWSKSxI9FZABwPrZDsuM4jtMKso6OOB14ApgG9ALGA5sAU4FzsmYmIiOAy4Aa4BpVvSDvfC1wI7A9MBc4XFWnhXNnAaOBeuBUVX04hF8HHAjMVtWtU2n9EfgW5sN+D/ieqn6aVVbHcZz2IKslvAAYjo2EuAr4J/BjYLiqzs+SgIjUAFcC38RGVRwpIsPyoo0G5qvqZsAlwIXh2mHAEcBWwAhgbEgP4PoQls+jwNaqug3wDnBWpjt1HMdpR1q0hEWkO7AI2FZVr8eUXmvYEZisqlNCurcDI4E3UnFGAueG33cCfxaRKITfrqrLgKkiMjmk97yqPi0iG+VnpqqPpA5fAA5rpdyO4zgVo0UlrKorRGQ6bZ9dNxiYnjqeAexULE7IdwHQP4S/kHft4BLy/j6FR3cgImOAMSFPBgwYUEKyjuN0RcqpJ7L6hP8EnCsiR6vqkrLl3g6IyNnACuCWQudV9Wrg6nAYz5kzp6T0fT1hx+l6lKonBg0aVPRcViU8Evv8nykib2LuiS9Q1f0ypDETWD91vF4IKxRnRnCDrIZ10GW5tgkiMgrrtNtbVX2TOMdxOhxZlfCM8NcWJgFDRGRjTIEeARyVF2cCcBzwPObDnaiqsYhMAG4VkYuBQdj6FS82l1kYiXE6sLuqLm6j7I7jOBUhas9dhEVkf+BSbIjadar6WxE5D3hJVSeISC/gJmA7YB5wRKoj72zMt7sC+ImqPhjCbwP2AAZgM/h+parXhs67WsySBnhBVX/Qgojxhx9+WNI9uTvCcboes2bNKil+cEdEhc6VpIRFZH1seBnA66raVuu4o+FK2HGcFimnEs7kjhCRPsBfgKNTCTWIyM3ASStbZ53jOE5HIeuwsz9in/zfBtYIf4cCe4ZzjuM4TivI2jF3GHBsMlU4cK+ILANuAE4pu2SO4zhdgKyW8GrYOhH5TAX6lU8cx3GcrkVWJfw/wqyyPE4M5xzHcZxWkNUd8UvM/fA14OkQthvwFeCgSgjmOI7TFchkCavqP7DlJd8B9g5/7wDbq+pDlRPPcRync9OukzVWAnycsOM4LVLOccJZd1veP0wDzg8fUSjccRzHyUYpuy33KBBeA/y+fOI4juN0LbIq4SEUHgXxejjnOI7jtIJSdltet0D4IGB5+cRxHMfpWmRVwk8Avw6rnAEgIr2xrYgmVkAux3GcLkEpuy0/B0wRkedC2C6YEv9aJQRzHMfpCmQdJzwF2Ba4Fugd/q4BvqyqkysnnuM4TufGxwk3xscJO85KxowDh7Pe/ZPaNc92W09YRFYBalV1bipsC8w9sTZwt6r+vSRpHMdxysSMA4dXW4Q205I74i/AecmBiKwJPAt8C9gQuEZEjqiceI7jOE2ZceDwTqGAoWUlvDMwPnV8NLbH2xBV3Qa4BDi5MqI5juM0pbMo34SWRkcMBNIdb3sBd6nqgnB8PXBsBeRyHMf5gs6meNO0pISXYTsWJ+wI3J06/hxYJWtmYZ2Jy7Dpzteo6gV552uBG7EV2+YCh6vqtHDuLGA0UA+cmuzyISLXAQcCs1V161RaawLjgI2AaYCo6vyssjqOU306s/JNaMkd8Qa2tREiMhxYB3gydX4j4KMsGYlIDXAl8E1sx+YjRWRYXrTRwHxV3QxzdVwYrh0GHAFsBYwAxob0wKzxQosInQk8rqpDgMfDseM4KwldQQFDy0r4j8CvRORF4GHgPlX9IHX+AOBfGfPaEZisqlNUtQ64HRiZF2cktmcdwJ3A3iIShfDbVXWZqk7FXCQ7Aqjq08C8Avml07oBODijnI7jVJmuooChBXeEqk4QkW9goyHuBK7Ii/I5cFXGvAYD01PHM4CdisVR1RUisgDoH8JfyLt2cAv5raOqyWC+jzArvgkiMoawdZOqMmDAgJbvxHGcLk059USL05ZVdSJF1odQ1V+XTZIKoqqxiBSclaKqVwNXh8N4zpw5JaXtkzUcp+tRqp4IkzUKknUBn3IwE1g/dbxeCCsYR0S6Y7s8z814bT4fi8jAkNZAYHarJXccx6kQ7amEJwFDRGRjEemJdbRNyIszATgu/D4MmKiqcQg/QkRqRWRjbA3jF1vIL53WccC9ZbgHx3GcstJuSlhVVwCnYB18b1qQvi4i54lIsmPztUB/EZkMnEYY0aCqrwOKjdZ4CDhZVesBROQ24HlgCxGZISKjQ1oXAPuKyLvAPuHYcZwS6UqdZNXAF/BpjC/g43R5Cind9l4gp1TF32kX8HEcp3Pi1m3HIbMSFpHvAacCmwLbqupUEfk5MEVV76qUgI7jOJ2ZrFvejwH+hE1Z7kHOrJ6D+Xkdx3GcVpC1Y+5HwImq+htsFbWEl7GpxI7jOE4ryOqO2IzCQ8IWAf3KJ47jdG6K+WLbu2PJ6ThkVcKzMEX8fl74V4EpZZXIcToB3vHlZCWrO+JG4E8isjkQA71FZH9slbPrKiWc4zhOZyerJXw+tmzlm1in3Gsh/O9Yh53jOI7TCjIp4TDbbZSInAvsgFnQL6vqexWUzXFKoiUXgPtdnY5IJiUsIr8ELgq7XExLhfcGfq6q5xW51HEqhvtdnc5AVp/wryi8jVGfcM5xHMdpBVmVcIR1yOUzBPi0bNI4juN0MZp1R4jIVEz5xsBLIlKfOl0DrAvcUTnxnI6Ij3V1nPLRkk/4GswKPg+4FdvOKKEOmAqMr4hkTtVxn6vjVJ6W9pj7LYCITAfGqerSdpHKcRyni5B1iNoNLcdyHMdxSiXrELUGCnfMAaCqNWWTyHEcpwuRdcbcsTRWwj2A7YHvACvFjsuO4zgdkazuiJsLBF8vIv8B9gT+UlapHMdxught3d5oInBxOQRxGtMR9vlyHKfytFUJjwAWZI0sIiOAy7Axxteo6gV552uxFdu2B+YCh4ep0ojIWcBooB44VVUfbi5NEdkb+CM2IeVzYJSqTm71nbYDPiTMcboeWTvmHskLioBBwFDgnIxp1ABXAvsCM4BJIjJBVd9IRRsNzFfVzUTkCGypzMNFZBhwBLaLxyDgsbCsJs2k+RdgpKq+KSI/DHKOyiJre+KK13G6Nlkt4Zl5xw3AS5hF+njGNHYEJqvqFAARuR0YCaSV8Ejg3PD7TuDPIhKF8NtVdRkwVUQmh/RoJs2Y3K4fqwGl7WXfDrgCdhwna8fc98qQ12Bgeup4BrBTsTiqukJEFgD9Q/gLedcODr+LpXk88A8RWQJ8BuxcSKiwiemYkCcDBgwo7a4cx+lylFNPtNUn3JH5KbC/qv5LRH6OdSAenx9JVa8Grg6H8Zw5c0rKZODAgW2V03GclYxS9cSgQYOKniuqhAv4gYuiqvtliDYTWD91vB5N3RxJnBki0h1zI8xt4dom4SKyFrCtqv4rhI8DHsogo+M4TrvSnCWcryDbyiRgiIhsHNI+AjgqL84E4DjgeeAwYKKqxiIyAbhVRC7GOuaGYLs/R0XSnA+sJiKbq+o7WMfdm2W+H8dxnDZTVAmXyQ+cTm+FiJwCPIwNJ7tOVV8XkfOAl1R1AnAtcFPoeJuHKVVCPMU63FYAJ6tqPUChNEP4CcBdYcr1fOD75bwfx3GcchDFcdElIZoQXASbhsP3wt5znYn4ww9LG0TRFp9wqaMj2nuyhsvXejqybODytZVZs2aVFD/4hKNC57KOE64Bfgn8H9ArJLZYRC4CzlPVhpIkchzHcYDsoyPOBU4GzgKeCmF7YPvLdcMUtOM4jlMiWZXwKOBEVU1vZfQfEZkF/AlXwo7jOK0i60afawOvFgh/FVirfOI4juN0LbIq4cnAIQXCDwHeK584juM4XYus7og/ANeKyHbAMyFsN+BQfOiX4zhOq8lkCYc95kZi6zX8JvwNAg5S1ZsqJ57jOE7nJvPaEar6APBABWVxHMfpcmQdJ1wLEJaSREQGAwcDr6vqk5USznEcp7OTtWNuPHAigIisgq3bcD7wqIiMqohkjuM4XYCsSnh74Mnw+2BgIbAOpphPK7tUjuM4XYSsSrgftqAOwN7AeFWtAx4DNqmEYI7jOF2BrEp4JrBNWENiP2yXZYDVgWUVkMtxHKdLkHV0xLXAbcAsTOk+EcJ3BN6qgFyO4zhdgqzjhH8HfA/4K/A1VV0eTjUAF1VINsdxnE5PKeOE7y4Qdl15xXEcx+laZFbCIrItNhJiqxD0BvAnVf1PJQRzHMfpCmRyR4jI4cDLwGZYp9xEbFTEy+Gc4ziO0wqyWsK/A36vqr9IB4b94X6H7WbsOI7jlEhWJTwQuLFA+E3YlkeZEJERwGXYppzXqOoFeedrQz7bY1vdH66q08K5s4DRQD1wqqo+3FyaIhJhs/q+E675i6penlVWx3Gc9iDrOOHnMMWYzw7Av7IkEMYYXwl8ExgGHCkiw/KijQbmq+pmwCXAheHaYdjOy1sBI4CxIlLTQpqjgPWBoaq6JXB7tlt1HMdpP4pawiKyS+rw78BFIjIUeCGE7YwpzTMz5rUjMFlVp4T0b8eWx3wjFWcktp8dwJ3An4NFOxK4PSwgNFVEJof0aCbNk4Cjkk1IVXV2Rjkdx3HajebcEc8CMY23aS60l9yNwC0Z8hoMTE8dzwB2KhZHVVeIyAKgfwh/Ie/aweF3sTQ3BQ4XkW8Dn2AujHfzhRKRMcCYkCcDBgzIcCuO43RlyqknmlPCG5ctl+pQCyxV1R1E5BDgOuDr+ZFU9Wrg6nAYz5kzp6RMBg4c2FY5HcdZyShVTwwaNKjouaJKWFXfz5K4iOwFZIk7E/PRJqwXwgrFmSEi3YHVsA665q4tFj4DSCaY3IO5VBzHcToUmSdrpBGRAdg05jHYeOGaDJdNAoaIyMaYojwCOCovzgTgOOB54DBgoqrGIjIBuFVELsa2VRqCrWkcNZPmeGBPYCqwO/BOa+7VcRynkmQdHQGY1Ssi4zAr83hAge2yXKuqK4BTgIeBNy1IXxeR80TkoBDtWqB/6Hg7jdDpp6qvh7zeAB4CTlbV+mJphrQuAA4Vkf8Cvw/yOo7jdCiiOI6bjZBn9fbHlOFoYFtVfaO5a1dC4g8//LCkC9riE55x4PCS4q93/6RW59UaXL7W05FlA5evrcyaNauk+MEnHBU616wlHKze97HP+rOBgar6g5JydxzHcYrSkk/4UOyz/k+qOr8d5HEcx+lStKSEv4u5IWaKyAPYCIOHKy6V4zhOF6FZd4SqjlPVvYFtgWmYEp6O+TY2rbh0juM4nZysO2u8q6o/x8bh/hR4ChgvIu+IyPmVFNBxHKczU9I44bCt0ThgnIhshm15fzxwTgVkcxzH6fSUNE44japODtbx+i1GdhzHcQrSaiWckNr003EcxymRNithx3Ecp/W4EnYcx6kiroQdx3GqiCthx3GcKpJpiJqI9AHOAPYB1iFPeavqJuUXzXEcp/OTdZzwX4ADsTHCH2LbHjmO4zhtJKsSPhDbfv6xSgrjOI7T1cjqE64DPqikII7jOF2RrEr4SmyKsuM4jlNGsrojNsS2CtoL+A9mGX+Bqo4pt2CO4zhdgaxKeDNM+YIp5DTeSec4jtNKMilhVd2z0oI4juN0RVq15X1rEZERwGVADXCNql6Qd74WuBHYHpiLjciYFs6dhW0wWg+cqqoPZ0zzcuD7qrpKBW/NcRynVWRWwiKyO3AU5o7omT6nqntluL4G6+DbF5gBTBKRCXk7No8G5qvqZiJyBHAhcLiIDAOOALYCBgGPicjm4ZqiaYrIDsAaWe/RcRynvck0OkJEjgYexWbL7Ql8BqwLfAV4L2NeOwKTVXWKqtYBtwMj8+KMBG4Iv+8E9haRKITfrqrLVHUqMDmkVzTNoPT/CJyeUT7HcZx2J6slfDrwU1W9UkQWAqcBU4GrMQs0C4Ox/ekSZgA7FYujqitEZAHQP4S/kHft4PC7WJqnABNUdZaIFBVKRMZgm5miqgwYMCDj7TiO01Upp57IqoQ3Bf4RftcBfVU1FpFLMAv512WTqAyIyCDgO8AeLcVV1auxxgQgnjNnTkl5DRw4sFTxHMdZySlVTwwaNKjouayTNT4F+obfs4DEH9sX6JcxjZk03gppvRBWMI6IdAdWwzroil1bLHw7bFjdZBGZBvQRkckZ5XQcx2k3slrCLwC7Af8D7gcuCZ1eI4FnM6YxCRgiIhtjivIIrKMvzQTgOOB54DBgYrC4JwC3isjFWMfcEOBFICqUpqq+jvmsARCRz1V1s4xyOo7jtBtZLeGfAU+H378G7gMOAF4HTsiSgKquwPy0DwNvWpC+LiLnichBIdq1QP9gtZ4GnBmufR1Q4A3gIeBkVa0vlmbGe3Icx6k6URz7hLcU8YcffljSBW3xCc84cHhJ8de7f1Kr82oNLl/r6ciygcvXVmbNmlVS/OATjgqdK2WccE9gBOYKuEZVF4jIRsCnqvppSRI5juM4QPadNTbARkGsB9QC9wALgJ8AvYAfVEg+x3GcTk1Wn/AlwL+BNYElqfB7gRZnyzmO4ziFyaqEvw6cp6rL8sKnkps04TiO45RIViXcm7w1hANrAUvLJ47jOE7XIqsSfg44MnWcDKn4Mbmha47jOE6JZB0d8f+AJ0VkaLjmLBHZBtgS2KVSwjmO43R2MlnCqvoytjDOMmzVtK8B7wA7+eQIx3Gc1pN5nHBYo/d7FZTFcRyny5HVJ+w4juNUgGYtYREpNCKiCaras+VYjuM4Tj4tuSO6A9OAvwMfVFwax3GcLkZLSvhg4ETgF8Bj2OLn96lqfYXlchzH6RI06xNW1QmqegC2s8Yk4Apguoj8Nqzh6ziO47SBrEPUpqvqr7Cdlk/EpjG/KyKrV1A2x3GcTk+poyO+ju1eMRybRedTlh3HcdpAi+OERWQtYBS2g8aawE3AV1T1zcqK5jiO0/lpaYjancCB2B5z5wJ3FVhJzXEcx2klLVnCh2BD0+owa3iUiDSJpKr7lV0yx3GcLkBLSvhGciumOY7jOGWmWSWsqqPKmZmIjAAuA2qwfeouyDtfiyn+7YG5wOGqOi2cOwsYDdQDp6rqw82lKSK3ADsAy4EXgRNVdXk578dxHKettNvaESJSA1wJfBMYBhwpIsPyoo0G5qvqZtiWSheGa4dhozK2wjYbHSsiNS2keQswFPgStij98RW8PcdxnFaReRW1MrAjMFlVpwCIyO3ASOCNVJyRWAcgwJ3An0UkCuG3h07BqSIyOaRHsTRV9R9JoiLyIrZJqeM4ToeiPZXwYGB66ngGtkZxwTiqukJEFgD9Q/gLedcme9s1m6aI9ACOwXYBaYKIjAHGhDwZMGBA9jtyHKdLUk490Z5KuFqMBZ5W1WcKnVTVq7E1MQDiOXPmlJT4wIED2yad4zgrHaXqiUGDBhU9155KeCawfup4vRBWKM4MEekOrIZ10DV3bdE0ReRX2GakJ5ZBfsdxnLLTnkp4EjAkLPwzE+toOyovzgTgOOB54DBgoqrGIjIBuFVELgYGAUOwEQ9RsTRF5HjgG8DeqtpQ6ZtzHMdpDe02OkJVVwCnAA8Db1qQvi4i54nIQSHatUD/0PF2GnBmuPZ1QLFOvIeAk1W1vliaIa2/AusAz4vIv0Xkl+1yo47jOCUQxbHPxUgRf/jhhyVd0Baf8IwDh5cUf737J7U6r9bg8rWejiwbuHxtZdasWSXFDz7hqNA532POcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq4krYcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq4krYcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq4krYcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq4krYcRynirgSdhzHqSKuhB3HcaqIK2HHcZwq0p5b3iMiI4DLgBrgGlW9IO98LXAjsD0wFzhcVaeFc2cBo4F64FRVfbi5NEVkY+B2oD/wMnCMqtZV+h4dx3FKod0sYRGpAa4EvgkMA44UkWF50UYD81V1M+AS4MJw7TDgCGArYAQwVkRqWkjzQuCSkNb8kLbjOE6Hoj3dETsCk1V1SrBIbwdG5sUZCdwQft8J7C0iUQi/XVWXqepUYHJIr2Ca4Zq9QhqENA+u3K05juO0jvZ0RwwGpqeOZwA7FYujqitEZAHmThgMvJB37eDwu1Ca/YFPVXVFgfiNEJExwJiQJ4MGDSrtrtrA+g+81G55tQaXr/V0ZNnA5Wsr5dQT7eoT7oio6tXA1a29XkTqyyhOS3QDGtoxv1Jx+VpPR5YNXL5GqGpNudJqT3fETGD91PF6IaxgHBHpDqyGddAVu7ZY+Fxg9ZBGsbwcx3GqTnsq4UnAEBHZWER6Yh1tE/LiTACOC78PAyaqahzCjxCR2jDqYQjwYrE0wzVPhDQIad5bwXtzHMdpFe3mjgg+3lOAh7HhZNep6usich7wkqpOAK4FbhKRycA8TKkS4inwBrACOFlV6wEKpRmyPAO4XUTOB14NaVeCSRVKtxBrA7PbMb9ScflaT0eWDVy+ihHFcVxtGRzHcbosPmPOcRynirgSdhzHqSKuhKuIiAwVkUNEZEgV8h7b3nmurIjIGiLyQxHZugp5R+2d58pAgdm2Ky1dfpxwVkSkN7Cpqv4vFbYasCswB3gNm1K9GXArsA5wLtAbG5kxFlhVVT8L1z6CzeqbB/QXkVGqelMb5LsXUOBuVV2S4ZKjgR8WSWtX4F+hM3ULYAEwV1WXp+KsARypqmNFZBQwQlWPCOc2AKaraiwitwEPqOrNqWu7qWqDiHQLcrwIbA18V1W/nU4f+CtwtKreGMIjQjmKyDeBPYFbgFnAsdiknHeBTYMMlzZTZusA66vqS+H4QGz6+3QgBr4MDMWmxTcAPUTkWODREPZqyH8B8LCqfiQiB5OrAwuA84BNgPeACNgO+BXwJnAC8BG2HgrAHaq6REReA/ZQ1XnATBHZVlU/CTLWAGcD96nqq8XurcC9boCtyfI68HEon3dVdaGIHKmqt4lIj/QzTpX311X16VTY48A+wFBVfTOEXQ6craoLU/HGAH/PTzOcGwScAvw+uUZEtgIOAP6pqv/Mi3868DQwHBvt9CWgtoV73jKRLxw/gs2evTuUc1H5Wkh3beAc4C1VbbMx4x1zGRGRXwGrYy/XxsD3sRewJ7Acm0rdCxu3vAzog73I3cL/+cDnQA9slMfe2Iu9IoQ1AA9is/2Gh+Pl4Zp7MGWwLfA+cFT4vz/wCDAlyDYLGICNif43sGqQ8+Zw/bzw1w/YBnv5G7AFjl7Gpn0/ByzGpoqfA3wtFEE9MA24C3uZvx6u/SlwJvAMsArwEnAa8CNgN2yo4E+wyn84sC6wEaaIhgKjQtqfAWsC44CdgQ3D/W+EKcV1gywXhPtaGp5DjCk3gEXYKJnaVNh3sAZxGLb2yBtYg/l14FuYIfJkKNu1wrPIpw57pqvmhS/AGtkeIb+Psef+KTY2/VZMWczBGtzkZavH6kVSNz7DnknyPHqm4kbY85iFPY/9gO+Fc5Ox578EGx1wM6agDg3XpNNdAxs/PyBcm0xueA9rJJ4JZfQHYHOsTu0efm8KPI89l0SmQjQAD4Q8voyV7cfAb4BDsLoXAQND2sk1zwD/wupHLdbIriIimwK3BdnXCvcSA68A52P15x7sPbwRe28ODfn8E6tzv8Dey59ijeNU7B17Hxvq2oA9xw+CzD2x5/1WKNPeQF8gMUZuw97dbtis3DWLlEVmXAlnRESWY0NgBpKrhPXYS19OEqWSVi6lXlsJ2pp2A8XdXyuozlfZtWRb2KnYc04rynRYoePlFFbwbeEjrHEqRFueVyXrUaXyTtevOBWW/9w+xRRtHwo/v+bkSoyqL/Isx8w5d0dkpxtWXukHVm4FTCr91lTESr44bU27uf6HatXDrCvrFXvOhcokPyw5LrcChuIKuJAcpVBNP3Rr807XrySNQs9t9VbmlRhGZW+gvGMuOx+T+5RzHKfrURF96Uo4O//Ay8txujpRkd+txpVKds4J/zvySlKO47Qfp5QjEVfCGVHVj4BnsTJbjPmGOpJCXll7WCtZhitrmawM1NF1yje5z9exETjJ8UXlSNyVcEZE5BBV/To2ZGx1rLf7BUwhtweFKnx6PHBE2xRaQ/hLFkFZ2oa0EuIiv5PjFSHPeuylTn4ntOVFTzpROjLzW3ldUnZ15MqrDuu3SMcpVOZZ05+L1fXkOBkyGYd83goyzAbewYYvZkm/AZgYri31+RSLXyx8MTY8cCa5cvq8SNzmSNwO/yM3jHA7bGhcm3ElnJ1LROQFbBxjskHpZuF/Swu7l1L5lwIPYRU+rVSTivBiKqx36rp0HsWUcXNyJONWk87HXkXiJY3OCmzsbHNpJjI3YGNak7hLwrnkrwYbNpT8TuiRSiNLo5CWJcLGydanwpcHuQnhbWlA02U+C3gqFb6gQPx6cvUkuW4NTHmWqpAS5dKTxuW1Vup3UrZpWQv5MGeF/w2p//OxsbSrpNLqRu55rIONM++BjaXdHBvPnXWo1140HWmUkDyvBpqWSRTOH593X8Xevz5YfR6MlVMcZG5OETf3LA7HxiovxSbqlGVUj48TzoiI7IPNlAJ7AXykhON0PWKs4ewBLFLVfm1N0C3h7FxEblypK2DH6ZpEmHujDh8d0e5sgu/O4TiOTZKppbjLriR8xlx2ZtO448NxnK5Jn/C/LCN73BLOTh9a7oBzHKfzk3SklcWIdSWcnSHY4h+LsB7Uz4FPqimQ47QB75FvPYkv+KhyJOZKOCOquggbWtUXawH70nhIUGehI7yciQzJcLKONCmms+CLxTemNfX+1nJk7Eo4IyJyMbY2KTQd71lOqq0EO8LLmciQfO61tp62ZkLAykhXuMdKk7Xep8v6yXJk7B1z2fkpuQdQiSUsEzqCEuwsdJX67XWm/UhmpnYDvlqOBN0Szk49NkMMcp/JjuN0PRK9+atyJua0zKzU70pawo7jdFyS9U4gt3xBm3AlnB2lbbteOI6z8tOdnN48ohwJuhLOzpnYZpiQ8w0vKxLXcZzOS7JA09xyJOZKODvbACeH33Xhf7NbbhegM/did+Z768j4BKL2I1k6NpmufE05Eu0qvcfl4DrgMcwf1NpNGzuzG6Mz31tCpXYhbstOzJ2lf6KaOzxnJVk6NjG+DilHoq6Es7MNsCX29eBWX9ekUkqiEjsxr2x0dAWcJmkwXqYMjaC7I7KznFyjtTJVGMdxykNifCXv/8xyJOpKODuTaLy7g1vDKyc+xttpLRG53TxicjNo24Qr4eycgW0nkzC1WoI4bcJdcCsvHcHwSW/L5WtHtCeq+izwzVTQRlUSxeka+KiHpnQEN+DHWGPwMjClHAm6Es6IiHwJ2I9ca+xl1zVpL+XYWUY9rMwU2q16HawxWAP4WTkycUWSnf8AB2I70XZ2K2U5zd9jWQapd3CKffq6cuw6pHerhtw78SnwiapqOTJxJZydp4GPgDXJbZ/dWUlvNV+I/u0lSBtpyzrE+fdfyCrqSlTzfheXMf/8OpGljiQdckl/wqfA5mWSx7e8LxURWYE1Xh3BP7Wy0tqB+flDhFYmst5zskxipfKIQx6VsOirPeGiufzrKXzPWerUR9gGDjVY2dUDDapalo0+3RIuncXYFkcLab2l1ZFavmrI0toXNemVXhnJKndb3skseURURgEvycs/f12VhVS+rjV3/8XuuQ7bqizh8wJx1k1dnzSSPUTkvJIlLIAP18mIiEzHKtGqZUiuvRRJMiY2/zlX22LpzJRiyS6j9PVHKiVLW+md+l1H01mA5XhvWqIh/KXre0tTwmtp/Aw+AVYJv5P3JCnHjzG35CHh3PrlENot4ewcDRxTbSFaIN/S6E7hhjYq8rsY6TVUOwL591lN2RbnHRd7pwrJWEkFDK17v0uxVovF7dnKvIulu7yZvNIsxlwHaUqx+mNg49TxqdhXbzdgOvAC9hzfBuYBY0pIuyjuEy4REdkU2Ba4CzgPeAR4nMq/UFlYhFlXaxY49zDwDcyf1S3EK8WntYKcQi/mX+ss1NF4Yk76y2Ep9qyjAueykJRj1jKstLW8MlPpepj2Fy8hZ+0vwqzrH6rqtW3NxC3h0vkUuB5rdU8GniL3ws4DXiHnV1oCfAbMCeeaI877n/87C30prIAB9g3/I6zynoRZGFlJW9TVVMDtYTX0yMsnrWR70fyXRL7Fmz/UL/GVFlPcdanfMY0bg0qTv4HtAsqzZna5n1kiZ2vrYRZ5ksY1eU69Q9gi4IfYcNXjW5l/I1wJZ0REdg5+4dmYf6sPpvRqyD2oCZjCTcbR9gxxEsszf8GP9AtbaNeOYgq5NYo63ap3x9ZCLeSqWI41IsuwBiS/o6IBUxTJOhrJPPpy0twY5easzlLdEssw2Zfmhed3AC5J/c7PYyr23OMi5xNFkZzvG/7/O/zPL9/0M8nSEZn4Qe+msQJvDYmsSZ6r0dQKT+5jEdmfe3P3UCiNlupUMb2VXtchzQrg9vB7dob0ofAQxXrsvf8T5g/epIU0MuFKODsXATdgvbwJPTClmzAKm1W3YTiuCX9rAgOBQXlptlT+6fPFrK+WlFKiFPJfsHTjATmFFGMV7TWs9Z+HVb7Eaq4Lf4liqk+l00Buokf+Qjn5lX4x9lWRzj+htRZOKfU5udeIxm6Z/C+ShZjVk9xvkscfMQV6DqYAk/J5OpVWA7lyzX9OXwn/V8kLb+kekuc5LRU/xjqLkg6oT1Pyt/QFVipJuR2DTePP2vBNorDxUKj+ttT4FDuXXtchTXdyWxGtjZVZ8rwWY/7eT8m9Ly8Bu2ENzc5B1oXAZMwwGQAcR65BbRPuE86IiMzDCj9tpaX9dclSlzH2kOvI9cwuwaznpONg/RD3aawjYEMa92SXOnIhuTb5n67gbR0Jkb6+UFqLKFwZ25pvosAS/2v6d7kpNIogeUl7FDmfNd3kGSTXJ+N0l2AK+G2s0dmU3BfIGlg9S/KeHcLXBnYBXsWsMcGUx0CsbiZlszzE75PKN+s9LMTqaiJ7/hdB4o6pD8d9U/e4JNzD7PB7W1rnTsmvO+n+iLewiRLJvSSddonBszycy9qQ34F9Ca2HKd7kuulYeddi93oB5n48GrgP+A5wuqruVNqtNcUt4ex0V9UGzBpOemAT3+FschZBUqZ/xzrsegL9gDewB74x9mBrgD2xhYCSsZvpSp9Y3EtDOs+G43HAeym5/gs8EeR4FHv5Dgjnlof0kqnWiYz1mMukntx+WcmqcPOwXuAJWKORbnQichZuouj7kLOO0p/D9anwYiTnV6TiPYdZeVGQJSmTXsD7wB6YlQ6NXSJvhbKA7MtVNpCzKNNTU5PZUQuwclqROpewGFM0C4Oci1U1UUbpuhDR9IumG1ZuAJthCjjCvjwWY3VhEbl6sTbWUPcBjg15/AxTltuEdJ7FlHMi5yo0flbF3Fz5JEPJCk1I6oktWtOQ+ltMbgzwJ9ikhmHAcHLKeRHwLvZOJJb5/PC/0MibdL75Q86Gkqv/MbaS2dPAB8AzIezjcN2sIE8DuS/W5Zil+3A4PghTqF8N9zwHq8frkzOwajDL93jsXYyBPwOXUgZcCWenl4jciJXZR9iDfQV7IFPC39ewCvkJ8CA5n+ocrPJ8D6tg+R1iL6V+vx3ST3yFvYC9Q9oAh2MvbcIWwF4h3Z2xivNAOP53iLM6VpEWYi/o05giizFFsxj4K/ZCrIk1FIOwl757kPdMrFI/FGTbAFioqt1UtRtmIcwHbg55jgnx3gjHaeWUkLxsifVej33iXhXODaLxC/khsD32+Z+UTZLOUMyaSY6XkJvdlCjPO8m5UhZiSnw09lwOB+arandyin9NzCpNlEANpuiWAW+G/FcBrgRiEflDKLuvkusDiDHFkyidpCxIpZncY3esXMH8sen4M8J9nBzKaz72XOdjxsCumOVJOD+enFV3N00VGwWOY+C28HsJ1qgvCsfLQ94TsbJbjlnBfclNc++P1flp4ZoeWBn3wcrlE3J1f43UPSdhiRzpxryQjtos9fs4YB+skRqONRSDwnXdwr1vClyRkmkr4Oshv0/DX6Jwv4uNfFoR5EoMrvUwA+yzkO6dqpqUVZtwJZyd32It8HvAl7GyG4pVvi9hyvCXIW4/rNU/BDgLewmTFr8eezlnpNJeBfhn+L0FZo2kRznMwCowWMVYjlXUZzDF+FRIdwy5mUufY1ZcYgUljUU9cAtmOXbHKlcf4DfkxryuhfksE2VRE87Xk1M+55J6sVX1VuAPwMEh6JpwHxuSU4JTadzJBY39eA3Yp953U+fS7AJcSK6c80le7BpyY1XTn6aHhfBeWNn0Ae7FlOh1QN/Q0K7Aync81vmSdMAsxj79e2DKclG4t7MwZTQMGznzj5DPXHLKfEZIM7G0E+u/DlMem5Ar7zexhrkee46vYM85cWs0qGp/TBmOD/ksxZZXTNI8htzn+dC8csr/VE+7wRLfaW9MuSWupgasz2N3zAI8ldzu44mLohf27CaRU6i1wLfD72Oxur4Y+6pJ7ncWjRumYi6MaSk5k/6HF1Ln052ISb/Etao6DRhLzu/bK+QRYY3K0Vj5zQSOBEZi70YD5uZ5HnNPALwTwjcqImPJuBLOzjuq+musZYyB80P4p5iC/AizWJMxpj2xl/wKzIdVg5X3eZhi+la4filmLW6Vyqt3uD6pyIMxyygGXgReD+fnYxbqbzDL61py1mFfbFhaouyXYI1FA6Z0Tgrp3RXO30LuUzTfH9gNq5QDMSW7FOuAPDFdQKp6cZD1QuBHgGIKpBvmZlgVU/6f07iDM8mrO+aX2zp1bim5T9/lwP3kLKf0iITFmKtmMo39n9Oxl/djcgvBzFLVjbGG5KLU3++wRnZ+kGU7rDH9O7mXdw729bAGplCSBm4CcDH2JdAL+zz+b0rG/2LPLPFdfkbOn7lbyDcp76GYYq7BnuNwYAdy7oU/isheWP3aCbP2ppJbWGoVcs99DI2/nJpjCXBJ+L8Eq6vLQvrfx8aZ34t1Rk4J/tCFqfg1WB3cNdzvEuyzvxZ7T04M5Vob0k2e4+ZBzuRrIemkTbuI7sW+WpLzEVaeD4Z8zqSxC2w5wQgQkX9iCnZ1cvUiaYiOxDbw7Y3V3RFYoxoD/y/EuwrbReNkrEP2eOyLrCy4Es7OVeH/McBSVf0F9vLMwz5Rt8Ra/LexCjIde/C3YBXiHKzyLMYUy6HklMuV5D4/6zFFch6Nh60lVtQmmEW7GNgfe2luwV7qRZhVATlr69JwfGX4X4O9sEMxRbFjCD+O3Gd8YmlDTlGswF6oxJpfD/siAEBE1hORu7FGYh3MOt8Hc6M0YJNaXsAUeQ1m6a3AXryl4Z7/Q65nP3kBe5GzaHtgjUBPcqMOGjBFMBWzIG/GGoG3wvWjsBfrOqyxfIqca+cxoE9oXJ9J/d0Q0n0Os/ZeJtdQbE3ORZGUUQ9MQV0T8usVyu2o1H0cRWO6h3KoJTfSIlFKC8n57D9PlUdyzRGYsqshZ3WuFmT7Y5D3w1C+EvJIrPYk/bSb5uPwvxb4CaaQemHjYXtin+5/w+r2msDeqvpEuGZeiJu4JNbB6sbW4dr9Qrn0xurif8N93kvOzTMHe2bvhOMLsXqRdG7XYNbpP1JyJu/Gr0PaF4T0IqyRrMW+SH8ZZNkDU8LLw/3eEPK5mZxB8FK4JlHySd1fiFnxp2FfY/dRxmnYPjoiIyKyUFVXDaMkuqtqvxC+GnATpoSPwVrm1bDPrd5Yp0rSybR6SC7xgS7EHvoCcp9ziYW7OrmK9g5WEQenRIqwipZ2a4C10g+RswbzZxUlL95+4f+qmK90Bmahf5yKuw6muBLL/ArMKvs9cA/2Qp0V4p6PKcE7Mf/qPpg1fEMol5uCHEmH1BxMmX0e7rsGa7jGAWNUtb+ITAtx1yY3WyntXklm/V2PWSpfwhqTb4SyeRL7nFw15H+zqn6Q3JyIPACMVdUHRCTpmEzojT2bj0M5DgiyLw/3/gQ56++qIM8/gzw7YQpwBY3XVEiTWHu15J5V4nJaC2tka0N+k7DGa22skZ2IlfWlId93gauxERNzw/3WhrJNOk7TdSB/NE0StgKrH0kj0pNcp+cdwO9VNX9MNeE5Jc+lB02nGXfH+iu2wb44tsQMl5uxr4cGrCHuFe47PaqDkP/jWAOwKfbVcHiI8yn2nOrIfQWmOyITORIXxudY49szpLUFOT9vHbkRUN1S6dSF479g/S/TgbVUdXh+WbQGV8IZEZHF2KiD+7AH8628KEdiVkcPYEVKSR+KWappf9UyzPL7BKuc0PwU4sQS2jcV9hg5ZZRQj1m34zBL+i2slzepkAtoPDGhNlx/iqrellJ6q5FTAPPJNQAROSstnw2A3qpaJyJ9yHV2LMLK7fHUvSwkV+GXYQp5MKZgBgUZ91PVZ5LEReQsTNEmY5fXxF6oiVhnXo+QVndyQ6kmY8o37TdMcxOwgao2mRwiIt2xl+0a4BTMDfI3zKI6Nsj7INYJ+jvMatwBa7iOwl7yJeE+kxERSU9/H3IW/Koh3q+wr5pjsEYlsfLnYKt4LcKsvtsxCz1pkP+JKZP+Ic867PnMDnkmLqgYU16bhuvTfJ2ceyAZAdM3yJo0JpNp3LkIgKru1rRYm5RlMpzuv6GMupMzMgoZCXHq3OfAlqo6W0SODWU1F+ucuwozHiZjX0JrYnVtCdZA/QRT6msD/wOGhDJ5F/PfvxWOB2JuM7D3sRdWBxO//lohn6Rc+gNHl6tjzpVwRkSkHrNuNwpBH+dFibFPwT8BsarWBGV0DuZb3BCrxK8CP1PVZSHdpIL2wyrcXzH/2ArsRVtBTllOT+V1LnChqg5sQe5pIX4/zPJMV/wYGxHQPxX/70HehzHl9jHmurgBuFRV05NT0vl8ljQ84Xieqq6Zyn8jcsOEasi9hJ9jyu2UEK8HcDbmj/u1ql6USrMf5ns/HlOO66rqZyKSDEdKeu0/o6nPblbecYy9XGuraqPOQhHpDfwfpvTuxhRkL2AVVX0qxDkQe9ETf+v12PN/JcjxRxqPeumBTfo4HFMgX8Ve5k+x4WX7hfzqMGUxKMTZCxu9MURVF4S8F2IW5U9ons+xRuHGINNrwGXYp3260/N+rJ8h6Yy9Hmvk98U+5bfCFPmP8jNQ1RtakIHwfN4j158CVgf6kfMPD8YU4gfYSIq+5CzX87GG97fh2m7h2kKGyyLsPYsxt8g0rJwTZdwt5DcjpHEf5t4ZrqpvBHk/xd6VCzEXRA1WfxKjoUe51hIGV8KZSZRMUCp9yA3dyacG+Juq/iYotB2wCrE5VtFrgSdU9Uch3RhrdZPB+THWAic+u1rMB/w65kdeBXupDgD+o6rblXAP/ci9/HOB51X1s7w4HwJfDpbHethLsQdmsR2nqlIk7eRLIXm5x9P4ZX8U+DnwiKr+T0Q2wV7M5DM0+RyuC26f7bBP4NeAUYmcqeeQzi9xreTzZvKjkLIQkUnA+ap6b174x0GmzzD3BpjC3RzzwwP8GOsT6E3O9ZSsO5t8yi/HvnZ6YGVeD3yqquuISC3WUfVzVV0/KKq5WOO3X5D9fcwHCfCcqh4rIoOBf4WyfAXrNNw6/B6lqtNEJMIaqUT2ZLJDDblP7eUhv1Vo3CG7MJzvTc5n+xmmzPuFctgK+7r4maoWWn83v5yPa+b0X4EfYA3N17BG6VdYY3Q59hyWkes7AFOm3YOsbwGvqeoPg6X8sao+LCKJi2E+pozTroVl4b4bMFdfMnpkBlaWE8O5LTHf+jTMCJkbfj+uqslwyDbj6wmXiKpuVEL0EZh18QrWY3wn9uI+Tc6q+Fsq7hvYBI5rsIrzVUwJb4R1yC3AXo4VwEWqenqJsn9GbpB6MVZR1dnhd3/sZVWs4bmxmetmY51fCXMLHF8A9BOR1cm5c+ZiVvE8TIn1EpGTMSX0U+AE4GUROVRVX0ulV4t1TiW95EmPONjL1x9T8i9QfEPGS4CrRKQGGK+qDSKSTFLoS27ECZi7JUrlOQizruow//dz2HN6Hxtrq5hbYnfsha/DFMaxwUV1OdZxm8j265Rcy8K1w8N9XUvOBXQ45oK4KtzbFMxSPBpTkAdjX1J7Al9V1UkAIrIF5lteFVOqS7DP8ITEx75aKMeF2DPvgX0tLRWR2zGL9WrM/fYHzA3TEv8Dlqnq/4Isa5NT5jXAXap6g4hsiD33n2Dl/QhmACwHNlLVZaHuzAa2VtV3guL9c3iG38a+EMGeUR/sy3Mx1oC+i7kGwercSeT8ye9iyvguzIXXD1P6awIHqerbQfbTyA0nLQuuhLOTP2Y1C31VdZaI9FXVl0VkNVWdHjrzEq4iN8vtAOyTfSD2Ob0a9uKMwTqZ+mEv3B/zLdgy0l1ExmKdWxuGsH7Y8KCPRWQvVZ2Yf1GWxim4dM7BLJ1kuFXickmsG7BP+Y8xt84mInIm8IyI/CSV3CJV3SSk+wzmungsHI8P6V5PM8pCVW8VkXUxK6dWROaQ++Q8PQy5S2T/FOimqhuLyAhMEa2CNQCbYUp/KKZUbgv3dBumHDXIchQ2KmAJ9lXxWEqcd9I+xnCvm4fw9HC+BzC/8P5YA79eUJBPkxtdcAxwaqKAA5cHWZdiijj5BD4y3MuqmLL6rqreE2SYgynAHYPyOwDYKii/CVjDk0UJX4o1Mv8Lx1eTU+aXEZ6Pqr4vIktVdYiIfA3zvddjCvM3wOmYz/YjYJqIPEbOUEncbX8MjVyapPw2wt6jWZgR8CnWmH4Dc7/Mx4aZ7o5NdGqu/MuGuyMqSOqT+UHMx/kbrHMp+Q82pOlGTDH9AustXoZ9vh+AKemfYa1/pKqrVFDeB7CXO9nyJRnWtD5mtTUQFGMr01+E+dguwoaK7YZ9ViefmcmsvYWqOijv2j0wpbZ28Ld/4YMOymJwylL6hJyyWB/7lF+/GbmyuGn+ibmWRgBnYEpsV0xxJZb3bOyz/f3UpRsBvYJsfTErdENVbTSqJd+n3hKhbsU07iAej1nC44EjVfWBVPw5mBL+D7kheouxL64PsOf8v1AOkzCL8XysDnwZU/hXq+oGqTQXqmqLQ7VaeD7J7MVkksh4GruxemANyGJV3U5Erie3sPoR2JfSeFVdT0Q+CfKPw2YPfkBuucn7yHWIQm7M/baq2je4eZ4F+pfyHMqBW8KVJflEr8Gc/BT43w2zJvpiCinCfIUzsI4RwSyn2UB/EdmYxjPVppRR3t0xJfQX4BZVfQtARGZhHRezm7s4A/8m18M+H5v6eVXIY3DI+2xsXn4jVPVJEfkKuZcq/WWSHrO7MzYZ451w3fTw4hclo5vmDKzhSKzXWeRcBP3ITVhYjo26SPgFcLbIF670unwFXOB+slCL1Z27UmGrhONVgZtF5ApV/WU41zNc8wS5iSC9MYU4BfvqmYRZ68di7rJVsXq5P+be+MJyD89rQUZZiz4f7ItnA3Jun3w3VhzkuS8MD23AGr+byfnlE/fAU5iL4c8hvTVT6c7HlPACckM3fw2MF5GfY18PLwAHiMieNH7Hmnz5lRNXwhUk4yf655hiuZucjy5R0L3C32nhOBlmROo4fwpqW1gH6/w7Dvh/IvIfzCLKX+S8tZyBWSS9sYVTdgQInVR/xl6aT8lNtGiEqs7CviLIs8BexxZhUcw6aq2yKIqqPhuU+ebA2+kOKRHZHLPeZ4XO2LTV3YDda0KTDSKDoqzJf/kLyJBWBotorIDTJAplZ7GZdZCbxXcUuef5GrmNALpjivdb2DPfBussuxRTijE2rCsh8U1noejzwRTqv9RmMBZFRDYgVfYiMgRrND4it97FjzHlPIbcEquPY66gKzEXyBqpZB8K/3+PfY2tTeFGoFVffllxJVx9umM+pvnYi1KLdVClx67+LO2frBSqughzjdwYOkmOwSr0msBNInK5qv6juTRa4BNMwW6HWSUjRORLmF9wbsj7r+QanaycgVlKf8XK7Wupc6Uoi6IEv3OcOi4UbTdV/V7edcnPNTDfcbJCV0LSiKY7GgvRRBnk55XKcz9sVEVfbLgbmItrnfB7MdZJnJZtD8zy7YY1xGuq6o9E5GasA22LpHMqUIpvtE3Pp0jZr0Ljr5fdVHUmZrEjIsmsuRrMtZestTyd3LvVE1O8CwgrwbXW1dYWXAlXn30w63A1rCLsgo1f7Y+5Bwa0hwLOR1Xfx3yC54vIV7ExmjcFuVrL5ZgSPg+zaC8J4fOwTq2NgV9piYPgg5WaWEqV6ki5JvU7wiyrZjulRGQtzAVzHOajTDoQ7xCRbbDP7GQ686ISFUAjZR3yOirktW7I60pVvaMZ2Y7CXF9DQ3pjVPVvwY/+NPCjUJYvkDfhJU8hN0sZnk+hsk+GlyX3831Mqe6PuTf6YO6h32BfIqtgDcwgzPf7d6wh2hM4S1V3zXo/5cY75joAIrIqBSqoiLxAbkWvQsSquncZ5eiDTUP+MjZk51xstMCfMP+0qur325B+uoMm6aQ6FrNyCnaIdVQkTEYpEN4De+lHYb3uk7HP5Z9in9770VgpXxmUckkdcxnyGprvw0/FH4ONAlhObtHyFaraOxW34P11BIJv+DVynWxJgzQUU7bzMGOhF7lJFkOxGXtbYyNWklmPg4APVDXtpmhX3BLuAATF+3KBU38rEAZWeU4ltw5DubiSxrPlvkRuttwJWmS2XAn01DBTUFUXicgCVb2lpYtWMj7GlMP12IiX/2KKrw82MiFRlBsBklKUrRkC2SgvVX0FQESaWOhBAc/DrMXu2AiOv2MKezmwap5Punt7d1CVyAHYcMdkosrvsKnLm2puotF0zNq/Pwx/i9TWDvkd8DsR2VlVF4ax4VXDlXAHRvO20xaR/pilegK59SHKyTfIzZa7AuvI2V1Tazi0kdq8TqneRTqpVmZew3yeO2FfE4+TW9t2pKo+Dk0VZZahXi3lJSJTVbXJ+g6BZBZgDeYiuQrrKPshuR0lmptsU/EOqhK5Ahsy+BDBh01qopGqzhCR5ar6jIj0CA3KyFRHJQDhuKp60JXwSkAYx/pzcgvJfEVV32v+qlaRX4k/L6MCBtuKJt0pdTuFO6k6HPkvL0UsRVXdI3RqHoutP5FMzGkAdhCRV5pRlCVRIK/LReQRcrtdpEkU9kvYJ/rpmI8+mWn4ldCx1eEoVPbYWOITMev+ZcJSlnnPZFk4/gyre9B0Z22w4Z9Vw33CHRixhWR+gk3WeBL75Hy9gvm1tP5DRT5J051U+ZM0OgrSdKnLfAr2rIeZXz/EptQm06sfxDpdtyyn4kvNMhPM8r5OU1PbUwr7WKzz6iVszHAyvrlR/I5CkbLfkNykmBibVfcZjYdSboBZ9Mk6L1UZ/dASroQ7MGILyXSj6YpcX1BOpSi5Fc+KUbZKnNeb36iTqhzpdzREpBemiH+MWaUFFWWZ8zpWVb9ZJE6+wn4eWye7YPyORhaDAXMDXY354U9Q1Q/bU8asuBLuwLSnUmwPSu3N78xkUZRdSY5SyfpuhIlA52ITon5NbuNZoGN0NroSdtqN1LTT64FbU735s7A5/F1GCTvtRxh6eRu2NnN6hE+HMGK8Y64Dkz9TqBCaYWeDDkQpvfmO02ZEZG/MJfEKYfhaCO+ODSGsOq6EOzYlz9LqyJTYm+84bUJErsNWvTtVVe/MO12DrWz4iyYXtjPujliJ6MizmFpDS735jtMWROQm4MeqOq/AuVpgiapWdaIGuCXsVBFVfRZ4VkROJXQOVVkkpxOhqse0EKVDWKCuhJ2qo7aN+m3kliR0nDZTYJJHmp7tJkgLuBLuwGSdpdW+UjnOSsO1LZz/oF2kaAFXwh2b/ErU0efzO06HoaWF4jsK3jHnOI5TRareM+g4jtOVcSXsOI5TRVwJO47jVBFXwo7jOFXk/wNluNZOejZZKwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mean_feature_importance(feature_importance_dict, cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.])"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "idxs = np.argsort(np.mean(per_feat_pred, axis=-1)).squeeze()[::-1][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "mask = np.zeros(X_test.shape[-1])\n",
    "mask[idxs] = 1.0\n",
    "X_test_mask = X_test @ np.diag(mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "Array(0.36981997, dtype=float32)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_eval(params, model, rng_key, X_test_mask, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "['ZXDB',\n 'ZRSR2',\n 'ZNRF3',\n 'ZNF814',\n 'ZNF780A',\n 'ZNF721',\n 'ZNF680',\n 'ZNF626',\n 'ZNF521',\n 'ZNF429']"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_outer_df.iloc[:,idxs].columns.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}