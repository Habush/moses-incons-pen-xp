{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xabush/moses-incons-pen-xp\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd \"~/moses-incons-pen-xp\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn import linear_model\n",
    "from notebooks.manifold_reg.util import *\n",
    "from notebooks.manifold_reg.grad_util import *\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from autograd import elementwise_grad as egrad\n",
    "import scipy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def assign_cols(X):\n",
    "    cols = []\n",
    "    for i in range(1, X.shape[1]):\n",
    "        cols.append(f\"{i}\")\n",
    "    cols.append(\"y\")\n",
    "    X.columns = cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 1001)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/data_bm.csv\")\n",
    "data_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    g1  g2  g3  g4  g5  g6  g7  g8  g9  g10  ...  g992  g993  g994  g995  \\\n0    1   1   1   1   1   1   1   1   1    1  ...     0     1     1     0   \n1    1   1   1   1   1   1   0   0   1    1  ...     0     0     1     0   \n2    1   1   1   1   1   1   0   0   1    1  ...     0     0     1     0   \n3    1   1   0   1   1   1   0   0   1    1  ...     0     0     1     0   \n4    1   1   0   1   1   1   0   1   1    1  ...     0     1     1     0   \n..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...   ...   ...   ...   ...   \n95   1   1   0   1   1   1   0   1   1    1  ...     0     1     1     0   \n96   1   1   1   1   1   1   0   0   1    1  ...     0     0     1     0   \n97   1   0   1   1   1   1   0   0   1    1  ...     1     1     1     0   \n98   1   1   0   1   1   1   0   1   1    1  ...     1     1     1     0   \n99   1   1   0   1   1   1   0   0   1    1  ...     0     0     1     0   \n\n    g996  g997  g998  g999  g1000  y  \n0      0     0     0     0      0  0  \n1      0     1     0     1      0  0  \n2      0     0     1     1      0  1  \n3      0     0     0     1      0  0  \n4      0     0     0     1      0  0  \n..   ...   ...   ...   ...    ... ..  \n95     0     0     1     1      0  0  \n96     0     1     0     1      0  0  \n97     0     1     1     1      0  0  \n98     0     0     1     1      0  0  \n99     0     0     1     1      0  1  \n\n[100 rows x 1001 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>g1</th>\n      <th>g2</th>\n      <th>g3</th>\n      <th>g4</th>\n      <th>g5</th>\n      <th>g6</th>\n      <th>g7</th>\n      <th>g8</th>\n      <th>g9</th>\n      <th>g10</th>\n      <th>...</th>\n      <th>g992</th>\n      <th>g993</th>\n      <th>g994</th>\n      <th>g995</th>\n      <th>g996</th>\n      <th>g997</th>\n      <th>g998</th>\n      <th>g999</th>\n      <th>g1000</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 1001 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "assign_cols(data_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "net_df = pd.read_csv(\"data/feat_net.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "329034"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(net_df.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "outputs": [],
   "source": [
    "assoc_mat = net_df.to_numpy()\n",
    "np.fill_diagonal(assoc_mat, 1.0)\n",
    "assoc_mat = np.abs(assoc_mat)\n",
    "assoc_mat_2 = np.copy(assoc_mat)\n",
    "assoc_mat_2[assoc_mat_2 > 0.0] = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.     ,  0.     , -1.3997 , ...,  1.     ,  0.     ,  0.     ],\n       [ 0.     ,  1.     ,  0.     , ...,  0.     , -1.4212 ,  0.     ],\n       [-1.3997 ,  0.     ,  1.     , ...,  0.     ,  0.     , -0.17373],\n       ...,\n       [ 1.     ,  0.     ,  0.     , ...,  1.     ,  0.     ,  0.     ],\n       [ 0.     , -1.4212 ,  0.     , ...,  0.     ,  1.     , -1.1482 ],\n       [ 0.     ,  0.     , -0.17373, ...,  0.     , -1.1482 ,  1.     ]])"
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_mat_3 = net_df.to_numpy()\n",
    "np.fill_diagonal(assoc_mat_3, 1.0)\n",
    "assoc_mat_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "outputs": [],
   "source": [
    "np.save(\"data/bmm/feat_net.npy\", assoc_mat)\n",
    "np.save(\"data/bmm/feat_net_bin.npy\", assoc_mat_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 1000)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data_df.iloc[:,:-1].to_numpy(), data_df.iloc[:,-1:].to_numpy()\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y, shuffle=True, test_size=0.3)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "outputs": [],
   "source": [
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(data_df.iloc[:,:-1], data_df.iloc[:,-1:], random_state=42, stratify=data_df.iloc[:,-1:], shuffle=True, test_size=0.3)\n",
    "X_train_df.columns = [f\"f{i}\" for i in range(X_train_df.shape[1])]\n",
    "X_test_df.columns = [f\"f{i}\" for i in range(X_test_df.shape[1])]\n",
    "y_train_df.columns = [\"y\"]\n",
    "y_test_df.columns = [\"y\"]\n",
    "df_train = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "df_test = pd.concat([X_test_df, y_test_df], axis=1)\n",
    "df_train.to_csv(\"data/bmm/data_train.csv\", index=False)\n",
    "df_test.to_csv(\"data/bmm/data_test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0, 1]), array([21,  9]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.00000000e-02, 3.59381366e-02, 1.29154967e-01, 4.64158883e-01,\n       1.66810054e+00, 5.99484250e+00, 2.15443469e+01, 7.74263683e+01,\n       2.78255940e+02, 1.00000000e+03])"
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas = np.logspace(-2, 3, 10)\n",
    "gammas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.42857143e-02, -4.14078675e-04,  5.59006211e-03, ...,\n        -8.69565217e-03,  1.20082816e-02,  2.07039337e-04],\n       [-4.14078675e-04,  2.81573499e-02, -1.78053830e-02, ...,\n        -1.73913043e-02, -4.96894410e-03,  4.14078675e-04],\n       [ 5.59006211e-03, -1.78053830e-02,  2.40372671e-01, ...,\n        -5.50724638e-02, -1.98757764e-02,  8.90269151e-03],\n       ...,\n       [-8.69565217e-03, -1.73913043e-02, -5.50724638e-02, ...,\n         2.43478261e-01, -2.89855072e-03, -5.79710145e-03],\n       [ 1.20082816e-02, -4.96894410e-03, -1.98757764e-02, ...,\n        -2.89855072e-03,  1.44099379e-01, -1.20082816e-02],\n       [ 2.07039337e-04,  4.14078675e-04,  8.90269151e-03, ...,\n        -5.79710145e-03, -1.20082816e-02,  1.42857143e-02]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat = np.cov(X_train, rowvar=False)\n",
    "cov_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "l, u = np.linalg.eigh(cov_mat)\n",
    "l = np.flip(l)\n",
    "u = np.flip(u, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.lines.Line2D at 0x7ff939e8b0d0>"
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbrElEQVR4nO3dfZQddZ3n8ffnPqTzTCBpIKQDSVbACQgB2/AgjlHZGUA07gwjeFYRZmciyOyRXVyP4MMcR1fPziLDAiMxqy4CPnGAwyInHEdQVFaCdGISCCEQUUiTQJoASZqEJJ3+7h9Vndx0307fTt/u23Xv53VOnVu3qu6tb3U6n/zyq19VKSIwM7Psy9W6ADMzqw4HuplZnXCgm5nVCQe6mVmdcKCbmdWJQq12PG3atJg1a9bQvmTbuuR18olDrsfMLAuWL1/+akQ0l1tXs0CfNWsWbW1tQ/uShxYkr+c+MtRyzMwyQdIL/a1zl4uZWZ2oWQu9Kk7+Yq0rMDMbNbId6EefW+sKzMxGjYq7XCTlJf1e0gNl1knSTZLWS1ot6fTqltmP11cmk5mZDaqF/hlgLTC5zLrzgePT6Qzg1vR1eC2/Onn1SVEzs8pa6JJagA8C3+lnk4XA7ZFYBkyRNL1KNZqZWQUq7XK5Efgc0N3P+hnAhpL37ekyMzMbIQMGuqQLgc0Rsfxgm5VZ1ue+vJIWSWqT1NbR0TGIMvdb9/J2vvlv69jSueuQPm9mVq8qaaG/G/iwpD8BPwbeL+nOXtu0AzNL3rcAG3t/UUQsiYjWiGhtbi57odOAnu/o5OZfrOfVzt2H9Hkzs3o1YKBHxLUR0RIRs4BLgF9ExMd7bXY/cGk62uVMYGtEbKp+uTCmkJS8q2svnPr1ZDIzs0Mfhy7pCoCIWAwsBS4A1gM7gMurUl0ZPYG+u6sbWs4ert2YmWXOoAI9Ih4BHknnF5csD+CqahbWn6ZCHoBdXd3Q8dtkYbOD3cwsc1eKHtBCX3VdstDj0M3MsndzrqbSPnQzM9snc4G+/6Rof0PizcwaU/YCPe9ANzMrJ3OB3lQs6UM3M7N9MndStClfMsrlnTfWthgzs1Ekc4F+wCiXw+fVthgzs1Ekc10u+Vxy25i93d3w8kPJZGZm2Wuh7w904KmvJQv95CIzs+y10NM8Z2/0uZmjmVlDy1ygSyIn6O52oJuZlcpcoEPS7eIWupnZgTIZ6DnJLXQzs14yd1IUkhZ6dwTM/3atSzEzGzUyGeg5KRnlMvnEWpdiZjZqZLTLhaSF3v7TZDIzs4oeEj1W0u8krZK0RtJXymyzQNJWSSvT6cvDU24inxN7uwOe+WYymZlZRV0uu4D3R0SnpCLwqKQHI2JZr+1+ExEXVr/EvjzKxcysrwEDPX28XGf6tphONU1Tj3IxM+uroj50SXlJK4HNwM8j4vEym52Vdss8KOmkahbZ274uFzMz26eiQI+IvRExD2gB5ks6udcmK4DjIuJU4GbgvnLfI2mRpDZJbR0dHYdetNzlYmbW26BGuUTEG8AjwHm9lm+LiM50filQlDStzOeXRERrRLQ2NzcfetE5iADOuiOZzMysolEuzZKmpPPjgHOBZ3ptc7QkpfPz0+/dUvVqU3mlXS4TZiaTmZlVNMplOvB9SXmSoL4rIh6QdAVARCwGLgKulNQF7AQuSU+mDotczyiXF36SLDju4uHalZlZZlQyymU1cFqZ5YtL5m8Bbqluaf3L94xyee7WZIED3cwsm1eKepSLmVlfmQz0nNKbc5mZ2T6ZDHS30M3M+spkoCc356p1FWZmo0s2b5/bcz/0c+6udSlmZqNGJgN93zj0sX2uXTIza1jZ7HLp6UN//rZkMjOzbAZ6vmeUiwPdzGyfbAa6R7mYmfXhQDczqxOZDPRiPsfuvQ50M7NSmQz0MQXRtbe71mWYmY0qmRy2WMjl2LO3GxYsrXUpZmajRiYDvZjPsWdvQGF8rUsxMxs1MtnlUswraaE/+61kMjOzrAZ62uXy4l3JZGZmFT2Cbqyk30laJWmNpK+U2UaSbpK0XtJqSacPT7mJYj5Hl0e5mJkdoJI+9F3A+yOiU1IReFTSgxGxrGSb84Hj0+kM4Nb0dVgU82K3R7mYmR1gwBZ6JDrTt8V06t08Xgjcnm67DJgiaXp1S92vmM/R5QuLzMwOUFEfuqS8pJXAZuDnEfF4r01mABtK3reny3p/zyJJbZLaOjo6DrFkKOSTK0X90CIzs/0qCvSI2BsR84AWYL6kk3ttonIfK/M9SyKiNSJam5ubB11sj2I+KXvXgofh3EcO+XvMzOrJoEa5RMQbwCPAeb1WtQMzS963ABuHUtjBFPPJvx/udjEz26+SUS7Nkqak8+OAc4Fnem12P3BpOtrlTGBrRGyqdrE9elrouWeuh7XXD9duzMwypZJRLtOB70vKk/wDcFdEPCDpCoCIWAwsBS4A1gM7gMuHqV4Axo/JA5DftBQKOfizzw7n7szMMmHAQI+I1cBpZZYvLpkP4Krqlta/SWOLQNLl0jRSOzUzG+UyeaXopLHJv0O+J7qZ2X4ZDfSkhb632xcXmZn1yOTdFnta6LujCfJja1yNmdnokMkWes9J0V9M/z6878EaV2NmNjpkMtALuaRsP7XIzGy/TAZ6z4VFc1+7CZ78ao2rMTMbHTIZ6PlcEujTd/4WXnm4xtWYmY0OmQz0nitFo+/tYszMGlYmA72QttB9t0Uzs/0yGej5fYHuRDcz65HJceiSKOTEDk2Bpkm1LsfMbFTIZAsdkodc3DPhf8F77ql1KWZmo0JmA72Yy7HH49DNzPbJbKAX8uJ9O/8FVl5b61LMzEaFTPahA+RzOVr2roJXJ9S6FDOzUSGzLfRiXh6HbmZWopJH0M2U9EtJayWtkfSZMtsskLRV0sp0+vLwlLtfIS+PQzczK1FJl0sXcE1ErJA0CVgu6ecR8XSv7X4TERdWv8Tyirmc2+dmZiUGbKFHxKaIWJHObwfWAjOGu7CB5HPitTgSxrfUuhQzs1FhUH3okmaRPF/08TKrz5K0StKDkk7q5/OLJLVJauvo6Bh8tSWK+Rz/u+srcPadQ/oeM7N6UXGgS5oI3ANcHRHbeq1eARwXEacCNwP3lfuOiFgSEa0R0drc3HyIJSeaijl2dXkcuplZj4oCXVKRJMx/EBH39l4fEdsiojOdXwoUJU2raqW9NBVyXJK7AZZfPZy7MTPLjAFPikoS8F1gbUTc0M82RwOvRERImk/yD8WWqlbay9hinmNzz8LrrwznbszMMqOSUS7vBj4BPClpZbrsOuBYgIhYDFwEXCmpC9gJXBLDfCvEsYU83Xs9zsXMrMeAgR4RjwIaYJtbgFuqVVQlmoo5urtGco9mZqNbZq8UHVvI0+0ri8zM9slsoDcVc/xp1wyYdEKtSzEzGxUyG+hji3m+sPE/wxlLal2KmdmokNlAbyp4HLqZWanMBnohl+O/H3Mzsezva12KmdmokNn7oRfyYk7TS8T2tw4+BMfMrEFktoWezyUxPszD3c3MMiOzgV7oCfQa12FmNlpkNtB7WuhOdDOzRGYDvZATT++cw57DTql1KWZmo0JmAz2fy/FPmxaxbe7/rHUpZmajQmYDvacPfc9ej0U3M4MMB3o+J/5l5vVMWfm3tS7FzGxUyPQ49KOKr5J/y7dcNDODjLfQATwM3cwskdlALzjQzcwOMGCgS5op6ZeS1kpaI+kzZbaRpJskrZe0WtLpw1PufvlcUnp4ILqZGVBZC70LuCYi/gw4E7hK0txe25wPHJ9Oi4Bbq1plGYWcWLHj7XROetdw78rMLBMGDPSI2BQRK9L57cBaYEavzRYCt0diGTBF0vSqV1sinxP//PJltB/7peHcjZlZZgyqD13SLOA04PFeq2YAG0ret9M39JG0SFKbpLaOjo5BlnqgQj7pQ+/qdpeLmRkMItAlTQTuAa6OiG29V5f5SJ+kjYglEdEaEa3Nzc2Dq7SXQi7Hrcd9nbet++SQvsfMrF5UNA5dUpEkzH8QEfeW2aQdmFnyvgXYOPTy+pfPicPz2yjsGc69mJllRyWjXAR8F1gbETf0s9n9wKXpaJczga0RsamKdfax//a57nIxM4PKWujvBj4BPClpZbrsOuBYgIhYDCwFLgDWAzuAy6teaS9NxRw7AXehm5klBgz0iHiU8n3kpdsEcFW1iqrEhDEF3gD2OtHNzIAM38tlQlOB/9d5KmNmHMmRtS7GzGwUyGygjx+T5+bNH2PsaScy7JelmpllQGbv5dJUyFHIiTd3+W6LZmaQ4Ra6JG6b/Y8ctbUJeLTW5ZiZ1VxmAx1gfH4P2uuTomZmkOEuF4BiXr7038wslelAL+RzfqaomVkq04FezLmFbmbWI9OB/sLY9/Gz11t9cZGZGbU8KbpuHSxYcOCyj34UPv1p2LEDLrig72cuuyyZXn0VLrqId2zfxYSOTvbc+17yhRxceSVcfDFs2ACf+ETfz19zDXzoQ8m+P/Wpvuu/+EU491xYuRKuvrrv+q9/Hc4+G377W7juur7rb7wR5s2Dhx6Cr32t7/pvfxtOPBF++lP45jf7rr/jDpg5E37yE7i1zDNC7r4bpk2D225Lpt6WLoXx4+Fb34K77uq7/pFHktfrr4cHHjhw3bhx8OCDyfxXvwoPP3zg+qlT4Z57kvlrr4XHHjtwfUsL3HlnMn/11cnPsNQJJ8CSJcn8okXw7LMHrp83L/n5AXz849DefuD6s86Cb3wjmf/rv4YtWw5c/4EPwJfSe+Offz7s3Hng+gsvhM9+Npnv/XsHg/7d68O/e/7dg9r87pXIdAt9TCEpf3eX+9HNzBQ1espya2trtLW1Dek7tj9wDms2bmXnex/mfSf6BgBmVv8kLY+I1nLrMt1Cz6e30O18y1eLmpnVRaD78n8zszoJ9E4HuplZxgNdPS30vTWuxMys9ip5BN33JG2W9FQ/6xdI2ippZTp9ufpl9lPbcR/l4Tffy+s7do/ULs3MRq1KWui3AecNsM1vImJeOv3T0Muq0Amf5lf8DZu27hx4WzOzOjdgoEfEr4HXRqCWwevawbGHiY1vvFXrSszMaq5afehnSVol6UFJJ/W3kaRFktoktXV0dAx9r49cwBcnfJbnNm+nyzfpMrMGV41AXwEcFxGnAjcD9/W3YUQsiYjWiGhtbm6uwq6TR9G9tafbrXQza3hDDvSI2BYRnen8UqAoadqQK6vQvrHouz100cwa25ADXdLRUjJ+UNL89Du3HPxT1dMzdHGHA93MGtyAd1uU9CNgATBNUjvwj0ARICIWAxcBV0rqAnYCl8QI3iAml+sJdI9FN7PGNmCgR8THBlh/C3BL1SoajDmXse31HYAvLjIzy/RDoplzGbs7OoFfsXOPu1zMrLFlO9DfepWJSka3uMvFzBpdtgP90YuY2h3A59i20y10M2tsmb45FyQnRZsKOd/PxcwaXuYDXcDUCWPY0ulAN7PGlvlABzhi4hi2vLmr1mWYmdVUXQT67GkTWffy9lqXYWZWU9k+KXr8lQC8Y8xkfrpqI1t37uGwccUaF2VmVhvZDvTjLgbgyNdeAmBL5y4Hupk1rGx3uby5Ad7cwNSJYwDY8qZPjJpZ48p2C/2xTwAwde79ALy63SdGzaxxZbuFnpp5xDgA1m/urHElZma1UxeBPmlskVlTx7Nm47Zal2JmVjN1EegAJx1zGGs2ba11GWZmNVM3gT73mMlseG0nW3fuqXUpZmY1ke2Tom+/Zt/sScdMBuDpjds4699NrVVFZmY1M2ALXdL3JG2W9FQ/6yXpJknrJa2WdHr1y+xHy4eSiaTLBWDNRne7mFljqqTL5TbgvIOsPx84Pp0WAbcOvawKbVuXTEDzpCaOnNTE05t8YtTMGtOAgR4RvwZeO8gmC4HbI7EMmCJperUKPKjffSqZUicdM5k1LznQzawxVeOk6AxgQ8n79nRZH5IWSWqT1NbR0VGFXR/olJYpPLd5O527/LALM2s81Qh0lVkW5TaMiCUR0RoRrc3NzVXY9YHmHjOZ7oDnO3yBkZk1nmoEejsws+R9C7CxCt87aEdOagLg1U7fAsDMGk81Av1+4NJ0tMuZwNaI2FSF7x20aRPTQN/um3SZWeMZcBy6pB8BC4BpktqBfwSKABGxGFgKXACsB3YAlw9XsX2c/MUD3janLfSXt701YiWYmY0WAwZ6RHxsgPUBXFW1igbj6HMPeDu2mGfW1PGs9dBFM2tA2b70//WVyVTi5BmHsbrdFxeZWePJdqAvvzqZSpzSchgvvbGTLT4xamYNJtuBXsY7ZkwB4MmX3Eo3s8ZSd4F+8ozkJl1PutvFzBpM3QX6pLFF5jRP4IkXXq91KWZmI6ruAh3gL+YezaPPdfgWAGbWULId6Kd+PZl6OWP2EXQHPOV+dDNrINkO9Oazk6mXU1qSe6Ovbn9jhAsyM6udbAd6x2+TqZepE5uYNXU8v3ymg+S6JzOz+pftQF91XTKV8bH5x/LY81t8kZGZNYxsB/pBfPCU5Bkbq9ztYmYNom4DfcaUccyYMo4fLHvR3S5m1hDqNtAl8an3zmHdK9t5YcuOWpdjZjbs6jbQAU4/9nAA2nyRkZk1gGwH+jtvTKZ+nHDUJKYfNpYfPv7CiJVkZlYr2Q70w+clUz/GFHL8zTtbWPHiG6x40a10M6tvFQW6pPMkrZO0XtLny6xfIGmrpJXp9OXql1rGyw8l00Fc/u7ZTBiT585lbqWbWX2r5BF0eeBfgX9P8kDoJyTdHxFP99r0NxFx4TDU2L+nvpa89npyUanDJ4zhwlOO4YHVG9n5kb2MG5MfoeLMzEZWJS30+cD6iHg+InYDPwYWDm9Z1bXwtGN4c/deHn7mlVqXYmY2bCoJ9BnAhpL37emy3s6StErSg5JOKvdFkhZJapPU1tHRcQjlHpozZk/lqMlN3Pf7jSO2TzOzkVZJoKvMst5X6qwAjouIU4GbgfvKfVFELImI1ohobW5uHlShQ5HPiQ+fegy/enazH01nZnWrkkBvB2aWvG8BDmjqRsS2iOhM55cCRUnTqlZlFVz8rpl0dQfff8wnR82sPlUS6E8Ax0uaLWkMcAlwf+kGko6WpHR+fvq9W6pdbB/zv51MFXjbkZOYP+sI7l3R7lsBmFldGjDQI6IL+AfgZ8Ba4K6IWCPpCklXpJtdBDwlaRVwE3BJjERqTj4xmSr0H06bQfvrO7nxoeeGsSgzs9pQrVqrra2t0dbWNrQvaf9p8tryoYo2jwj+9rYnWPHiGzx8zXuZNrFpaPs3MxthkpZHRGu5ddm+UvSZbyZThSTx3/7y7Wx7aw93uC/dzOpMtgP9EMw9ZjLnvG0aP3liA7u69ta6HDOzqmm4QAdY9OdzeHnbW/zw8RdrXYqZWdU0ZKCf87ZpnDnnCG74+bO0v+57pZtZfWjIQJfEN/7qFHbs3suX7nuq1uWYmVXFgDfnGtXOuuOQPzp72gT+4xnHcueyF/jjq28ye9qEKhZmZjbyst1CnzAzmQ7R379nDmMKOZb8+g9VLMrMrDayHegv/CSZDtHMI8bzkXkzuHt5O4+s21zFwszMRl62A/25W5NpCD533tuZ0FRgya+fr1JRZma1ke1Ar4IjJozhL+YexfrNnbUuxcxsSBo+0AHGFfPs6uqudRlmZkPiQAeainl2O9DNLOMc6EBTIceurr2+ra6ZZVq2x6Gfc3dVvqapkKM7oKs7KObLPaDJzGz0y3agj63OQ5GaCnkAdnV1U8z7Py1mlk3ZTq/nb0umIWoqJj+GXXt890Uzy66KAl3SeZLWSVov6fNl1kvSTen61ZJOr36pZVQr0AtpoPvEqJll2ICBLikP/CtwPjAX+Jikub02Ox84Pp0WAUO72meElXa5mJllVSV96POB9RHxPICkHwMLgadLtlkI3J4+R3SZpCmSpkfEpqpXPAx6Wuif/N7v9s2bmQ2Xi981k797z5yqf28lgT4D2FDyvh04o4JtZgAHBLqkRSQteI499tjB1jps3jX7CP7q9Bm85T50MxsBw/U840oCvdw4vt4DtivZhohYAiyB5CHRFex7REyb2MQNH51X6zLMzIakkkBvB0rvUdsCbDyEbapvwdJh34WZWVZU0mH8BHC8pNmSxgCXAPf32uZ+4NJ0tMuZwNYR6T8vjE8mMzMbuIUeEV2S/gH4GZAHvhcRayRdka5fDCwFLgDWAzuAy4ev5BLPfit5PeHTI7I7M7PRrKIrRSNiKUloly5bXDIfwFXVLa0CL96VvDrQzcwyfqWomZnt40A3M6sTDnQzszrhQDczqxOq1UMdJHUALxzix6cBr1axnCzwMTcGH3NjGMoxHxcRzeVW1CzQh0JSW0S01rqOkeRjbgw+5sYwXMfsLhczszrhQDczqxNZDfQltS6gBnzMjcHH3BiG5Zgz2YduZmZ9ZbWFbmZmvTjQzczqROYCfaAHVmeVpJmSfilpraQ1kj6TLj9C0s8lPZe+Hl7ymWvTn8M6SX9Zu+oPnaS8pN9LeiB9X+/HO0XS3ZKeSf+sz2qAY/4v6e/0U5J+JGlsvR2zpO9J2izpqZJlgz5GSe+U9GS67iZJ5R4e1L+IyMxEcvvePwBzgDHAKmBureuq0rFNB05P5ycBz5I8lPufgc+nyz8P/I90fm56/E3A7PTnkq/1cRzCcf9X4IfAA+n7ej/e7wN/l86PAabU8zGTPIryj8C49P1dwGX1dszAnwOnA0+VLBv0MQK/A84ieQrcg8D5g6kjay30fQ+sjojdQM8DqzMvIjZFxIp0fjuwluQvw0KSECB9/Ug6vxD4cUTsiog/ktyLfv6IFj1EklqADwLfKVlcz8c7meQv/ncBImJ3RLxBHR9zqgCMk1QAxpM8zayujjkifg281mvxoI5R0nRgckQ8Fkm6317ymYpkLdD7exh1XZE0CzgNeBw4KtKnP6WvR6ab1cPP4kbgc0B3ybJ6Pt45QAfwf9Jupu9ImkAdH3NEvARcD7xI8tD4rRHxb9TxMZcY7DHOSOd7L69Y1gK9oodRZ5mkicA9wNURse1gm5ZZlpmfhaQLgc0RsbzSj5RZlpnjTRVI/lt+a0ScBrxJ8l/x/mT+mNN+44UkXQvHABMkffxgHymzLFPHXIH+jnHIx561QK/Nw6hHiKQiSZj/ICLuTRe/kv5XjPR1c7o86z+LdwMflvQnkq6z90u6k/o9XkiOoT0iHk/f300S8PV8zOcCf4yIjojYA9wLnE19H3OPwR5jezrfe3nFshbolTywOpPSs9nfBdZGxA0lq+4HPpnOfxL4vyXLL5HUJGk2cDzJCZVMiIhrI6IlImaR/Dn+IiI+Tp0eL0BEvAxskHRiuugDwNPU8TGTdLWcKWl8+jv+AZLzQ/V8zD0GdYxpt8x2SWemP6tLSz5TmVqfHT6Es8kXkIwA+QPwhVrXU8XjOofkv1ergZXpdAEwFXgYeC59PaLkM19Ifw7rGOTZ8NE0AQvYP8qlro8XmAe0pX/O9wGHN8AxfwV4BngKuINkdEddHTPwI5JzBHtIWtr/6VCOEWhNf05/AG4hvZq/0smX/puZ1YmsdbmYmVk/HOhmZnXCgW5mVicc6GZmdcKBbmZWJxzoZmZ1woFuZlYn/j//b+gcZqpWHQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 10\n",
    "plt.plot(np.arange(l.shape[0]), l)\n",
    "plt.axvline(x=p, color=\"orange\", linestyle=\"--\")\n",
    "plt.axhline(y=l[p], color=\"red\", linestyle=\"--\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "from notebooks.manifold_reg.util import get_psd_mat\n",
    "l_p = l[:35]\n",
    "u_p = u[:35]\n",
    "l_p_inv = np.diag(1.0/(l_p))\n",
    "cov_inv = u_p.T @ l_p_inv @ u_p\n",
    "cov_inv = get_psd_mat((assoc_mat * cov_inv))\n",
    "K_train = calculate_mahal_kernel(X_train, X_train, cov_inv, 1)\n",
    "K_test = calculate_mahal_kernel(X_test, X_train, cov_inv, 1)\n",
    "K_train_idt = calculate_mahal_kernel(X_train, X_train, np.identity(X_train.shape[1]), 1)\n",
    "K_test_idt = calculate_mahal_kernel(X_test, X_train, np.identity(X_train.shape[1]), 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num iter: 0\n",
      "gamma - 0.01\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.04\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.13\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.46\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 1.67\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 5.99\n",
      "Num iter: 0\n",
      "epoch 0, delta=2.16721, rel_change=1.00000, ls_steps=38000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=36979\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=3.15902, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00334, rel_change=0.00106, ls_steps=8315\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=6574\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=2.16721, rel_change=1.00000, ls_steps=38000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=35156\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=3.00468, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00005, rel_change=0.00002, ls_steps=1466\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=10000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.85175, rel_change=1.00000, ls_steps=36000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=29998\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=2.90870, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=14000\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=3.50674, rel_change=1.00000, ls_steps=16009\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=16972\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=4.19401, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00052, rel_change=0.00012, ls_steps=14000\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=2065\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=3.15825, rel_change=1.00000, ls_steps=44000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=72859\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=4.19837, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00035, rel_change=0.00008, ls_steps=1886\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=12000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "gamma - 21.54\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.74125, rel_change=1.00000, ls_steps=20000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=16639\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.77311, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1537\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.74125, rel_change=1.00000, ls_steps=2000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=2660\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.76871, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1005\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.65322, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=792\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.68393, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1552\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.12017, rel_change=1.00000, ls_steps=70000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=66916\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.14206, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=976\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.02050, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=742\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.05315, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=3339\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 77.43\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.67202, rel_change=1.00000, ls_steps=68000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=68492\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.67427, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1484\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.67202, rel_change=1.00000, ls_steps=68000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=68441\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.67397, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=921\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.59264, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=413\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.59480, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1317\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.01400, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=40508\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.01555, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1613\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.92400, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=510\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.92632, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1844\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 278.26\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.66691, rel_change=1.00000, ls_steps=68000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=60444\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66708, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1385\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.66691, rel_change=1.00000, ls_steps=68000\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=66340\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66706, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=10433\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.58816, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=324\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.58833, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1403\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.00618, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=325\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.00630, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1401\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.91689, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=68657\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.91706, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1665\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 1000.00\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.66651, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=58246\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66653, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1127\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.66651, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=110\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66652, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=4998\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.58782, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=134\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.58783, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1422\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=1.00557, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=66204\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.00558, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1382\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 0\n",
      "epoch 0, delta=0.91634, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=76378\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.91635, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1509\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import *\n",
    "train_errs_mahal_auc_0, train_errs_mahal_ll_0, test_errs_mahal_auc_0, test_errs_mahal_ll_0, \\\n",
    "               train_errs_idt_auc_0, train_errs_idt_ll_0, test_errs_idt_auc_0, test_errs_idt_ll_0 = compare_kernels_log(gammas, X_train, X_test, y_train, y_test, cv_fold=5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7fdeab039f70>"
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "fig.suptitle(\"No graph - all components\", fontsize=18)\n",
    "ax[0].plot(gammas, train_errs_mahal_auc_0, label=\"Mahalnobis Ker\")\n",
    "ax[0].plot(gammas, train_errs_idt_auc_0, label=\"Identity Ker\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[1].plot(gammas, test_errs_mahal_auc_0, label=\"Mahalnobis Ker\")\n",
    "ax[1].plot(gammas, test_errs_idt_auc_0, label=\"Identity Ker\")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[1].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[0].set_ylabel(\"train auc\", fontsize=14)\n",
    "ax[1].set_ylabel(\"test auc\", fontsize=14)\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num iter: 9\n",
      "gamma - 0.01\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.04\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.13\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 0.46\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 1.67\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.51186, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00011, rel_change=0.00021, ls_steps=2000\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=273\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.69335, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.02135, rel_change=0.02987, ls_steps=0\n",
      "epoch 2, delta=0.00006, rel_change=0.00008, ls_steps=0\n",
      "epoch 3, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 3 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.46973, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00002, rel_change=0.00004, ls_steps=2260\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=4000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.17201, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.01087, rel_change=0.00919, ls_steps=1144\n",
      "epoch 2, delta=0.00001, rel_change=0.00001, ls_steps=1199\n",
      "epoch 3, delta=0.00000, rel_change=0.00000, ls_steps=1161\n",
      "relative change below tolerance; stopping after 3 epochs\n",
      "epoch 0, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=0\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 5.99\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.96311, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=10000\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=3.15902, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00334, rel_change=0.00106, ls_steps=8315\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=6574\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.91853, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00002, rel_change=0.00002, ls_steps=1315\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=10000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "epoch 0, delta=3.00468, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00005, rel_change=0.00002, ls_steps=1466\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=10000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.82430, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00006, rel_change=0.00007, ls_steps=524\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=557\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "epoch 0, delta=2.90870, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=14000\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.34172, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00001, rel_change=0.00000, ls_steps=3035\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=4.19401, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00052, rel_change=0.00012, ls_steps=14000\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=2065\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.25055, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1580\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=4.19837, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00035, rel_change=0.00008, ls_steps=1886\n",
      "epoch 2, delta=0.00000, rel_change=0.00000, ls_steps=12000\n",
      "relative change below tolerance; stopping after 2 epochs\n",
      "gamma - 21.54\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.68633, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1447\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.77311, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1537\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.68364, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=936\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.76871, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1005\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.60386, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=4000\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.68393, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1552\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.02862, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1814\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.14206, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=976\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.93905, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1407\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.05315, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=3339\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 77.43\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66800, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1336\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.67427, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1484\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66779, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1245\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.67397, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=921\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.58902, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=422\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.59480, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1317\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.00729, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=3458\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.01555, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1613\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.91804, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=8892\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.92632, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1844\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 278.26\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66660, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1293\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66708, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1385\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66658, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1495\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66706, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=10433\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.58788, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=789\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.58833, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1403\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.00566, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=3424\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.00630, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1401\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.91643, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1511\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.91706, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1665\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "gamma - 1000.00\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66649, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1221\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66653, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1127\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.66649, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1333\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.66652, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=4998\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.58779, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=681\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.58783, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1422\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=1.00553, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=6779\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=1.00558, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1382\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Num iter: 9\n",
      "epoch 0, delta=0.91630, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1301\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "epoch 0, delta=0.91635, rel_change=1.00000, ls_steps=0\n",
      "epoch 1, delta=0.00000, rel_change=0.00000, ls_steps=1509\n",
      "relative change below tolerance; stopping after 1 epochs\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_errs_mahal_auc, train_errs_mahal_ll, test_errs_mahal_auc, test_errs_mahal_ll, \\\n",
    "               train_errs_idt_auc, train_errs_idt_ll, test_errs_idt_auc, test_errs_idt_ll = compare_kernels_log(gammas, X_train, X_test, y_train, y_test, assoc_mat, cv_fold=5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7fdeaad5ee80>"
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "fig.suptitle(\"Graph mask - all components\", fontsize=18)\n",
    "ax[0].plot(gammas, train_errs_mahal_auc, label=\"Mahalnobis Ker\")\n",
    "ax[0].plot(gammas, train_errs_idt_auc, label=\"Identity Ker\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[1].plot(gammas, test_errs_mahal_auc, label=\"Mahalnobis Ker\")\n",
    "ax[1].plot(gammas, test_errs_idt_auc, label=\"Identity Ker\")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[1].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[0].set_ylabel(\"train auc\", fontsize=14)\n",
    "ax[1].set_ylabel(\"test auc\", fontsize=14)\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma - 0.01\n",
      "gamma - 0.04\n",
      "gamma - 0.13\n",
      "gamma - 0.46\n",
      "gamma - 1.67\n",
      "gamma - 5.99\n",
      "gamma - 21.54\n",
      "gamma - 77.43\n",
      "gamma - 278.26\n",
      "gamma - 1000.00\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import compare_kernels_log\n",
    "train_errs_mahal_auc_2, train_errs_mahal_ll_2, test_errs_mahal_auc_2, test_errs_mahal_ll_2, \\\n",
    "               train_errs_idt_auc_2, train_errs_idt_ll_2, test_errs_idt_auc_2, test_errs_idt_ll_2 = compare_kernels_log(gammas, X_train, X_test, y_train, y_test, None, cv_fold=5, random_state=42, n_component=35)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7ff7922adca0>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "fig.suptitle(\"No graph - 40 components\", fontsize=18)\n",
    "ax[0].plot(gammas, train_errs_mahal_auc_2, label=\"Mahalnobis Ker\")\n",
    "ax[0].plot(gammas, train_errs_idt_auc_2, label=\"Identity Ker\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[1].plot(gammas, test_errs_mahal_auc_2, label=\"Mahalnobis Ker\")\n",
    "ax[1].plot(gammas, test_errs_idt_auc_2, label=\"Identity Ker\")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[1].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[0].set_ylabel(\"train auc\", fontsize=14)\n",
    "ax[1].set_ylabel(\"test auc\", fontsize=14)\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5       , 0.5       , 0.5       , 0.46560847, 0.63492063,\n       0.8042328 , 0.7989418 , 0.72486772, 0.67724868, 0.67195767])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errs_mahal_auc_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma - 0.01\n",
      "gamma - 0.04\n",
      "gamma - 0.13\n",
      "gamma - 0.46\n",
      "gamma - 1.67\n",
      "gamma - 5.99\n",
      "gamma - 21.54\n",
      "gamma - 77.43\n",
      "gamma - 278.26\n",
      "gamma - 1000.00\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import compare_kernels_log\n",
    "train_errs_mahal_auc_3, train_errs_mahal_ll_3, test_errs_mahal_auc_3, test_errs_mahal_ll_3, \\\n",
    "               train_errs_idt_auc_3, train_errs_idt_ll_3, test_errs_idt_auc_3, test_errs_idt_ll_3 = compare_kernels_log(gammas, X_train, X_test, y_train, y_test, assoc_mat, cv_fold=5, random_state=42, n_component=36)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7ff79236ef10>"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "fig.suptitle(\"Graph mask - 40 components\", fontsize=18)\n",
    "ax[0].plot(gammas, train_errs_mahal_auc_3, label=\"Mahalnobis Ker\")\n",
    "ax[0].plot(gammas, train_errs_idt_auc_3, label=\"Identity Ker\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[1].plot(gammas, test_errs_mahal_auc_3, label=\"Mahalnobis Ker\")\n",
    "ax[1].plot(gammas, test_errs_idt_auc_3, label=\"Identity Ker\")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[0].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[1].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "ax[0].set_ylabel(\"train auc\", fontsize=14)\n",
    "ax[1].set_ylabel(\"test auc\", fontsize=14)\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.5       , 0.5       , 0.5       , 0.45502646, 0.4021164 ,\n       0.65079365, 0.66666667, 0.74603175, 0.73544974, 0.73544974])"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros(len(y_train))\n",
    "test_errs_mahal_auc_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def log_likelihood(b, X, y):\n",
    "    f = X @ b\n",
    "    ll = np.sum((y * f) - np.log(1 + np.exp(f)))\n",
    "    return ll\n",
    "def bic(b, X, y, p):\n",
    "    y_c = y.copy()\n",
    "    y_c[y_c == 0] = -1\n",
    "    ll = log_likelihood(b, X, y)\n",
    "    d = X.shape[1] - p\n",
    "    # print(f\"ll: {ll}\")\n",
    "    return -2*ll + p*np.log(np.log(X.shape[0]))\n",
    "\n",
    "def aic(b, X, y, p):\n",
    "    ll = log_likelihood(b, X, y)\n",
    "    # print(f\"ll - {ll}\")\n",
    "    # d = X.shape[1] - p\n",
    "    return -2*ll + 2*p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "outputs": [],
   "source": [
    "from notebooks.manifold_reg.util import get_psd_mat_2, KernelLogisiticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import traceback\n",
    "def select_n_components_0(X, y, assoc_mat=None):\n",
    "    n_dims = np.arange(1, 101)\n",
    "    n_samples = X.shape[0]\n",
    "    bic_scores = np.zeros(len(n_dims))\n",
    "    aic_scores = np.zeros(len(n_dims))\n",
    "    d = X.shape[1]\n",
    "    for i, p in enumerate(n_dims):\n",
    "        try:\n",
    "            clf = KernelLogisiticRegression(n_components=p, gamma=0.01, assoc_mat=assoc_mat).fit(X, y)\n",
    "            ll = log_likelihood(clf.coef_[0],  clf.K_, y)\n",
    "            # y_pred = clf.predict_proba(K)[:,1]\n",
    "            # bic_s = -2*ll + 0.5*((p*(p + 1)))*np.log(n_samples)\n",
    "            # aic_s = -2*ll + (p*(p + 1))\n",
    "            bic_s = -2*ll + (d - 1)*(p-1)*np.log(n_samples)\n",
    "            aic_s = -2*ll + 2*(d - 1)*(p-1)\n",
    "            bic_scores[i] = bic_s\n",
    "            aic_scores[i] = aic_s\n",
    "            print(f\"p : {p}, bic: {bic_s}, aic: {aic_s}, ll: {ll}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {p}\")\n",
    "            bic_scores[i] = 1e6\n",
    "            aic_scores[i] = 1e6\n",
    "\n",
    "    return bic_scores, aic_scores\n",
    "\n",
    "def calculate_acc_var(l, n):\n",
    "    ls = []\n",
    "    for i in n:\n",
    "        ls.append(np.round((np.sum(l[:i])/np.sum(l)), 3))\n",
    "    return ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1\n",
      "p : 2, bic: 4244.265984147496, aic: 1998.0192373401858, ll: -0.009618670092911105\n",
      "p : 3, bic: 8488.512730954806, aic: 3996.019237340186, ll: -0.009618670092911105\n",
      "p : 4, bic: 12732.759477762116, aic: 5994.019237340186, ll: -0.009618670092911105\n",
      "p : 5, bic: 16977.006224569424, aic: 7992.019237340186, ll: -0.009618670092911105\n",
      "p : 6, bic: 21221.252971376733, aic: 9990.019237340186, ll: -0.009618670092911105\n",
      "p : 7, bic: 25465.499718184044, aic: 11988.019237340186, ll: -0.009618670092911105\n",
      "p : 8, bic: 29709.746464991353, aic: 13986.019237340186, ll: -0.009618670092911105\n",
      "p : 9, bic: 33953.99321179867, aic: 15984.019237340186, ll: -0.009618670092911105\n",
      "p : 10, bic: 38198.23995860598, aic: 17982.019237340184, ll: -0.009618670092911105\n",
      "p : 11, bic: 42442.486705413285, aic: 19980.019237340184, ll: -0.009618670092911105\n",
      "p : 12, bic: 46686.7334522206, aic: 21978.019237340184, ll: -0.009618670092911105\n",
      "p : 13, bic: 50930.98019902791, aic: 23976.019237340184, ll: -0.009618670092911105\n",
      "p : 14, bic: 55175.22694583522, aic: 25974.019237340184, ll: -0.009618670092911105\n",
      "p : 15, bic: 59419.473692642525, aic: 27972.019237340184, ll: -0.009618670092911105\n",
      "p : 16, bic: 63663.72043944984, aic: 29970.019237340184, ll: -0.009618670092911105\n",
      "p : 17, bic: 67907.96718625714, aic: 31968.019237340184, ll: -0.009618670092911105\n",
      "p : 18, bic: 72152.21393306446, aic: 33966.01923734019, ll: -0.009618670092911105\n",
      "p : 19, bic: 76396.46067987176, aic: 35964.01923734019, ll: -0.009618670092911105\n",
      "p : 20, bic: 80640.70742667907, aic: 37962.01923734019, ll: -0.009618670092911105\n",
      "p : 21, bic: 84884.95417348637, aic: 39960.01923734019, ll: -0.009618670092911105\n",
      "p : 22, bic: 89129.20092029369, aic: 41958.01923734019, ll: -0.009618670092911105\n",
      "p : 23, bic: 93373.447667101, aic: 43956.01923734019, ll: -0.009618670092911105\n",
      "p : 24, bic: 97617.6944139083, aic: 45954.01923734019, ll: -0.009618670092911105\n",
      "p : 25, bic: 101861.94116071562, aic: 47952.01923734019, ll: -0.009618670092911105\n",
      "p : 26, bic: 106106.18790752294, aic: 49950.01923734019, ll: -0.009618670092911105\n",
      "p : 27, bic: 110350.43465433024, aic: 51948.01923734019, ll: -0.009618670092911105\n",
      "p : 28, bic: 114594.68140113755, aic: 53946.01923734019, ll: -0.009618670092911105\n",
      "p : 29, bic: 118838.92814794485, aic: 55944.01923734019, ll: -0.009618670092911105\n",
      "p : 30, bic: 123083.17489475217, aic: 57942.01923734019, ll: -0.009618670092911105\n",
      "p : 31, bic: 127327.42164155949, aic: 59940.01923734019, ll: -0.009618670092911105\n",
      "p : 32, bic: 131571.66838836682, aic: 61938.01923734019, ll: -0.009618670092911105\n",
      "p : 33, bic: 135815.91513517412, aic: 63936.01923734019, ll: -0.009618670092911105\n",
      "p : 34, bic: 140060.16188198142, aic: 65934.01923734018, ll: -0.009618670092911105\n",
      "p : 35, bic: 144304.40862878875, aic: 67932.01923734018, ll: -0.009618670092911105\n",
      "p : 36, bic: 148548.65537559605, aic: 69930.01923734018, ll: -0.009618670092911105\n",
      "p : 37, bic: 152792.90212240335, aic: 71928.01923734018, ll: -0.009618670092911105\n",
      "p : 38, bic: 157037.14886921065, aic: 73926.01923734018, ll: -0.009618670092911105\n",
      "p : 39, bic: 161281.39561601798, aic: 75924.01923734018, ll: -0.009618670092911105\n",
      "p : 40, bic: 165525.64236282528, aic: 77922.01923734018, ll: -0.009618670092911105\n",
      "p : 41, bic: 169769.88910963258, aic: 79920.01923734018, ll: -0.009618670092911105\n",
      "p : 42, bic: 174014.1358564399, aic: 81918.01923734018, ll: -0.009618670092911105\n",
      "p : 43, bic: 178258.3826032472, aic: 83916.01923734018, ll: -0.009618670092911105\n",
      "p : 44, bic: 182502.6293500545, aic: 85914.01923734018, ll: -0.009618670092911105\n",
      "p : 45, bic: 186746.87609686184, aic: 87912.01923734018, ll: -0.009618670092911105\n",
      "p : 46, bic: 190991.12284366915, aic: 89910.01923734018, ll: -0.009618670092911105\n",
      "p : 47, bic: 195235.36959047645, aic: 91908.01923734018, ll: -0.009618670092911105\n",
      "p : 48, bic: 199479.61633728378, aic: 93906.01923734018, ll: -0.009618670092911105\n",
      "p : 49, bic: 203723.86308409108, aic: 95904.01923734018, ll: -0.009618670092911105\n",
      "p : 50, bic: 207968.10983089838, aic: 97902.01923734018, ll: -0.009618670092911105\n",
      "p : 51, bic: 212212.3565777057, aic: 99900.01923734018, ll: -0.009618670092911105\n",
      "p : 52, bic: 216456.603324513, aic: 101898.01923734018, ll: -0.009618670092911105\n",
      "p : 53, bic: 220700.8500713203, aic: 103896.01923734018, ll: -0.009618670092911105\n",
      "p : 54, bic: 224945.0968181276, aic: 105894.01923734018, ll: -0.009618670092911105\n",
      "p : 55, bic: 229189.34356493494, aic: 107892.01923734018, ll: -0.009618670092911105\n",
      "p : 56, bic: 233433.59031174224, aic: 109890.01923734018, ll: -0.009618670092911105\n",
      "p : 57, bic: 237677.83705854954, aic: 111888.01923734018, ll: -0.009618670092911105\n",
      "p : 58, bic: 241922.08380535687, aic: 113886.01923734018, ll: -0.009618670092911105\n",
      "p : 59, bic: 246166.33055216417, aic: 115884.01923734018, ll: -0.009618670092911105\n",
      "p : 60, bic: 250410.57729897148, aic: 117882.01923734018, ll: -0.009618670092911105\n",
      "p : 61, bic: 254654.8240457788, aic: 119880.01923734018, ll: -0.009618670092911105\n",
      "p : 62, bic: 258899.0707925861, aic: 121878.01923734018, ll: -0.009618670092911105\n",
      "p : 63, bic: 263143.31753939344, aic: 123876.01923734018, ll: -0.009618670092911105\n",
      "p : 64, bic: 267387.56428620074, aic: 125874.01923734018, ll: -0.009618670092911105\n",
      "p : 65, bic: 271631.81103300804, aic: 127872.01923734018, ll: -0.009618670092911105\n",
      "p : 66, bic: 275876.05777981534, aic: 129870.01923734018, ll: -0.009618670092911105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3845/471891507.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilterwarnings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ignore\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mbic_scores\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maic_scores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselect_n_components_0\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0massoc_mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_3845/2631775957.py\u001B[0m in \u001B[0;36mselect_n_components_0\u001B[0;34m(X, y, assoc_mat)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_dims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m             \u001B[0mclf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mKernelLogisiticRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_components\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0massoc_mat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0massoc_mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m             \u001B[0mll\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlog_likelihood\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mK_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m             \u001B[0;31m# y_pred = clf.predict_proba(K)[:,1]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/moses-incons-pen-xp/notebooks/manifold_reg/util.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    932\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprec_mat_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 934\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mK_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_mahal_kernel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mX_\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprec_mat_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgamma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    935\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclf_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLogisticRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfit_intercept\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_intercept\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpenalty\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpenalty\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'auto'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    936\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclf_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mK_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/moses-incons-pen-xp/notebooks/manifold_reg/util.py\u001B[0m in \u001B[0;36mcalculate_mahal_kernel\u001B[0;34m(X, Y, cov_inv, gamma)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcalculate_mahal_kernel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcov_inv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 380\u001B[0;31m     \u001B[0mD\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpairwise_distances\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"mahalanobis\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mVI\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcov_inv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    381\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[0mK\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2.0\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgamma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mD\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mpairwise_distances\u001B[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001B[0m\n\u001B[1;32m   1879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1880\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0meffective_n_jobs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1881\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdistance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msquareform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdistance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpdist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmetric\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1882\u001B[0m         \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdistance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcdist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmetric\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1883\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/spatial/distance.py\u001B[0m in \u001B[0;36mpdist\u001B[0;34m(X, metric, out, **kwargs)\u001B[0m\n\u001B[1;32m   2248\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmetric_info\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2249\u001B[0m             \u001B[0mpdist_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmetric_info\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpdist_func\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2250\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mpdist_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2251\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mmstr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"test_\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2252\u001B[0m             \u001B[0mmetric_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_TEST_METRICS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/spatial/distance.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, X, out, **kwargs)\u001B[0m\n\u001B[1;32m   1721\u001B[0m         \u001B[0;31m# get pdist wrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1722\u001B[0m         \u001B[0mpdist_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_distance_wrap\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34mf'pdist_{metric_name}_{typ}_wrap'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1723\u001B[0;31m         \u001B[0mpdist_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1724\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1725\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "bic_scores, aic_scores = select_n_components_0(X_train, y_train, assoc_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(aic_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "outputs": [],
   "source": [
    "def plot_ker_scores(gammas, train_1, train_2, test_1, test_2, title=\"\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    fig.suptitle(title)\n",
    "    ax[0].plot(gammas, train_1, label=\"Mahalnobis Ker\")\n",
    "    ax[0].plot(gammas, train_2, label=\"Identity Ker\")\n",
    "    ax[0].set_xscale(\"log\")\n",
    "    ax[1].plot(gammas, test_1, label=\"Mahalnobis Ker\")\n",
    "    ax[1].plot(gammas, test_2, label=\"Identity Ker\")\n",
    "    ax[1].set_xscale(\"log\")\n",
    "    ax[0].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "    ax[1].set_xlabel(\"$\\gamma$\", fontsize=14)\n",
    "    ax[0].set_ylabel(\"train auc\", fontsize=14)\n",
    "    ax[1].set_ylabel(\"test auc\", fontsize=14)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "outputs": [],
   "source": [
    "from sklearn.covariance import ShrunkCovariance\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def shrunk_cov_score(X):\n",
    "    shrinkages = np.logspace(-2, 0, 30)\n",
    "    cv = GridSearchCV(ShrunkCovariance(), {\"shrinkage\": shrinkages}, verbose=2, n_jobs=-1).fit(X)\n",
    "    return cv.best_estimator_, np.mean(cross_val_score(cv.best_estimator_, X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "scv, score = shrunk_cov_score(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(bic_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 70)"
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(X_test, X_train, metric=\"mahalanobis\",  VI=scv.precision_).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from notebooks.manifold_reg.util import get_psd_mat, compare_kernels_log\n",
    "def select_n_components():\n",
    "    n_dims = np.arange(1, X_train.shape[0] + 1)\n",
    "    train_auc_scores = np.zeros((2, len(n_dims), len(gammas)))\n",
    "    test_auc_scores = np.zeros((2, len(n_dims), len(gammas)))\n",
    "    for p in n_dims:\n",
    "        try:\n",
    "            train_auc_scores[0, p], _, test_auc_scores[0, p], _, \\\n",
    "                   train_auc_scores[1, p], _, test_auc_scores[1, p], _ = compare_kernels_log(gammas, X_train, X_test, y_train, y_test, assoc_mat, cv_fold=5, random_state=42, n_component=p, verbose=0)\n",
    "        except:\n",
    "            print(f\"skipping - {p}\")\n",
    "    return train_auc_scores, test_auc_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "outputs": [],
   "source": [
    "def auc_scorer(est, X, y):\n",
    "    return est.score(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.997]"
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_acc_var(l, [68])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model selection where we select $\\gamma$ using all components"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'gammas': 0.01}, cv score: 0.5061868686868687, test score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import KernelLogisiticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cv_1 = GridSearchCV(KernelLogisiticRegression(assoc_mat=assoc_mat), {\"gammas\": gammas}, scoring=\"roc_auc\", verbose=2, n_jobs=-1).fit(X_train, y_train)\n",
    "sc_1  = np.mean(cross_val_score(cv_1.best_estimator_, X_train, y_train))\n",
    "cv_1.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best Params: {cv_1.best_params_}, cv score: {sc_1}, test score: {cv_1.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model selection with identity covariance matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 1.6681005372000592}, cv score: 0.5647727272727272, test score: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "cv_2 = GridSearchCV(KernelLogisiticRegression(identity=True), {\"gamma\": gammas}, scoring=\"roc_auc\", verbose=2, n_jobs=-1).fit(X_train, y_train)\n",
    "sc_2 = np.mean(cross_val_score(cv_2.best_estimator_, X_train, y_train))\n",
    "cv_2.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_2.best_params_}, cv score: {sc_2}, test score: {cv_2.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model selection where we select optimal n_comp and $\\gamma$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 690 candidates, totalling 3450 fits\n",
      "Best params: {'gammas': 0.01, 'n_components': 31}, cv score: 0.6284343434343435, test score: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import KernelLogisiticRegression\n",
    "cv_4 = GridSearchCV(KernelLogisiticRegression(assoc_mat=assoc_mat), {\"gammas\": gammas, \"n_components\": np.arange(1, 70)}, scoring=\"roc_auc\", verbose=1, n_jobs=8).fit(X_train, y_train)\n",
    "sc_4 = np.mean(cross_val_score(cv_4.best_estimator_, X_train, y_train))\n",
    "cv_4.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_4.best_params_}, cv score: {sc_4}, test score: {cv_4.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model selection where we select optimal n_comp and $\\gamma$ - using binary graph mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 690 candidates, totalling 3450 fits\n",
      "Best params: {'gammas': 0.01, 'n_components': 27}, cv score: 0.625050505050505, test score: 0.6402116402116401\n"
     ]
    }
   ],
   "source": [
    "cv_5 = GridSearchCV(KernelLogisiticRegression(assoc_mat=assoc_mat_2), {\"gammas\": gammas, \"n_components\": np.arange(1, 70)}, scoring=\"roc_auc\", verbose=1, n_jobs=-1).fit(X_train, y_train)\n",
    "sc_5 = np.mean(cross_val_score(cv_5.best_estimator_, X_train, y_train))\n",
    "cv_5.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_5.best_params_}, cv score: {sc_5}, test score: {cv_5.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model selection where we select optimal n_comp and $\\gamma$ - without using graph mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 690 candidates, totalling 3450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................gammas=0.01, n_components=1; total time=  13.2s\n",
      "[CV] END ........................gammas=0.01, n_components=4; total time=  13.7s\n",
      "[CV] END ........................gammas=0.01, n_components=8; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=11; total time=  13.2s\n",
      "[CV] END .......................gammas=0.01, n_components=14; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=18; total time=  12.8s\n",
      "[CV] END .......................gammas=0.01, n_components=21; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=23; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=27; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=30; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=33; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=36; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=40; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=43; total time=  12.9s\n",
      "[CV] END .......................gammas=0.01, n_components=46; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=49; total time=  13.5s\n",
      "[CV] END .......................gammas=0.01, n_components=52; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=55; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=58; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=61; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=65; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=68; total time=  16.0s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=2; total time=  14.9s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=5; total time=  13.9s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=8; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=11; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=14; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=18; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=21; total time=  12.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=24; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=27; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=30; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=33; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=37; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=40; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=43; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=46; total time=  17.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=50; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=53; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=56; total time=  16.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=60; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=63; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=66; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=69; total time=  16.6s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=4; total time=  13.3s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=7; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=10; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=13; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=17; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=20; total time=  16.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=23; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=26; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=29; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=33; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=36; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=39; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=42; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=45; total time=  12.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=48; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=51; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=54; total time=  16.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=58; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=61; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=64; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=67; total time=  14.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=1; total time=  14.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=4; total time=  12.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=7; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=10; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=13; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=17; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=20; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=23; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=26; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=29; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=33; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=36; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=39; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=43; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=46; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=48; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=52; total time=  16.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=55; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=58; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=61; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=64; total time=  17.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=68; total time=  13.7s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=2; total time=  14.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=5; total time=  13.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=8; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=11; total time=  15.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=15; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=18; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=21; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=25; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=27; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=31; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=34; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=37; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=40; total time=  12.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=43; total time=  15.7s\n",
      "[CV] END ........................gammas=0.01, n_components=1; total time=  13.0s\n",
      "[CV] END ........................gammas=0.01, n_components=4; total time=  12.9s\n",
      "[CV] END ........................gammas=0.01, n_components=7; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=11; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=15; total time=  12.6s\n",
      "[CV] END .......................gammas=0.01, n_components=17; total time=  13.5s\n",
      "[CV] END .......................gammas=0.01, n_components=20; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=24; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=27; total time=  12.6s\n",
      "[CV] END .......................gammas=0.01, n_components=30; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=33; total time=  12.7s\n",
      "[CV] END .......................gammas=0.01, n_components=36; total time=  12.2s\n",
      "[CV] END .......................gammas=0.01, n_components=39; total time=  15.3s\n",
      "[CV] END .......................gammas=0.01, n_components=42; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=45; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=49; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=52; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=55; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=58; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=61; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=64; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=67; total time=  15.5s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=2; total time=  15.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=5; total time=  13.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=7; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=11; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=15; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=18; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=21; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=24; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=27; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=30; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=34; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=37; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=40; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=43; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=46; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=49; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=52; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=56; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=59; total time=  17.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=62; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=65; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=68; total time=  14.3s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=3; total time=  13.6s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=6; total time=  14.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=9; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=12; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=15; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=18; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=21; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=25; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=28; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=31; total time=  15.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=35; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=38; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=41; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=44; total time=  15.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=47; total time=  15.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=51; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=54; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=57; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=60; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=64; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=67; total time=  14.3s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=1; total time=  15.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=4; total time=  16.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=8; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=11; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=14; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=17; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=20; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=24; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=27; total time=  15.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=30; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=33; total time=  13.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=36; total time=  16.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=40; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=43; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=46; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=49; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=52; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=55; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=58; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=61; total time=  15.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=65; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=68; total time=  17.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=2; total time=  13.1s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=5; total time=  14.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=8; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=12; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=15; total time=  16.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=19; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=22; total time=  15.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=25; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=29; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=32; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=36; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=38; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=42; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=45; total time=  14.5s\n",
      "[CV] END ........................gammas=0.01, n_components=1; total time=  10.2s\n",
      "[CV] END ........................gammas=0.01, n_components=4; total time=  14.1s\n",
      "[CV] END ........................gammas=0.01, n_components=7; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=10; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=14; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=17; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=21; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=24; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=27; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=30; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=34; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=37; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=41; total time=  16.0s\n",
      "[CV] END .......................gammas=0.01, n_components=44; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=47; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=50; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=54; total time=  17.1s\n",
      "[CV] END .......................gammas=0.01, n_components=57; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=61; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=64; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=67; total time=  14.7s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=1; total time=  14.9s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=4; total time=  15.5s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=8; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=11; total time=  13.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=14; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=17; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=20; total time=  16.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=24; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=27; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=30; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=33; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=36; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=40; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=42; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=46; total time=  13.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=49; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=52; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=55; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=58; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=61; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=64; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=67; total time=  14.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=2; total time=  15.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=5; total time=  13.4s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=8; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=11; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=14; total time=  15.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=18; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=21; total time=  12.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=24; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=27; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=30; total time=  13.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=33; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=37; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=40; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=43; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=46; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=49; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=52; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=56; total time=  16.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=59; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=62; total time=  15.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=66; total time=  16.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=69; total time=  15.3s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=3; total time=  15.0s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=6; total time=  15.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=10; total time=  13.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=13; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=16; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=19; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=23; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=26; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=30; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=33; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=36; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=39; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=42; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=45; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=49; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=52; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=55; total time=  13.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=58; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=61; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=64; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=67; total time=  14.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=1; total time=  15.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=4; total time=  14.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=7; total time=  12.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=10; total time=  13.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=13; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=17; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=20; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=23; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=26; total time=  15.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=29; total time=  12.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=32; total time=  12.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=34; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=38; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=41; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=44; total time=  15.4s\n",
      "[CV] END ........................gammas=0.01, n_components=2; total time=  14.2s\n",
      "[CV] END ........................gammas=0.01, n_components=5; total time=  14.3s\n",
      "[CV] END ........................gammas=0.01, n_components=9; total time=  12.3s\n",
      "[CV] END .......................gammas=0.01, n_components=11; total time=  12.9s\n",
      "[CV] END .......................gammas=0.01, n_components=13; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=17; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=20; total time=  12.7s\n",
      "[CV] END .......................gammas=0.01, n_components=23; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=26; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=29; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=33; total time=  16.3s\n",
      "[CV] END .......................gammas=0.01, n_components=37; total time=  12.6s\n",
      "[CV] END .......................gammas=0.01, n_components=39; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=42; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=45; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=48; total time=  16.5s\n",
      "[CV] END .......................gammas=0.01, n_components=52; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=56; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=59; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=62; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=66; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=68; total time=  14.2s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=2; total time=  15.4s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=6; total time=  15.4s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=9; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=12; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=15; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=18; total time=  15.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=22; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=25; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=28; total time=  12.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=31; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=34; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=37; total time=  15.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=40; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=43; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=47; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=50; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=53; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=56; total time=  16.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=59; total time=  16.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=63; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=66; total time=  16.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=1; total time=  16.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=4; total time=  14.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=7; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=10; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=14; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=17; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=20; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=23; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=26; total time=  15.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=30; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=33; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=36; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=39; total time=  13.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=42; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=46; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=49; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=52; total time=  13.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=55; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=58; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=61; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=65; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=68; total time=  14.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=2; total time=  13.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=5; total time=  14.9s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=8; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=11; total time=  16.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=15; total time=  15.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=18; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=21; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=24; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=27; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=31; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=34; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=37; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=40; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=43; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=47; total time=  16.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=50; total time=  12.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=53; total time=  17.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=56; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=59; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=63; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=66; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=69; total time=  15.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=3; total time=  15.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=7; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=10; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=13; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=16; total time=  14.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=20; total time=  13.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=22; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=25; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=28; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=31; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=35; total time=  16.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=39; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=42; total time=  13.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=44; total time=  14.1s\n",
      "[CV] END ........................gammas=0.01, n_components=2; total time=  14.8s\n",
      "[CV] END ........................gammas=0.01, n_components=6; total time=  14.2s\n",
      "[CV] END ........................gammas=0.01, n_components=9; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=13; total time=  16.7s\n",
      "[CV] END .......................gammas=0.01, n_components=16; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=19; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=22; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=25; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=28; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=31; total time=  13.2s\n",
      "[CV] END .......................gammas=0.01, n_components=34; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=37; total time=  13.5s\n",
      "[CV] END .......................gammas=0.01, n_components=40; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=43; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=46; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=49; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=53; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=56; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=60; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=63; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=66; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=69; total time=  16.7s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=4; total time=  13.8s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=7; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=10; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=13; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=16; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=19; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=22; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=26; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=29; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=32; total time=  12.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=35; total time=  13.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=38; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=41; total time=  17.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=45; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=48; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=51; total time=  16.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=54; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=58; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=61; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=64; total time=  16.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=68; total time=  15.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=2; total time=  14.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=5; total time=  15.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=9; total time=  18.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=12; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=16; total time=  12.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=19; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=22; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=25; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=28; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=31; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=34; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=37; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=40; total time=  13.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=44; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=47; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=50; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=53; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=56; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=59; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=62; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=65; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=68; total time=  16.1s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=3; total time=  15.2s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=6; total time=  13.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=9; total time=  13.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=12; total time=  13.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=15; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=18; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=22; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=25; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=28; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=31; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=34; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=38; total time=  12.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=41; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=44; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=47; total time=  16.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=50; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=53; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=56; total time=  12.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=59; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=62; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=66; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=69; total time=  13.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=3; total time=  14.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=6; total time=  14.0s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=9; total time=  12.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=12; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=15; total time=  16.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=18; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=22; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=25; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=28; total time=  16.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=31; total time=  16.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=35; total time=  12.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=38; total time=  14.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=41; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=44; total time=  13.8s\n",
      "[CV] END ........................gammas=0.01, n_components=2; total time=  13.5s\n",
      "[CV] END ........................gammas=0.01, n_components=5; total time=  12.6s\n",
      "[CV] END ........................gammas=0.01, n_components=7; total time=  13.9s\n",
      "[CV] END .......................gammas=0.01, n_components=10; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=14; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=17; total time=  13.2s\n",
      "[CV] END .......................gammas=0.01, n_components=20; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=24; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=27; total time=  16.5s\n",
      "[CV] END .......................gammas=0.01, n_components=31; total time=  13.5s\n",
      "[CV] END .......................gammas=0.01, n_components=34; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=37; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=40; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=44; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=47; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=50; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=53; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=56; total time=  13.0s\n",
      "[CV] END .......................gammas=0.01, n_components=59; total time=  12.8s\n",
      "[CV] END .......................gammas=0.01, n_components=62; total time=  17.5s\n",
      "[CV] END .......................gammas=0.01, n_components=65; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=69; total time=  15.3s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=3; total time=  14.3s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=6; total time=  14.0s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=9; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=12; total time=  13.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=15; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=19; total time=  15.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=22; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=25; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=28; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=31; total time=  12.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=34; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=37; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=40; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=44; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=47; total time=  13.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=50; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=54; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=57; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=60; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=63; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=66; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=69; total time=  16.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=3; total time=  13.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=6; total time=  16.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=10; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=13; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=16; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=19; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=22; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=26; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=29; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=32; total time=  16.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=35; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=38; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=42; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=45; total time=  13.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=48; total time=  16.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=52; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=55; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=58; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=61; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=64; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=68; total time=  14.4s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=1; total time=  14.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=5; total time=  14.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=8; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=11; total time=  16.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=14; total time=  16.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=18; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=21; total time=  16.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=25; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=28; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=31; total time=  12.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=34; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=37; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=40; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=43; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=46; total time=  16.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=50; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=53; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=57; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=60; total time=  16.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=63; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=66; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=69; total time=  16.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=3; total time=  13.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=6; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=10; total time=  12.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=13; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=16; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=19; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=23; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=26; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=29; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=33; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=35; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=39; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=42; total time=  12.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=45; total time=  16.1s\n",
      "[CV] END ........................gammas=0.01, n_components=2; total time=  13.3s\n",
      "[CV] END ........................gammas=0.01, n_components=5; total time=  13.6s\n",
      "[CV] END ........................gammas=0.01, n_components=8; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=11; total time=  13.9s\n",
      "[CV] END .......................gammas=0.01, n_components=14; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=18; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=22; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=25; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=28; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=31; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=34; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=38; total time=  12.7s\n",
      "[CV] END .......................gammas=0.01, n_components=40; total time=  13.4s\n",
      "[CV] END .......................gammas=0.01, n_components=43; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=47; total time=  16.2s\n",
      "[CV] END .......................gammas=0.01, n_components=50; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=53; total time=  16.7s\n",
      "[CV] END .......................gammas=0.01, n_components=57; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=60; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=63; total time=  14.1s\n",
      "[CV] END .......................gammas=0.01, n_components=66; total time=  15.5s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=1; total time=  14.3s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=4; total time=  14.4s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=7; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=10; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=14; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=17; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=20; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=23; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=27; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=29; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=33; total time=  12.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=35; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=38; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=41; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=44; total time=  16.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=48; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=51; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=54; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=57; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=60; total time=  16.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=64; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=67; total time=  16.4s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=1; total time=  15.4s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=5; total time=  14.0s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=8; total time=  13.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=11; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=14; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=17; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=20; total time=  16.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=24; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=27; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=31; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=34; total time=  13.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=37; total time=  15.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=40; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=43; total time=  16.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=47; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=49; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=53; total time=  16.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=56; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=59; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=63; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=66; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=69; total time=  15.4s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=3; total time=  14.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=6; total time=  13.1s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=9; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=12; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=16; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=19; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=22; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=25; total time=  15.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=29; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=32; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=35; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=39; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=42; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=45; total time=  13.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=48; total time=  12.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=51; total time=  15.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=54; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=57; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=60; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=64; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=66; total time=  16.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=1; total time=  14.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=4; total time=  15.2s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=7; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=11; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=14; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=17; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=20; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=23; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=27; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=30; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=33; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=36; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=39; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=43; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=46; total time=  14.4s\n",
      "[CV] END ........................gammas=0.01, n_components=3; total time=  13.2s\n",
      "[CV] END ........................gammas=0.01, n_components=5; total time=  14.1s\n",
      "[CV] END ........................gammas=0.01, n_components=8; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=11; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=14; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=18; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=21; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=24; total time=  12.8s\n",
      "[CV] END .......................gammas=0.01, n_components=27; total time=  12.5s\n",
      "[CV] END .......................gammas=0.01, n_components=30; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=33; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=37; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=41; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=44; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=47; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=50; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=52; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=55; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=58; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=62; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=65; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=68; total time=  15.1s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=2; total time=  13.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=5; total time=  14.8s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=8; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=12; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=15; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=18; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=21; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=24; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=27; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=31; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=34; total time=  18.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=38; total time=  12.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=41; total time=  13.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=44; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=47; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=50; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=53; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=57; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=60; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=63; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=66; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=69; total time=  16.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=3; total time=  13.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=7; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=10; total time=  13.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=13; total time=  12.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=15; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=18; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=22; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=25; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=29; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=32; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=34; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=38; total time=  16.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=41; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=44; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=48; total time=  13.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=50; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=54; total time=  12.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=56; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=60; total time=  16.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=63; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=66; total time=  16.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=69; total time=  16.4s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=4; total time=  14.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=7; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=11; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=14; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=17; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=21; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=24; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=27; total time=  16.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=30; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=33; total time=  16.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=37; total time=  13.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=40; total time=  15.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=44; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=47; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=49; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=53; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=56; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=60; total time=  18.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=63; total time=  13.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=66; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=69; total time=  19.0s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=4; total time=  15.1s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=8; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=11; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=14; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=17; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=20; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=24; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=27; total time=  13.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=30; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=33; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=36; total time=  18.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=40; total time=  12.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=42; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=46; total time=  13.6s\n",
      "[CV] END ........................gammas=0.01, n_components=1; total time=  13.8s\n",
      "[CV] END ........................gammas=0.01, n_components=6; total time=  13.5s\n",
      "[CV] END ........................gammas=0.01, n_components=8; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=12; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=15; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=18; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=21; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=25; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=28; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=31; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=35; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=38; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=41; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=44; total time=  16.2s\n",
      "[CV] END .......................gammas=0.01, n_components=47; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=51; total time=  13.9s\n",
      "[CV] END .......................gammas=0.01, n_components=54; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=57; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=60; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=63; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=66; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=69; total time=  16.2s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=3; total time=  13.1s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=6; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=10; total time=  15.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=13; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=17; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=20; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=23; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=26; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=29; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=32; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=35; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=39; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=42; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=45; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=49; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=52; total time=  15.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=55; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=58; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=62; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=65; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=68; total time=  14.3s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=2; total time=  14.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=4; total time=  14.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=8; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=11; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=15; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=18; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=21; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=24; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=28; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=31; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=34; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=37; total time=  16.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=41; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=44; total time=  13.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=47; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=50; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=53; total time=  15.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=57; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=60; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=63; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=67; total time=  14.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=1; total time=  14.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=4; total time=  13.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=7; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=10; total time=  13.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=13; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=16; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=20; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=23; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=26; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=29; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=32; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=35; total time=  13.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=38; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=41; total time=  15.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=45; total time=  13.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=48; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=51; total time=  16.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=55; total time=  17.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=58; total time=  16.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=62; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=65; total time=  16.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=68; total time=  15.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=2; total time=  13.7s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=5; total time=  13.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=8; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=11; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=14; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=18; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=21; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=24; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=28; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=31; total time=  13.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=34; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=37; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=40; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=44; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=47; total time=  12.8s\n",
      "[CV] END ........................gammas=0.01, n_components=3; total time=  14.3s\n",
      "[CV] END ........................gammas=0.01, n_components=6; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=10; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=13; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=16; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=19; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=22; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=25; total time=  16.0s\n",
      "[CV] END .......................gammas=0.01, n_components=29; total time=  16.5s\n",
      "[CV] END .......................gammas=0.01, n_components=32; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=35; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=39; total time=  17.3s\n",
      "[CV] END .......................gammas=0.01, n_components=42; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=45; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=48; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=51; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=55; total time=  13.9s\n",
      "[CV] END .......................gammas=0.01, n_components=58; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=61; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=64; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=67; total time=  14.9s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=1; total time=  16.4s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=5; total time=  13.8s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=8; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=11; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=14; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=17; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=20; total time=  12.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=23; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=26; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=30; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=33; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=36; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=39; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=42; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=45; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=48; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=52; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=55; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=58; total time=  16.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=62; total time=  15.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=65; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=68; total time=  16.7s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=2; total time=  14.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=6; total time=  15.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=9; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=12; total time=  16.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=16; total time=  13.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=19; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=22; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=25; total time=  12.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=28; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=31; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=35; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=38; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=41; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=44; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=47; total time=  16.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=51; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=54; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=57; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=60; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=63; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=66; total time=  15.1s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=1; total time=  13.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=3; total time=  14.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=7; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=10; total time=  13.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=13; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=16; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=19; total time=  13.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=22; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=25; total time=  13.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=28; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=31; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=34; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=37; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=41; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=44; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=47; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=50; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=54; total time=  15.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=57; total time=  16.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=60; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=63; total time=  17.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=67; total time=  16.2s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=1; total time=  13.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=4; total time=  15.1s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=7; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=10; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=13; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=17; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=20; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=23; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=26; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=30; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=33; total time=  13.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=36; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=39; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=43; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=46; total time=  15.6s\n",
      "[CV] END ........................gammas=0.01, n_components=1; total time=  13.2s\n",
      "[CV] END ........................gammas=0.01, n_components=4; total time=  16.1s\n",
      "[CV] END ........................gammas=0.01, n_components=9; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=12; total time=  13.0s\n",
      "[CV] END .......................gammas=0.01, n_components=15; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=17; total time=  12.9s\n",
      "[CV] END .......................gammas=0.01, n_components=20; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=23; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=26; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=30; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=33; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=36; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=40; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=43; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=46; total time=  15.7s\n",
      "[CV] END .......................gammas=0.01, n_components=49; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=52; total time=  16.2s\n",
      "[CV] END .......................gammas=0.01, n_components=55; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=59; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=62; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=65; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=69; total time=  15.2s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=3; total time=  12.7s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=6; total time=  14.2s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=9; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=12; total time=  13.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=15; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=18; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=21; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=25; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=28; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=31; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=34; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=37; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=41; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=44; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=47; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=51; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=54; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=57; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=61; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=64; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=67; total time=  14.3s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=1; total time=  13.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=4; total time=  14.7s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=7; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=11; total time=  15.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=14; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=17; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=20; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=23; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=27; total time=  16.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=30; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=33; total time=  13.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=36; total time=  13.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=39; total time=  15.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=43; total time=  16.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=46; total time=  17.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=50; total time=  16.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=53; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=56; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=59; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=62; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=65; total time=  15.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=69; total time=  15.9s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=3; total time=  13.9s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=6; total time=  14.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=9; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=13; total time=  12.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=16; total time=  15.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=19; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=22; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=26; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=29; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=32; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=35; total time=  13.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=38; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=41; total time=  16.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=44; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=48; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=51; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=54; total time=  15.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=58; total time=  16.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=61; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=64; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=67; total time=  15.0s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=1; total time=  15.2s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=5; total time=  15.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=8; total time=  16.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=11; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=14; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=17; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=21; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=24; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=27; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=30; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=34; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=37; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=40; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=43; total time=  15.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=46; total time=  17.9s\n",
      "[CV] END ........................gammas=0.01, n_components=3; total time=  14.3s\n",
      "[CV] END ........................gammas=0.01, n_components=6; total time=  13.3s\n",
      "[CV] END ........................gammas=0.01, n_components=9; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=13; total time=  15.3s\n",
      "[CV] END .......................gammas=0.01, n_components=16; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=19; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=23; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=26; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=29; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=32; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=36; total time=  16.0s\n",
      "[CV] END .......................gammas=0.01, n_components=39; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=42; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=46; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=49; total time=  16.6s\n",
      "[CV] END .......................gammas=0.01, n_components=53; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=56; total time=  16.0s\n",
      "[CV] END .......................gammas=0.01, n_components=59; total time=  13.2s\n",
      "[CV] END .......................gammas=0.01, n_components=62; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=65; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=68; total time=  15.9s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=3; total time=  15.5s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=6; total time=  15.7s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=9; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=13; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=16; total time=  14.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=19; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=22; total time=  16.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=25; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=29; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=32; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=36; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=38; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=42; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=45; total time=  15.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=48; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=51; total time=  15.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=55; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=58; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=61; total time=  17.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=65; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=68; total time=  14.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=2; total time=  13.7s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=5; total time=  15.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=8; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=12; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=15; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=18; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=21; total time=  13.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=24; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=27; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=30; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=33; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=36; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=40; total time=  13.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=43; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=46; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=49; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=52; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=55; total time=  16.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=59; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=62; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=65; total time=  16.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=68; total time=  16.7s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=2; total time=  15.0s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=5; total time=  12.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=9; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=12; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=15; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=18; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=21; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=24; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=27; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=30; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=34; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=37; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=40; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=43; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=46; total time=  16.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=50; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=53; total time=  12.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=56; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=59; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=62; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=65; total time=  16.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=68; total time=  14.7s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=3; total time=  13.7s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=6; total time=  13.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=9; total time=  16.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=12; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=15; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=18; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=21; total time=  13.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=24; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=28; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=31; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=34; total time=  17.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=37; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=41; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=44; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=47; total time=  16.8s\n",
      "[CV] END ........................gammas=0.01, n_components=3; total time=  14.5s\n",
      "[CV] END ........................gammas=0.01, n_components=6; total time=  13.7s\n",
      "[CV] END ........................gammas=0.01, n_components=8; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=12; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=15; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=19; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=22; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=24; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=28; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=31; total time=  13.0s\n",
      "[CV] END .......................gammas=0.01, n_components=34; total time=  12.2s\n",
      "[CV] END .......................gammas=0.01, n_components=36; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=39; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=43; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=46; total time=  17.3s\n",
      "[CV] END .......................gammas=0.01, n_components=50; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=53; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=56; total time=  15.3s\n",
      "[CV] END .......................gammas=0.01, n_components=59; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=63; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=66; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=69; total time=  16.3s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=4; total time=  15.0s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=7; total time=  14.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=10; total time=  15.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=13; total time=  13.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=16; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=19; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=23; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=26; total time=  16.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=30; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=33; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=36; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=39; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=43; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=46; total time=  16.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=49; total time=  17.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=53; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=56; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=59; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=62; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=65; total time=  15.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=69; total time=  14.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=3; total time=  16.5s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=6; total time=  14.9s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=9; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=13; total time=  13.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=16; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=19; total time=  15.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=23; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=26; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=29; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=32; total time=  14.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=35; total time=  16.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=39; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=42; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=45; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=49; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=52; total time=  15.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=55; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=58; total time=  17.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=62; total time=  15.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=65; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=68; total time=  15.4s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=2; total time=  13.3s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=6; total time=  16.1s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=9; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=12; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=15; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=19; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=22; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=25; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=28; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=31; total time=  16.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=35; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=38; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=42; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=45; total time=  13.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=48; total time=  13.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=51; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=54; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=57; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=60; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=63; total time=  16.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=67; total time=  14.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=1; total time=  13.6s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=4; total time=  15.2s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=7; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=10; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=14; total time=  12.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=16; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=19; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=22; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=25; total time=  13.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=28; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=32; total time=  16.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=35; total time=  12.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=38; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=41; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=45; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=48; total time=  13.5s\n",
      "[CV] END ........................gammas=0.01, n_components=2; total time=  13.6s\n",
      "[CV] END ........................gammas=0.01, n_components=5; total time=  15.6s\n",
      "[CV] END ........................gammas=0.01, n_components=9; total time=  13.2s\n",
      "[CV] END .......................gammas=0.01, n_components=12; total time=  14.8s\n",
      "[CV] END .......................gammas=0.01, n_components=16; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=19; total time=  16.1s\n",
      "[CV] END .......................gammas=0.01, n_components=22; total time=  14.6s\n",
      "[CV] END .......................gammas=0.01, n_components=26; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=29; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=32; total time=  13.7s\n",
      "[CV] END .......................gammas=0.01, n_components=35; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=38; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=41; total time=  16.2s\n",
      "[CV] END .......................gammas=0.01, n_components=44; total time=  13.6s\n",
      "[CV] END .......................gammas=0.01, n_components=48; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=51; total time=  15.6s\n",
      "[CV] END .......................gammas=0.01, n_components=54; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=57; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=60; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=64; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=67; total time=  17.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=1; total time=  14.8s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=4; total time=  15.8s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=8; total time=  13.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=11; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=14; total time=  16.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=17; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=21; total time=  17.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=24; total time=  16.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=28; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=31; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=35; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=38; total time=  13.8s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=41; total time=  12.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=44; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=47; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=50; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=53; total time=  14.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=56; total time=  13.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=59; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=62; total time=  15.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=66; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=69; total time=  15.2s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=3; total time=  13.7s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=6; total time=  13.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=9; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=12; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=15; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=19; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=22; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=25; total time=  14.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=28; total time=  14.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=32; total time=  17.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=35; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=38; total time=  14.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=41; total time=  13.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=45; total time=  15.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=48; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=51; total time=  16.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=55; total time=  13.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=57; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=61; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=64; total time=  15.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=67; total time=  16.0s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=2; total time=  14.6s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=5; total time=  14.0s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=8; total time=  13.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=11; total time=  14.7s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=14; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=17; total time=  13.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=20; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=23; total time=  13.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=27; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=30; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=33; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=36; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=39; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=42; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=45; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=49; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=52; total time=  16.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=55; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=59; total time=  16.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=62; total time=  14.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=65; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=68; total time=  15.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=2; total time=  15.4s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=6; total time=  15.3s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=9; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=12; total time=  16.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=16; total time=  12.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=19; total time=  16.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=22; total time=  16.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=26; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=29; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=32; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=36; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=39; total time=  13.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=42; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=45; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=49; total time=  14.0s\n",
      "[CV] END ........................gammas=0.01, n_components=4; total time=  15.2s\n",
      "[CV] END ........................gammas=0.01, n_components=7; total time=  13.4s\n",
      "[CV] END .......................gammas=0.01, n_components=10; total time=  12.9s\n",
      "[CV] END .......................gammas=0.01, n_components=12; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=15; total time=  13.5s\n",
      "[CV] END .......................gammas=0.01, n_components=18; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=21; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=25; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=28; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=32; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=35; total time=  16.9s\n",
      "[CV] END .......................gammas=0.01, n_components=38; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=41; total time=  16.2s\n",
      "[CV] END .......................gammas=0.01, n_components=45; total time=  13.3s\n",
      "[CV] END .......................gammas=0.01, n_components=48; total time=  13.4s\n",
      "[CV] END .......................gammas=0.01, n_components=51; total time=  14.5s\n",
      "[CV] END .......................gammas=0.01, n_components=54; total time=  13.1s\n",
      "[CV] END .......................gammas=0.01, n_components=57; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=60; total time=  15.3s\n",
      "[CV] END .......................gammas=0.01, n_components=63; total time=  15.2s\n",
      "[CV] END .......................gammas=0.01, n_components=67; total time=  14.0s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=1; total time=  14.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=3; total time=  13.7s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=7; total time=  16.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=10; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=13; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=16; total time=  16.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=20; total time=  13.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=23; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=26; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=29; total time=  15.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=32; total time=  16.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=36; total time=  14.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=39; total time=  17.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=43; total time=  15.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=46; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=49; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=52; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=55; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=59; total time=  14.5s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=61; total time=  13.4s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=64; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=67; total time=  14.3s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=1; total time=  15.6s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=5; total time=  15.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=8; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=11; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=14; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=17; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=21; total time=  14.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=24; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=27; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=30; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=34; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=37; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=40; total time=  13.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=43; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=46; total time=  16.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=50; total time=  16.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=53; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=57; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=60; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=63; total time=  16.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=66; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=69; total time=  16.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=4; total time=  14.8s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=7; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=10; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=14; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=17; total time=  13.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=20; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=23; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=26; total time=  13.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=29; total time=  15.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=32; total time=  17.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=36; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=39; total time=  15.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=42; total time=  17.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=46; total time=  14.3s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=49; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=52; total time=  15.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=56; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=59; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=62; total time=  15.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=65; total time=  15.6s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=69; total time=  14.0s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=3; total time=  14.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=6; total time=  15.9s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=9; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=13; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=16; total time=  16.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=19; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=23; total time=  16.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=26; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=29; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=32; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=35; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=38; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=41; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=45; total time=  16.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=48; total time=  14.7s\n",
      "[CV] END ........................gammas=0.01, n_components=3; total time=  16.1s\n",
      "[CV] END ........................gammas=0.01, n_components=7; total time=  14.3s\n",
      "[CV] END .......................gammas=0.01, n_components=10; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=13; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=16; total time=  14.9s\n",
      "[CV] END .......................gammas=0.01, n_components=20; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=23; total time=  13.9s\n",
      "[CV] END .......................gammas=0.01, n_components=26; total time=  15.8s\n",
      "[CV] END .......................gammas=0.01, n_components=29; total time=  14.7s\n",
      "[CV] END .......................gammas=0.01, n_components=32; total time=  14.0s\n",
      "[CV] END .......................gammas=0.01, n_components=35; total time=  15.1s\n",
      "[CV] END .......................gammas=0.01, n_components=38; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=42; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=45; total time=  14.2s\n",
      "[CV] END .......................gammas=0.01, n_components=48; total time=  13.8s\n",
      "[CV] END .......................gammas=0.01, n_components=51; total time=  15.0s\n",
      "[CV] END .......................gammas=0.01, n_components=54; total time=  15.9s\n",
      "[CV] END .......................gammas=0.01, n_components=58; total time=  14.4s\n",
      "[CV] END .......................gammas=0.01, n_components=61; total time=  15.5s\n",
      "[CV] END .......................gammas=0.01, n_components=64; total time=  15.4s\n",
      "[CV] END .......................gammas=0.01, n_components=68; total time=  16.3s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=2; total time=  16.1s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=5; total time=  17.6s\n",
      "[CV] END .........gammas=0.03593813663804628, n_components=9; total time=  14.1s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=12; total time=  15.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=16; total time=  13.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=19; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=22; total time=  13.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=25; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=28; total time=  16.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=32; total time=  16.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=35; total time=  15.7s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=39; total time=  14.9s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=42; total time=  15.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=45; total time=  14.6s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=48; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=51; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=54; total time=  14.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=57; total time=  14.0s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=60; total time=  13.3s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=63; total time=  16.2s\n",
      "[CV] END ........gammas=0.03593813663804628, n_components=67; total time=  14.6s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=1; total time=  15.1s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=4; total time=  13.8s\n",
      "[CV] END ..........gammas=0.1291549665014884, n_components=7; total time=  13.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=10; total time=  13.4s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=13; total time=  15.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=16; total time=  14.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=20; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=23; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=26; total time=  14.9s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=29; total time=  16.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=32; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=36; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=39; total time=  13.5s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=42; total time=  13.2s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=45; total time=  14.6s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=48; total time=  14.3s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=51; total time=  15.0s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=54; total time=  14.8s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=58; total time=  15.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=61; total time=  15.1s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=64; total time=  13.7s\n",
      "[CV] END .........gammas=0.1291549665014884, n_components=67; total time=  16.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=2; total time=  14.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=5; total time=  15.5s\n",
      "[CV] END ...........gammas=0.464158883361278, n_components=8; total time=  16.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=12; total time=  16.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=15; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=18; total time=  14.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=21; total time=  16.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=24; total time=  14.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=28; total time=  16.0s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=32; total time=  14.1s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=35; total time=  13.8s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=38; total time=  14.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=41; total time=  14.9s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=44; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=47; total time=  15.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=51; total time=  14.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=54; total time=  16.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=57; total time=  16.4s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=61; total time=  15.5s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=64; total time=  14.2s\n",
      "[CV] END ..........gammas=0.464158883361278, n_components=67; total time=  15.5s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=2; total time=  15.7s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=5; total time=  16.2s\n",
      "[CV] END ..........gammas=1.6681005372000592, n_components=9; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=12; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=15; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=18; total time=  13.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=21; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=24; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=27; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=30; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=33; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=37; total time=  12.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=40; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=43; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=46; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=49; total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........gammas=1.6681005372000592, n_components=49; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=52; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=55; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=58; total time=  14.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=62; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=65; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=68; total time=  14.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=2; total time=  14.8s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=5; total time=  14.2s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=8; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=11; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=14; total time=  12.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=18; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=21; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=24; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=27; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=30; total time=  15.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=33; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=36; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=40; total time=  15.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=43; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=46; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=49; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=52; total time=  13.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=55; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=58; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=61; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=65; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=68; total time=  13.7s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=2; total time=  14.4s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=5; total time=  14.0s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=8; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=11; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=14; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=17; total time=  11.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=19; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=22; total time=  16.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=26; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=29; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=32; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=35; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=38; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=42; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=45; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=48; total time=  13.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=51; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=54; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=57; total time=  13.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=60; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=63; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=66; total time=  13.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=69; total time=  16.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=4; total time=  13.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=7; total time=  13.9s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=9; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=13; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=16; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=19; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=22; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=25; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=28; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=32; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=35; total time=  15.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=38; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=41; total time=  13.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=44; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=48; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=51; total time=  16.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=54; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=57; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=60; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=63; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=66; total time=  15.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=1; total time=  13.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=3; total time=  14.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=7; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=10; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=13; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=16; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=19; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=22; total time=  13.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=25; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=29; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=32; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=35; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=39; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=41; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=44; total time=  15.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=48; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=51; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=54; total time=  15.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=58; total time=  13.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=61; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=64; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=67; total time=  15.4s\n",
      "[CV] END ......................gammas=1000.0, n_components=1; total time=  14.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=4; total time=  13.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=7; total time=  14.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=10; total time=  12.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=13; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=16; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=48; total time=  12.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=50; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=54; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=57; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=60; total time=  14.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=63; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=66; total time=  17.0s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=1; total time=  13.9s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=4; total time=  14.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=7; total time=  13.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=10; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=13; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=16; total time=  16.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=20; total time=  13.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=23; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=26; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=29; total time=  13.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=32; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=35; total time=  13.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=38; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=41; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=44; total time=  13.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=47; total time=  16.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=51; total time=  14.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=54; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=57; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=60; total time=  15.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=64; total time=  16.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=67; total time=  15.7s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=1; total time=  15.8s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=5; total time=  16.1s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=8; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=11; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=15; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=18; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=21; total time=  13.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=24; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=27; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=30; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=33; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=37; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=40; total time=  16.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=43; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=47; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=50; total time=  13.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=52; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=56; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=59; total time=  15.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=62; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=65; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=68; total time=  15.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=2; total time=  13.9s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=5; total time=  14.7s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=9; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=12; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=15; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=18; total time=  13.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=21; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=25; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=27; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=31; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=34; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=37; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=40; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=43; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=46; total time=  16.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=50; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=53; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=56; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=59; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=63; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=66; total time=  17.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=1; total time=  14.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=4; total time=  12.7s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=6; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=10; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=14; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=17; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=20; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=23; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=27; total time=  15.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=30; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=33; total time=  12.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=36; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=39; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=42; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=45; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=49; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=52; total time=  13.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=55; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=58; total time=  12.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=60; total time=  16.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=64; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=67; total time=  15.6s\n",
      "[CV] END ......................gammas=1000.0, n_components=1; total time=  13.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=4; total time=  14.2s\n",
      "[CV] END ......................gammas=1000.0, n_components=7; total time=  14.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=10; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=13; total time=  13.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=16; total time=  13.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=19; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=48; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=50; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=53; total time=  16.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=57; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=60; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=63; total time=  16.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=67; total time=  13.9s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=1; total time=  13.9s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=4; total time=  15.6s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=7; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=10; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=13; total time=  13.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=17; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=19; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=23; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=26; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=29; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=32; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=35; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=38; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=42; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=45; total time=  16.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=48; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=51; total time=  15.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=55; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=58; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=61; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=64; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=67; total time=  16.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=2; total time=  15.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=5; total time=  15.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=9; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=12; total time=  12.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=14; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=18; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=22; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=25; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=28; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=31; total time=  13.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=34; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=37; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=40; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=43; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=46; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=49; total time=  16.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=53; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=55; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=59; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=62; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=65; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=69; total time=  16.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=3; total time=  14.4s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=6; total time=  14.2s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=9; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=12; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=16; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=19; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=22; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=25; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=28; total time=  16.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=32; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=35; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=38; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=41; total time=  13.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=44; total time=  13.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=47; total time=  13.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=50; total time=  12.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=52; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=56; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=59; total time=  16.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=62; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=66; total time=  16.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=69; total time=  17.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=4; total time=  16.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=7; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=10; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=13; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=17; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=20; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=23; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=26; total time=  16.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=30; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=33; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=36; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=40; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=43; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=46; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=49; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=53; total time=  15.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=56; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=59; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=62; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=65; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=68; total time=  16.6s\n",
      "[CV] END ......................gammas=1000.0, n_components=2; total time=  16.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=6; total time=  13.9s\n",
      "[CV] END ......................gammas=1000.0, n_components=9; total time=  13.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=12; total time=  16.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=15; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=18; total time=  13.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=21; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=49; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=52; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=55; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=59; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=62; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=65; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=68; total time=  17.0s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=3; total time=  14.2s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=6; total time=  15.1s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=9; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=12; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=16; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=18; total time=  14.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=22; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=24; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=28; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=31; total time=  12.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=34; total time=  14.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=37; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=41; total time=  13.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=43; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=46; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=50; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=53; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=56; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=59; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=62; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=65; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=69; total time=  16.0s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=3; total time=  14.9s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=6; total time=  13.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=9; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=12; total time=  13.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=15; total time=  17.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=19; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=22; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=25; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=29; total time=  13.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=32; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=35; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=38; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=41; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=45; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=48; total time=  13.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=51; total time=  13.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=54; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=57; total time=  16.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=61; total time=  16.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=64; total time=  16.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=67; total time=  17.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=2; total time=  14.4s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=5; total time=  14.6s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=8; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=11; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=14; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=18; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=21; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=24; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=27; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=30; total time=  13.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=33; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=36; total time=  13.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=39; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=42; total time=  13.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=45; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=49; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=52; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=55; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=58; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=61; total time=  13.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=64; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=68; total time=  15.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=2; total time=  13.4s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=5; total time=  14.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=8; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=11; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=14; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=17; total time=  13.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=20; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=24; total time=  12.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=26; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=29; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=32; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=36; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=39; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=42; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=45; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=48; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=51; total time=  16.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=55; total time=  17.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=59; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=62; total time=  13.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=65; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=68; total time=  15.2s\n",
      "[CV] END ......................gammas=1000.0, n_components=2; total time=  16.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=5; total time=  14.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=9; total time=  13.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=12; total time=  15.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=15; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=18; total time=  15.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=22; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=47; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=50; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=53; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=56; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=59; total time=  16.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=62; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=66; total time=  14.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=69; total time=  17.1s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=3; total time=  16.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=7; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=10; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=13; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=16; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=19; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=23; total time=  13.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=26; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=29; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=32; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=35; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=39; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=42; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=45; total time=  16.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=48; total time=  16.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=52; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=54; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=58; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=61; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=64; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=67; total time=  16.1s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=1; total time=  14.1s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=4; total time=  15.8s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=8; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=11; total time=  16.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=15; total time=  16.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=18; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=21; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=25; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=28; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=30; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=34; total time=  15.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=38; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=41; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=44; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=48; total time=  16.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=51; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=54; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=58; total time=  13.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=61; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=64; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=67; total time=  17.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=1; total time=  14.3s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=4; total time=  15.7s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=8; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=11; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=14; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=17; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=20; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=24; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=27; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=30; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=33; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=36; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=39; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=42; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=46; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=49; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=52; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=55; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=59; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=61; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=65; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=68; total time=  16.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=2; total time=  12.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=5; total time=  14.6s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=8; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=11; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=14; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=18; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=21; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=24; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=27; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=30; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=34; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=37; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=40; total time=  16.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=43; total time=  16.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=47; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=50; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=53; total time=  16.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=57; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=60; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=63; total time=  15.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=66; total time=  14.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=1; total time=  13.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=3; total time=  15.1s\n",
      "[CV] END ......................gammas=1000.0, n_components=7; total time=  15.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=10; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=14; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=17; total time=  13.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=20; total time=  14.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=23; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=50; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=53; total time=  16.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=56; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=60; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=63; total time=  13.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=66; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=69; total time=  15.5s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=3; total time=  13.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=6; total time=  14.1s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=9; total time=  15.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=13; total time=  17.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=17; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=20; total time=  16.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=24; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=27; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=30; total time=  16.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=33; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=36; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=39; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=42; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=46; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=49; total time=  16.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=53; total time=  12.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=55; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=58; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=62; total time=  16.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=65; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=68; total time=  16.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=2; total time=  13.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=5; total time=  13.6s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=8; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=11; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=15; total time=  12.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=17; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=21; total time=  16.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=24; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=27; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=31; total time=  16.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=34; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=37; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=41; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=44; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=47; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=50; total time=  12.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=53; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=56; total time=  16.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=60; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=63; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=66; total time=  15.3s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=1; total time=  13.8s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=3; total time=  13.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=6; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=10; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=12; total time=  13.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=15; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=18; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=22; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=25; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=29; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=31; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=34; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=38; total time=  13.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=41; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=44; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=47; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=51; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=54; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=57; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=60; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=64; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=67; total time=  14.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=1; total time=  14.2s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=4; total time=  15.4s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=7; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=10; total time=  13.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=13; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=16; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=19; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=22; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=25; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=29; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=32; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=35; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=38; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=41; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=44; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=47; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=51; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=54; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=57; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=60; total time=  16.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=63; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=67; total time=  14.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=1; total time=  15.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=4; total time=  13.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=7; total time=  15.3s\n",
      "[CV] END .....................gammas=1000.0, n_components=11; total time=  14.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=14; total time=  13.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=17; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=20; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=23; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=47; total time=  16.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=51; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=54; total time=  12.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=57; total time=  15.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=60; total time=  14.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=63; total time=  15.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=67; total time=  16.0s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=1; total time=  14.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=5; total time=  15.0s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=8; total time=  12.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=10; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=14; total time=  12.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=16; total time=  14.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=19; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=22; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=25; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=29; total time=  15.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=33; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=36; total time=  16.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=39; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=42; total time=  16.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=45; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=49; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=52; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=56; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=59; total time=  16.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=62; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=65; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=68; total time=  14.6s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=2; total time=  14.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=5; total time=  17.7s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=9; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=12; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=16; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=19; total time=  12.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=22; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=25; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=28; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=32; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=35; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=38; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=41; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=44; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=47; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=51; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=54; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=57; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=60; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=63; total time=  13.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=66; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=69; total time=  15.3s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=3; total time=  14.8s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=6; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=10; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=13; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=16; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=19; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=22; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=26; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=29; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=32; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=35; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=38; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=42; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=45; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=48; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=51; total time=  16.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=54; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=58; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=61; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=64; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=67; total time=  15.7s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=1; total time=  16.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=5; total time=  15.7s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=8; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=11; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=15; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=19; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=22; total time=  16.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=26; total time=  13.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=28; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=32; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=35; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=38; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=42; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=45; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=48; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=52; total time=  13.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=55; total time=  16.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=58; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=61; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=64; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=68; total time=  14.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=2; total time=  14.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=5; total time=  14.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=8; total time=  13.5s\n",
      "[CV] END .....................gammas=1000.0, n_components=11; total time=  13.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=14; total time=  14.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=17; total time=  13.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=20; total time=  15.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=24; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=49; total time=  14.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=52; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=56; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=59; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=62; total time=  13.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=65; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=68; total time=  16.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=2; total time=  15.8s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=6; total time=  16.2s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=9; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=12; total time=  12.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=15; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=18; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=21; total time=  15.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=25; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=28; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=31; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=34; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=38; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=41; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=44; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=47; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=50; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=53; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=57; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=60; total time=  17.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=63; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=67; total time=  16.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=1; total time=  14.3s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=4; total time=  14.0s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=7; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=10; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=13; total time=  16.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=17; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=20; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=23; total time=  13.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=26; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=29; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=32; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=36; total time=  13.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=39; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=42; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=45; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=48; total time=  16.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=52; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=55; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=58; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=61; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=64; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=68; total time=  12.6s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=1; total time=  13.9s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=4; total time=  14.9s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=7; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=11; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=14; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=17; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=20; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=23; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=27; total time=  13.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=30; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=33; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=37; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=40; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=43; total time=  12.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=46; total time=  16.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=49; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=52; total time=  13.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=55; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=59; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=62; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=65; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=68; total time=  13.9s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=2; total time=  15.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=5; total time=  14.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=9; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=12; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=15; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=18; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=21; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=25; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=28; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=31; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=34; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=37; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=40; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=44; total time=  16.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=47; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=50; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=53; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=56; total time=  15.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=60; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=63; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=66; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=69; total time=  15.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=4; total time=  14.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=7; total time=  14.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=10; total time=  15.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=13; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=17; total time=  16.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=21; total time=  14.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=24; total time=  14.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=50; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=53; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=56; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=59; total time=  16.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=63; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=66; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=69; total time=  14.8s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=3; total time=  15.3s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=6; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=11; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=14; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=17; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=20; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=23; total time=  16.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=27; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=30; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=33; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=37; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=40; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=43; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=46; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=50; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=52; total time=  13.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=55; total time=  15.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=59; total time=  15.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=62; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=65; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=68; total time=  16.4s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=3; total time=  15.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=6; total time=  14.6s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=9; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=12; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=15; total time=  12.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=18; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=21; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=24; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=28; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=31; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=34; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=38; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=40; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=44; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=47; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=50; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=53; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=56; total time=  13.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=59; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=62; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=65; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=68; total time=  17.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=3; total time=  14.2s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=6; total time=  13.6s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=9; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=13; total time=  17.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=16; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=19; total time=  16.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=23; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=26; total time=  13.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=29; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=33; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=36; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=39; total time=  17.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=43; total time=  15.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=46; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=49; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=53; total time=  13.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=56; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=58; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=62; total time=  16.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=65; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=68; total time=  14.9s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=2; total time=  15.8s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=6; total time=  13.6s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=9; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=12; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=15; total time=  13.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=18; total time=  15.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=21; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=24; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=28; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=31; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=34; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=37; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=41; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=44; total time=  16.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=47; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=50; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=54; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=57; total time=  13.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=59; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=62; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=66; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=69; total time=  16.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=3; total time=  14.9s\n",
      "[CV] END ......................gammas=1000.0, n_components=6; total time=  14.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=9; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=13; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=16; total time=  14.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=19; total time=  13.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=22; total time=  15.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=26; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=48; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=51; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=54; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=57; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=61; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=64; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=67; total time=  14.5s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=1; total time=  14.6s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=4; total time=  13.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=7; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=11; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=14; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=17; total time=  15.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=20; total time=  12.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=23; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=26; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=30; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=33; total time=  16.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=36; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=39; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=43; total time=  16.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=46; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=49; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=52; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=56; total time=  17.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=59; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=63; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=66; total time=  15.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=69; total time=  15.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=3; total time=  14.7s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=6; total time=  14.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=9; total time=  16.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=13; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=17; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=20; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=23; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=26; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=30; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=33; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=36; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=39; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=42; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=45; total time=  13.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=48; total time=  14.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=51; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=55; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=58; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=61; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=64; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=68; total time=  16.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=2; total time=  15.2s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=5; total time=  15.2s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=9; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=11; total time=  13.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=15; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=17; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=21; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=24; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=27; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=30; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=34; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=37; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=40; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=44; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=47; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=50; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=53; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=56; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=60; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=63; total time=  16.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=66; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=69; total time=  13.8s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=3; total time=  15.6s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=6; total time=  14.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=9; total time=  15.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=13; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=16; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=19; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=23; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=26; total time=  12.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=29; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=32; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=35; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=38; total time=  17.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=42; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=46; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=49; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=52; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=55; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=58; total time=  15.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=61; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=65; total time=  15.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=68; total time=  16.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=3; total time=  14.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=6; total time=  13.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=8; total time=  14.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=12; total time=  15.5s\n",
      "[CV] END .....................gammas=1000.0, n_components=15; total time=  16.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=19; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=22; total time=  14.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=25; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=51; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=54; total time=  16.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=58; total time=  13.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=60; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=64; total time=  14.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=66; total time=  14.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=69; total time=  16.2s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=4; total time=  13.1s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=7; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=10; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=13; total time=  14.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=16; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=20; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=22; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=26; total time=  12.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=28; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=32; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=36; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=39; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=42; total time=  13.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=45; total time=  13.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=48; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=51; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=54; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=57; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=60; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=63; total time=  15.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=66; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=69; total time=  15.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=4; total time=  15.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=7; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=10; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=14; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=16; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=19; total time=  15.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=23; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=27; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=30; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=33; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=36; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=40; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=43; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=46; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=49; total time=  16.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=53; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=56; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=59; total time=  16.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=63; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=66; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=69; total time=  16.6s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=4; total time=  15.4s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=7; total time=  13.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=10; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=14; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=17; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=20; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=23; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=26; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=29; total time=  16.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=33; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=36; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=39; total time=  13.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=42; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=45; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=48; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=51; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=55; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=58; total time=  16.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=61; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=64; total time=  13.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=67; total time=  15.2s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=2; total time=  15.4s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=5; total time=  14.8s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=8; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=12; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=15; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=18; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=21; total time=  12.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=24; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=27; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=30; total time=  13.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=33; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=37; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=40; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=43; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=46; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=49; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=52; total time=  15.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=56; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=59; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=62; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=65; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=68; total time=  15.3s\n",
      "[CV] END ......................gammas=1000.0, n_components=3; total time=  15.8s\n",
      "[CV] END ......................gammas=1000.0, n_components=6; total time=  14.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=9; total time=  15.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=12; total time=  15.5s\n",
      "[CV] END .....................gammas=1000.0, n_components=16; total time=  15.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=19; total time=  14.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=22; total time=  15.3s\n",
      "[CV] END .....................gammas=1000.0, n_components=25; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=47; total time=  15.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=51; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=55; total time=  14.8s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=58; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=61; total time=  15.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=64; total time=  15.5s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=67; total time=  13.3s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=1; total time=  13.5s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=4; total time=  15.2s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=8; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=11; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=14; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=17; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=21; total time=  16.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=24; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=27; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=31; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=34; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=37; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=40; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=44; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=47; total time=  12.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=49; total time=  16.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=53; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=56; total time=  16.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=60; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=63; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=66; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=69; total time=  16.4s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=3; total time=  14.2s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=7; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=10; total time=  13.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=13; total time=  13.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=16; total time=  13.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=19; total time=  12.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=22; total time=  13.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=25; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=28; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=31; total time=  12.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=34; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=37; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=40; total time=  13.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=43; total time=  15.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=46; total time=  15.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=50; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=53; total time=  17.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=57; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=60; total time=  17.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=64; total time=  16.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=67; total time=  15.4s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=1; total time=  15.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=5; total time=  16.6s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=8; total time=  16.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=12; total time=  16.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=15; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=19; total time=  15.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=22; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=25; total time=  13.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=28; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=31; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=35; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=38; total time=  15.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=41; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=45; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=48; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=51; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=54; total time=  16.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=57; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=61; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=64; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=67; total time=  16.6s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=1; total time=  14.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=4; total time=  16.4s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=8; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=11; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=14; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=17; total time=  16.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=21; total time=  13.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=24; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=27; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=31; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=34; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=37; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=40; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=43; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=46; total time=  15.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=50; total time=  16.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=53; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=56; total time=  16.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=60; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=63; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=66; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=69; total time=  14.9s\n",
      "[CV] END ......................gammas=1000.0, n_components=3; total time=  15.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=6; total time=  15.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=10; total time=  15.5s\n",
      "[CV] END .....................gammas=1000.0, n_components=13; total time=  13.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=16; total time=  14.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=20; total time=  13.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=23; total time=  14.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=26; total time=  15.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=52; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=55; total time=  14.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=58; total time=  16.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=61; total time=  16.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=65; total time=  15.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=68; total time=  14.5s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=2; total time=  15.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=5; total time=  14.0s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=8; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=12; total time=  13.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=15; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=18; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=21; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=25; total time=  13.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=28; total time=  12.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=31; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=34; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=37; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=40; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=43; total time=  16.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=47; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=50; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=54; total time=  16.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=57; total time=  15.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=60; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=63; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=66; total time=  14.9s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=1; total time=  15.1s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=4; total time=  13.8s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=7; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=10; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=13; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=16; total time=  16.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=20; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=23; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=26; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=29; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=32; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=35; total time=  14.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=39; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=42; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=45; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=49; total time=  16.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=52; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=55; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=58; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=62; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=65; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=68; total time=  14.9s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=2; total time=  15.8s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=6; total time=  13.0s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=8; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=12; total time=  16.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=15; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=18; total time=  12.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=21; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=24; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=28; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=31; total time=  16.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=34; total time=  13.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=37; total time=  13.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=40; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=43; total time=  12.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=46; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=49; total time=  17.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=53; total time=  16.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=56; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=59; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=62; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=65; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=69; total time=  17.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=3; total time=  12.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=6; total time=  14.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=9; total time=  15.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=12; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=15; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=19; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=22; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=25; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=28; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=31; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=35; total time=  16.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=38; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=41; total time=  16.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=45; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=49; total time=  13.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=51; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=54; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=57; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=61; total time=  16.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=64; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=67; total time=  16.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=1; total time=  14.5s\n",
      "[CV] END ......................gammas=1000.0, n_components=5; total time=  13.9s\n",
      "[CV] END ......................gammas=1000.0, n_components=8; total time=  14.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=11; total time=  14.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=14; total time=  15.3s\n",
      "[CV] END .....................gammas=1000.0, n_components=17; total time=  13.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=21; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=24; total time=  15.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=27; total time=  13.9s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=53; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=56; total time=  14.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=59; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=62; total time=  13.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=65; total time=  15.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=69; total time=  16.3s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=3; total time=  14.8s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=6; total time=  14.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=9; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=12; total time=  14.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=15; total time=  15.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=19; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=22; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=25; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=29; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=32; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=35; total time=  13.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=38; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=41; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=44; total time=  16.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=48; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=51; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=54; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=57; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=61; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=64; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=67; total time=  14.8s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=1; total time=  14.6s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=4; total time=  13.9s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=7; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=11; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=14; total time=  16.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=17; total time=  15.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=20; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=24; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=27; total time=  13.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=30; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=33; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=36; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=39; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=42; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=46; total time=  13.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=49; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=52; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=55; total time=  14.6s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=58; total time=  14.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=61; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=65; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=67; total time=  16.4s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=2; total time=  15.3s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=5; total time=  13.8s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=8; total time=  13.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=11; total time=  14.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=14; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=18; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=21; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=24; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=28; total time=  16.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=31; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=34; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=37; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=41; total time=  14.4s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=44; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=47; total time=  16.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=50; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=53; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=57; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=60; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=63; total time=  16.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=66; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=69; total time=  15.7s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=3; total time=  14.8s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=7; total time=  16.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=11; total time=  13.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=14; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=17; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=20; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=23; total time=  16.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=27; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=30; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=33; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=36; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=39; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=43; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=46; total time=  12.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=48; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=52; total time=  15.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=55; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=58; total time=  16.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=62; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=65; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=69; total time=  14.3s\n",
      "[CV] END ......................gammas=1000.0, n_components=2; total time=  16.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=5; total time=  14.1s\n",
      "[CV] END ......................gammas=1000.0, n_components=9; total time=  15.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=12; total time=  14.3s\n",
      "[CV] END .....................gammas=1000.0, n_components=15; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=18; total time=  14.5s\n",
      "[CV] END .....................gammas=1000.0, n_components=21; total time=  15.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=25; total time=  14.0s\n",
      "[CV] END .....................gammas=1000.0, n_components=28; total time=  15.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=52; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=55; total time=  16.3s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=58; total time=  13.2s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=61; total time=  15.0s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=64; total time=  13.7s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=67; total time=  14.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=2; total time=  14.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=5; total time=  13.9s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=8; total time=  15.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=11; total time=  17.6s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=15; total time=  16.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=18; total time=  14.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=21; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=24; total time=  13.1s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=27; total time=  13.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=30; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=34; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=37; total time=  14.4s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=40; total time=  16.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=44; total time=  15.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=47; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=50; total time=  13.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=53; total time=  14.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=56; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=59; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=62; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=66; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=69; total time=  14.9s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=3; total time=  15.3s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=6; total time=  14.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=10; total time=  15.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=13; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=16; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=20; total time=  15.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=23; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=26; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=29; total time=  16.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=33; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=36; total time=  13.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=39; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=43; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=46; total time=  16.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=49; total time=  14.9s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=52; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=56; total time=  16.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=59; total time=  13.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=62; total time=  15.8s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=66; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=69; total time=  16.2s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=3; total time=  15.1s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=7; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=10; total time=  13.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=13; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=16; total time=  16.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=20; total time=  13.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=23; total time=  14.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=26; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=29; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=32; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=35; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=39; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=42; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=45; total time=  15.1s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=48; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=52; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=55; total time=  16.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=58; total time=  15.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=62; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=65; total time=  15.3s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=68; total time=  16.4s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=3; total time=  14.1s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=6; total time=  15.6s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=9; total time=  14.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=12; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=16; total time=  13.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=18; total time=  15.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=22; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=25; total time=  13.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=28; total time=  14.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=31; total time=  15.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=34; total time=  14.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=38; total time=  14.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=41; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=44; total time=  14.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=47; total time=  12.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=50; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=53; total time=  16.1s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=56; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=59; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=63; total time=  17.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=66; total time=  16.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=69; total time=  16.7s\n",
      "[CV] END ......................gammas=1000.0, n_components=4; total time=  16.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=8; total time=  15.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=11; total time=  13.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=14; total time=  14.4s\n",
      "[CV] END .....................gammas=1000.0, n_components=18; total time=  13.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=20; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=23; total time=  13.9s\n",
      "[CV] END .....................gammas=1000.0, n_components=26; total time=  15.8s\n",
      "[CV] END .....................gammas=1000.0, n_components=30; total time=  15.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=51; total time=  14.4s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=54; total time=  13.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=57; total time=  17.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=61; total time=  17.1s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=64; total time=  16.6s\n",
      "[CV] END .........gammas=1.6681005372000592, n_components=68; total time=  15.4s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=2; total time=  14.7s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=5; total time=  16.1s\n",
      "[CV] END ...........gammas=5.994842503189409, n_components=9; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=12; total time=  14.9s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=15; total time=  15.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=19; total time=  14.2s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=22; total time=  13.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=25; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=28; total time=  14.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=31; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=35; total time=  16.0s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=38; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=41; total time=  15.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=45; total time=  13.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=48; total time=  16.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=51; total time=  16.5s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=55; total time=  15.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=58; total time=  14.7s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=61; total time=  15.3s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=64; total time=  14.8s\n",
      "[CV] END ..........gammas=5.994842503189409, n_components=68; total time=  15.8s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=2; total time=  16.1s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=6; total time=  13.5s\n",
      "[CV] END ..........gammas=21.544346900318846, n_components=8; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=12; total time=  13.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=14; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=18; total time=  15.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=21; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=24; total time=  14.5s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=27; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=31; total time=  15.4s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=35; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=37; total time=  15.3s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=41; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=44; total time=  16.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=47; total time=  15.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=50; total time=  14.2s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=54; total time=  14.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=57; total time=  14.0s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=60; total time=  15.7s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=63; total time=  16.1s\n",
      "[CV] END .........gammas=21.544346900318846, n_components=67; total time=  14.7s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=1; total time=  15.5s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=4; total time=  14.5s\n",
      "[CV] END ...........gammas=77.42636826811278, n_components=7; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=10; total time=  14.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=13; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=17; total time=  14.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=20; total time=  15.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=23; total time=  14.0s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=26; total time=  15.5s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=30; total time=  14.8s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=32; total time=  14.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=36; total time=  17.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=40; total time=  15.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=43; total time=  16.2s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=47; total time=  16.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=50; total time=  15.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=54; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=57; total time=  15.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=60; total time=  14.7s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=63; total time=  14.9s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=67; total time=  13.6s\n",
      "[CV] END ..........gammas=77.42636826811278, n_components=69; total time=  15.3s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=4; total time=  15.5s\n",
      "[CV] END ...........gammas=278.2559402207126, n_components=7; total time=  13.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=10; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=13; total time=  14.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=16; total time=  15.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=20; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=23; total time=  14.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=26; total time=  15.4s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=29; total time=  15.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=33; total time=  15.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=36; total time=  13.7s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=39; total time=  12.6s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=42; total time=  14.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=45; total time=  13.9s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=48; total time=  15.3s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=51; total time=  13.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=54; total time=  15.2s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=57; total time=  14.0s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=61; total time=  14.8s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=64; total time=  16.5s\n",
      "[CV] END ..........gammas=278.2559402207126, n_components=67; total time=  16.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=2; total time=  15.2s\n",
      "[CV] END ......................gammas=1000.0, n_components=5; total time=  14.0s\n",
      "[CV] END ......................gammas=1000.0, n_components=8; total time=  14.1s\n",
      "[CV] END .....................gammas=1000.0, n_components=11; total time=  14.6s\n",
      "[CV] END .....................gammas=1000.0, n_components=15; total time=  13.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=18; total time=  16.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=21; total time=  15.2s\n",
      "[CV] END .....................gammas=1000.0, n_components=24; total time=  15.7s\n",
      "[CV] END .....................gammas=1000.0, n_components=27; total time=  14.3s\n",
      "[CV] END .....................gammas=1000.0, n_components=31; total time=  16.5s\n",
      "Best params: {'gammas': 0.01, 'n_components': 28}, cv score: 0.6589393939393939, test score: 0.6772486772486772\n"
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import KernelLogisiticRegression\n",
    "cv_6 = GridSearchCV(KernelLogisiticRegression(), {\"gammas\": gammas, \"n_components\": np.arange(1, 70)}, scoring=\"roc_auc\", verbose=2, n_jobs=-1).fit(X_train, y_train)\n",
    "sc_6 = np.mean(cross_val_score(cv_6.best_estimator_, X_train, y_train))\n",
    "cv_6.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_6.best_params_}, cv score: {sc_6}, test score: {cv_6.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model selection where we select optimal $\\gamma$ with shrinkage of covariance matrix - using graph mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.39112324e+04 -2.86287175e+04 -2.41329857e+04 -2.03085105e+04\n",
      " -1.70567284e+04 -1.42935477e+04 -1.19472238e+04 -9.95654626e+03\n",
      " -8.26929162e+03 -6.84090409e+03 -5.63336943e+03 -4.61425432e+03\n",
      " -3.75588678e+03 -3.03465685e+03 -2.43041994e+03 -1.92598771e+03\n",
      " -1.50669371e+03 -1.16002263e+03 -8.75293978e+02 -6.43392104e+02\n",
      " -4.56535788e+02 -3.08081740e+02 -1.92357346e+02 -1.04519425e+02\n",
      " -4.04383691e+01  3.38531148e+00  2.98348361e+01             nan\n",
      "             nan -7.06320549e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35405851e+04 -2.83135734e+04 -2.38651950e+04 -2.00811202e+04\n",
      " -1.68638063e+04 -1.41300327e+04 -1.18087978e+04 -9.83952531e+03\n",
      " -8.17053261e+03 -6.75772539e+03 -5.56348313e+03 -4.55570841e+03\n",
      " -3.70701580e+03 -2.99403982e+03 -2.39684445e+03 -1.89841927e+03\n",
      " -1.48424958e+03 -1.14194952e+03 -8.60948989e+02 -6.32226428e+02\n",
      " -4.48080786e+02 -3.01936993e+02 -1.88180359e+02 -1.02016642e+02\n",
      " -3.93571125e+01  3.26458951e+00  2.87073545e+01             nan\n",
      "             nan -7.67843516e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.35281385e+04 -2.83027560e+04 -2.38557677e+04 -2.00728789e+04\n",
      " -1.68565770e+04 -1.41236668e+04 -1.18031688e+04 -9.83452496e+03\n",
      " -8.16606883e+03 -6.75371958e+03 -5.55986825e+03 -4.55242732e+03\n",
      " -3.70401980e+03 -2.99128744e+03 -2.39430036e+03 -1.89605344e+03\n",
      " -1.48203653e+03 -1.13986766e+03 -8.58980112e+02 -6.30355297e+02\n",
      " -4.46294791e+02 -3.00225933e+02 -1.86536345e+02 -1.00434190e+02\n",
      " -3.78335610e+01  4.72800331e+00  3.01029037e+01             nan\n",
      "             nan -7.56802993e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.33590109e+04 -2.81582060e+04 -2.37321865e+04 -1.99671878e+04\n",
      " -1.67661491e+04 -1.40462612e+04 -1.17368734e+04 -9.77770862e+03\n",
      " -8.11733984e+03 -6.71189065e+03 -5.52392644e+03 -4.52150846e+03\n",
      " -3.67738667e+03 -2.96831112e+03 -2.37444436e+03 -1.87886015e+03\n",
      " -1.46711564e+03 -1.12688635e+03 -8.47654634e+02 -6.20443854e+02\n",
      " -4.37591489e+02 -2.92555675e+02 -1.79750584e+02 -9.44075042e+01\n",
      " -3.24611534e+01  9.53146606e+00  3.44015455e+01             nan\n",
      "             nan -7.47739740e+01]\n",
      "  warnings.warn(\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "7 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 679, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_shrunk_covariance.py\", line 180, in fit\n",
      "    self._set_covariance(covariance)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/covariance/_empirical_covariance.py\", line 192, in _set_covariance\n",
      "    self.precision_ = linalg.pinvh(covariance, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/basic.py\", line 1478, in pinvh\n",
      "    s, u = decomp.eigh(a, lower=lower, check_finite=False)\n",
      "  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 604, in eigh\n",
      "    raise LinAlgError(msg)\n",
      "numpy.linalg.LinAlgError: Internal Error.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xabush/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-3.43893553e+04 -2.90377775e+04 -2.44831234e+04 -2.06083774e+04\n",
      " -1.73137056e+04 -1.45139326e+04 -1.21363891e+04 -1.01190757e+04\n",
      " -8.40909581e+03 -6.96131941e+03 -5.73724227e+03 -4.70401302e+03\n",
      " -3.83360301e+03 -3.10209792e+03 -2.48909347e+03 -1.97717972e+03\n",
      " -1.55150105e+03 -1.19938068e+03 -9.10000238e+02 -6.74126207e+02\n",
      " -4.83876522e+02 -3.32521379e+02 -2.14313564e+02 -1.24344866e+02\n",
      " -5.84275408e+01 -1.30068321e+01  1.48617478e+01             nan\n",
      "             nan -7.75856373e+01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3845/4058558867.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mnotebooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmanifold_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mKernelLogisiticRegression\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mcv_7\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mKernelLogisiticRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0massoc_mat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0massoc_mat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshrink_cov\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"gammas\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mgammas\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"roc_auc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0msc_7\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcross_val_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv_7\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcv_7\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Best params: {cv_7.best_params_}, cv score: {sc_7}, test score: {cv_7.best_estimator_.score(X_test, y_test)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    889\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 891\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    892\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    893\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1390\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1391\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1392\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1393\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1394\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    836\u001B[0m                     )\n\u001B[1;32m    837\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 838\u001B[0;31m                 out = parallel(\n\u001B[0m\u001B[1;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[1;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1054\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1055\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1056\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1057\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    934\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 935\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    936\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    541\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    543\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 440\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    311\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 312\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    313\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import KernelLogisiticRegression\n",
    "cv_7 = GridSearchCV(KernelLogisiticRegression(assoc_mat=assoc_mat, shrink_cov=True), {\"gammas\": gammas}, scoring=\"roc_auc\", verbose=1, n_jobs=8).fit(X_train, y_train)\n",
    "sc_7 = np.mean(cross_val_score(cv_7.best_estimator_, X_train, y_train))\n",
    "cv_7.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_7.best_params_}, cv score: {sc_7}, test score: {cv_7.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6900 candidates, totalling 34500 fits\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 602, in dump\n    return Pickler.dump(self, obj)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/_memmapping_reducer.py\", line 442, in __call__\n    for dumped_filename in dump(a, filename):\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 482, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"/home/xabush/miniconda3/lib/python3.9/pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 281, in save\n    wrapper.write_array(obj, self)\n  File \"/home/xabush/miniconda3/lib/python3.9/site-packages/joblib/numpy_pickle.py\", line 104, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mPicklingError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3845/4205950585.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mnotebooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmanifold_reg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mKernelLogisiticRegression\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mcv_8\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mKernelLogisiticRegression\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0massoc_mat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0massoc_mat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"gammas\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mgammas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"n_components\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m70\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"alpha\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogspace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"roc_auc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0msc_8\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcross_val_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv_8\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcv_8\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Best params: {cv_8.best_params_}, cv score: {sc_8}, test score: {cv_8.best_estimator_.score(X_test, y_test)}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    889\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 891\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    892\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    893\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1390\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1391\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1392\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1393\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1394\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    836\u001B[0m                     )\n\u001B[1;32m    837\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 838\u001B[0;31m                 out = parallel(\n\u001B[0m\u001B[1;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[1;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1054\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1055\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1056\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1057\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    934\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 935\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    936\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    541\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    543\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    436\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 438\u001B[0;31m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    389\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 390\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    391\u001B[0m             \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    392\u001B[0m                 \u001B[0;31m# Break a reference cycle with the exception in self._exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mPicklingError\u001B[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "from notebooks.manifold_reg.util import KernelLogisiticRegression\n",
    "cv_8 = GridSearchCV(KernelLogisiticRegression(assoc_mat=assoc_mat), {\"gammas\": gammas, \"n_components\": np.arange(1, 70), \"alpha\": np.logspace(0, 3, 10)}, scoring=\"roc_auc\", verbose=1, n_jobs=10).fit(X_train, y_train)\n",
    "sc_8 = np.mean(cross_val_score(cv_8.best_estimator_, X_train, y_train))\n",
    "cv_8.best_estimator_.fit(X_train, y_train)\n",
    "print(f\"Best params: {cv_8.best_params_}, cv score: {sc_8}, test score: {cv_8.best_estimator_.score(X_test, y_test)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}